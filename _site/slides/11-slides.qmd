---
title: "POLS 1600"
subtitle: "Statistical Inference<br>and Course Review"
date: last-modified
date-format: "[Updated ]MMM D, YYYY"
format: 
  revealjs:
    theme: brownslides.scss
    logo: images/pols1600_hex.png
    footer: "POLS 1600"
    multiplex: false
    transition: fade
    slide-number: c
    incremental: true
    center: false
    menu: true
    scrollable: true
    highlight-style: github
    progress: true
    code-overflow: wrap
    html-math-method: mathjax
    chalkboard: true
    # include-after-body: title-slide.html
    title-slide-attributes:
      align: left
      data-background-image: images/pols1600_hex.png
      data-background-position: 90% 50%
      data-background-size: 40%
filters:
  - openlinksinnewpage
  - webr
webr:
  packages: ['dplyr',"ggplot2"]
  autoload-packages: true
execute: 
  eval: true
  echo: true
  warning: false
  message: false
  cache: false
---


```{r}
#| label: init
#| echo: false
#| results: hide
#| warning: false 
#| message: false

library(tidyverse)
library(labelled)
library(haven)
library(DeclareDesign)
library(easystats)
library(texreg)

```



# {{< fa map-location>}} Overview {.inverse}

## Class Plan

- Announcements
- Feedback
- Course Review
- Statistical Inference
- Final Projects


## Annoucements

- Lab 11/[Assignment 3](https://pols1600.paultesta.org/assignments/a3) this week
- No tutorial this week
- Next Tuesday, April 23, Work on Presentations/Drafts
- [Assignment 4](https://pols1600.paultesta.org/assignments/a3) now due April 25.
- April 30, Final Workshop 
- May 2 Class Presentations


## Setup: Packages for today

```{r}
#| label: packages
#| echo: true

## Pacakges for today
the_packages <- c(
  ## R Markdown
  "kableExtra","DT","texreg","htmltools",
  ## Tidyverse
  "tidyverse", "lubridate", "forcats", "haven", "labelled",
  ## Extensions for ggplot
  "ggmap","ggrepel", "ggridges", "ggthemes", "ggpubr", 
  "patchwork",
  "GGally", "scales", "dagitty", "ggdag", "ggforce",
  # Data 
  "COVID19","maps","mapdata","qss","tidycensus", "dataverse", 
  # Analysis
  "DeclareDesign", "easystats", "zoo"
)

## Define a function to load (and if needed install) packages

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

## Install (if needed) and load libraries in the_packages
ipak(the_packages)
```

# {{< fa magnifying-glass>}} Review {.inverse}

## Three Modes of Inference

- Descriptive

- Causal

- Predictive

## Descriptive Inference {.smaller}

> Summarize distributions and relationships in data

- You should know how to:

  - [Calculate](https://pols1600.paultesta.org/slides/01-slides#/using-r-to-summarize-data) and interpret measures: 
  - Central Tendency
  - Dispersion
  - Association
  - [Load](https://pols1600.paultesta.org/slides/01-slides#/loading-data-into-r), [look at](https://pols1600.paultesta.org/slides/01-slides#/looking-at-your-data), [wrangle](https://pols1600.paultesta.org/slides/01-slides#/dplyr-functions-for-data-wrangling), and [describe](https://pols1600.paultesta.org/slides/01-slides#/describing-data-in-r) data using:
  - Tables
  - Figures
  
## Data Wrangling {.smaller}

> The process of transforming data into a useable format

You should know how to:

- Load, look at,and transform data into R
- Get a [HLO](https://pols1600.paultesta.org/slides/01-slides#/hlos-allow-you-to) of the raw data:
  - Unit of analysis
  - Dimensions of the Data
  - Quickly summarize the distributions and values of variables
- [Recode](https://pols1600.paultesta.org/labs/09-lab-comments#recode-the-data) the data to:
  - Replace values as `NA`s
  - Create categories, indicators (0,1), and factors
  - Transform predictors (e.g. standardizing predictors)
- Reshape the data
  - Pivoting columns and rows
  - Joining data sets together.
- [Aggregate](https://pols1600.paultesta.org/labs/02-lab-comments#reproduce-the-figure-from-lab-01) the data into [summaries](https://pols1600.paultesta.org/labs/03-lab-comments#calculate-the-average-treatment-effect)
  
## Data Visualization{.smaller}

> A tool for describing distributions and relationships

You should know:

- The [grammar of graphics](https://pols1600.paultesta.org/slides/02-slides#/the-grammar-of-graphics):
  - Data
  - Aesthetic mappings
  - Geometries
- How to [generate common plots](https://pols1600.paultesta.org/slides/02-slides#/describing-distributions-and-associations) to describe:
  - Distributions
  - Relationships
  
## Causal Inference{.smaller}

> Causal Inference requires counterfactual comparisons

You should know:

- [Potential outcomes](https://pols1600.paultesta.org/slides/03-slides#/potential-outcomes-notation) and [DAGs](https://pols1600.paultesta.org/slides/05-slides#/directed-acyclic-graphs-1)

- The [fundamental problem of causal inference](https://pols1600.paultesta.org/slides/03-slides#/fundamental-problem-of-causal-inference)

- Bias caused by:
  - [Confounding](https://pols1600.paultesta.org/slides/05-slides#/section-1) (Coffee and Cancer)
  - [Colliding](https://pols1600.paultesta.org/slides/05-slides#/section-2) (Dating Jerks)
- Casual Identification in:
  - [Experimental](https://pols1600.paultesta.org/slides/03-slides#/causal-identification-with-experimental-designs) designs
  - [Observational](https://pols1600.paultesta.org/slides/05-slides#/observational-designs) designs 
  
## Prediction with Linear Models {.smaller}

> Linear regression provides a linear estimate of the conditional expectation function 

You should know:

- [How linear regression works](https://pols1600.paultesta.org/slides/05-slides#/understanding-linear-regression)

- [What it means to control for](https://pols1600.paultesta.org/slides/07-slides.html#/regression-models-partition-variance) predictors in a multiple regression

- When and [why we should control](https://pols1600.paultesta.org/slides/05-slides#/when-to-control-for-a-variable) for predictors.

- How to translate [substantive claims]{.blue} into [empirical expectations](https://pols1600.paultesta.org/labs/06-lab-comments#estimate-a-model-controlling-for-age) for our models

- How to [estimate and interpret]{.blue} these models using [tables](https://pols1600.paultesta.org/labs/06-lab-comments#display-the-model-as-a-regression-table) and [figures](https://pols1600.paultesta.org/labs/10-lab-comments#visualize-predicted-values)

- How to [quantify uncertainty]{.blue} about these estimates using [confidence intervals](https://pols1600.paultesta.org/slides/10-slides#/confidence-intervals-1) and [hypothesis tests](https://pols1600.paultesta.org/slides/10-slides#/what-is-a-hypothesis-test).


# {{< fa lightbulb>}} Quantifying Uncertainty {.inverse}

## Probability {.smaller}

- [Probability](https://pols1600.paultesta.org/slides/08-slides#/probability-1) describes the likelihood of an event

- [Random variables](https://pols1600.paultesta.org/slides/08-slides#/random-variables) assign numeric values to all the events that could occur.

- [Probability distributions](https://pols1600.paultesta.org/slides/08-slides#/probability-distributions) assign probabilities to every value of a random variable. Can be:

  - discrete
  - continuous
  - characterized by their expected values and variances
  - used to:
  - describe the [data generating process]{.blue}
  - [quantify uncertainty]{.blue} about estimates


## Sampling Distributions and Standard Errors {.smaller}

- A sampling distribution is a theoretical probability distribution of estimates obtained from taking repeated samples of size $n$ from some population

  - A distribution of what we could have seen

- A standard errors is simply the standard deviation ($\sigma$) of the sampling distribution

  - A measure of how much our estimate could have varied.

- Law of Large Numbers: As $N \to \infty$ $\bar{x} \to \mu$
- Central Limit Theorem: As $N \to \infty$ $\bar{x} \sim \mathcal{N}(\mu, \sigma^2)$

## Confidence Intervals {.smaller}

> Confidence intervals provide a range of plausible values for our estimate

- Three components:
  - Point Estimate (i.e. a mean, or coefficient)
  - Confidence Level (Often 95 percent by convention)
  - Margin of Error (+/- some range (typically 2\*SD for 95 percent CI))
- Confidence is about the interval
  - 95 percent of the intervals construct in this manner would contain the truth.

## Hypothesis Testing {.smaller}

- A hypothesis test quantifies how likely it is that we would observe what we did (our test statistic), if some claim about the world were true (our hypothesis, typically a null ).

- If our claim were true, then [under this null hypothesis]{.blue}, our test statistic would have a distribution centered around the truth.

- A [p-value]() which describes the probability of observing a test statistic as extreme or more extreme in a world where our null hypothesis was true

  - If our [p-value is small]{.blue} ($p < 0.05$), we [reject the null]{.blue} hypothesis

     If our [p-value is large]{.blue} ($p > 0.05$), we [fail to reject the null]{.blue}, or retain the null hypothesis


## {.smaller}
#### Relationship between CIs and Hypothsis Testing

:::: panel-tabset
## Concept

We can think of a confidence interval as a [range of hypotheses we would fail to reject]{.blue} with $p < \alpha$



## {{<fa code>}} Code

```{r}
#| label: pval_ci

# Load Data
load(url("https://pols1600.paultesta.org/files/data/nes24.rda"))

# Fit Model
m1 <- lm_robust(dv_participation ~   education + income, df,
                se = "classical")

# Range of hypotheses for education
pval_ci_df <- tibble(
  # Hypothesized Betas for Education
  Hypothesis = seq(0, .32, length.out = 100),
  # Test Statistics
  Statistic = (m1$coefficients["education"] - Hypothesis) /
  m1$std.error["education"],
  # P-value for two sided test
  `p-value` = 2*pt(abs(Statistic), df = m1$df,lower.tail = F)
)

fig_pval_ci <- pval_ci_df %>% 
  ggplot(aes(Hypothesis, `p-value`))+
  geom_line()+
  geom_vline(xintercept = m1$coefficients["education"],
             linetype = "solid",
             col = "red")+
  geom_vline(xintercept = m1$conf.low["education"],
             linetype = "dotted")+
  geom_vline(xintercept = m1$conf.high["education"],
             linetype = "dotted")+
  geom_hline(yintercept = 0.05,
             linetype = "dashed")+
  labs(
    x = "Hypothesized Education, Coefficent",
    title = "Confidence intervals are a range\nof plausible hypotheses"
  )+
  theme_minimal()

```

## {{<fa table>}} Table

```{r}
#| label: tabm1
#| echo: false
#| results: asis

htmlreg(m1)

```


## {{<fa chart-line>}} Figure

```{r}
#| label: fig_pval_ci
#| echo: false

fig_pval_ci
```

::::

## Four Possible Outcomes of a hypothesis Test {.smaller}

::::{.columns}

:::{.column width=45%}

- **False Positive: (Type I Error)** 
  - Rejecting a True $H_0$.
  - $\tau = 0$, but $\hat{\tau}$ has a $p<0.05$
  - Probability=$\alpha$

- **True Positive: (Correct Decision)** 
  - Rejecting a false $H_0$: 
  - $\tau \neq 0$, and  $\hat{\tau}$ has a $p<0.05$
  - Occurs with Probability = $1-\beta$


:::


:::{.column width=45%}

- **True Negative: (Correct Decision) ** 
  - Failing to reject a True $H_0$: 
  - $\tau = 0$, and $\hat{\tau}$ has a $p>0.05$
  - Occurs with Probability = $1-\alpha$

- **False Negative: (Type II Error)** 
  - Failing to reject a false $H_0$. 
  - $\tau \neq 0$ but $\hat{\tau}$ has a $p>0.05$
  - Occurs with Probability= $\beta$

:::

::::

## Type 1 and 2 Errors

![](https://miro.medium.com/max/1400/1*uF5aBZ63BZ8IDEyF8wo-CA.png)

[Source](https://towardsdatascience.com/a-general-guidance-of-hypothesis-testing-7cab119ca999)

## Statistical Power{.smaller}

```{webr-r}
#| label: plot_power
#| context: setup

power_function <- function(tau = 2, se =1, pval = 0.05){
  df <- tibble(
    x = seq(-4*se, tau+4*se,length.out = 100 ),
    p = dnorm(x, mean = 0, sd = se)
  )
  the_x_min <- min(df$x)
  the_x_max <- max(df$x)
  the_y_max <- max(df$p)
  
  z <- qnorm(1-(pval/2), sd = se)
  power <- pnorm(z, mean = tau, sd =se, lower.tail = F)
  type2_error <- pnorm(z, mean = tau, sd =se)
  if(power > type2_error){
    the_y_power <- dnorm(z, mean = tau, sd = se)*.7
    the_y_type2 <- dnorm(z, mean = tau, sd = se)*.3
  }
  if(power <= type2_error){
    the_y_power <- dnorm(z, mean = tau, sd = se)*.3
    the_y_type2 <- dnorm(z, mean = tau, sd = se)*.7
  }

  
  fig_power <- df %>% 
    ggplot(aes(x))+
    ylim(0,the_y_max + the_y_max/10)+
    stat_function(geom = "line", fun = dnorm,
                args = list(sd = se),
                alpha = 0.5)+
    stat_function(geom = "line", fun = dnorm,
                alpha = 0.5,
                col = "blue",
                args =list(mean = tau, sd = se))+
    stat_function(geom = "area", fun = dnorm,
                fill = "darkblue",
                alpha = 0.5,
                xlim = c(the_x_min,qnorm(1-(pval/2),sd = se)),
                args =list(mean = tau, sd = se))+
    stat_function(geom = "area", fun = dnorm,
                fill = "lightblue",
                alpha = 0.7,
                xlim = c(qnorm(1-(pval/2), sd = se),the_x_max),
                args =list(mean = tau, sd = se))+
    stat_function(geom = "area", fun = dnorm,
                fill = "red",
                alpha = .25,
                xlim = c(qnorm(1-(pval/2), sd = se),the_x_max),
                args =list(mean = 0, sd = se)
                )+
    stat_function(geom = "area", fun = dnorm,
                fill = "red",
                alpha = .5,
                xlim = c(qnorm(pval/2,sd = se),the_x_min),
                args =list(mean = 0, sd = se)
                )+
    geom_vline(xintercept = qnorm(1-(pval/2),sd = se), linetype =2)+
    geom_segment(
      data = tibble(x = 0,
           xend= tau,
           y = the_y_max,
           yend = the_y_max),
      aes(x = x, xend = xend, 
          y=y, yend=yend)
      )+
    annotate("text", x = tau/2, y = the_y_max + the_y_max/40, 
             label = expression(tau), hjust=.5)+
    annotate("text", x = -z-se/10, y = the_y_max*.02, 
             label = expression(
               paste(alpha,"/2", sep ="")), hjust=1
             )+
    annotate("text", x = z+se/10, y = the_y_max*.02, 
             label = expression(
               paste(alpha,"/2", sep ="")), hjust=0
             )+
  annotate("text", x = z-se/8, y = the_y_type2-the_y_max/20, label = expression(beta), hjust=1) +
  annotate("text", x = z-se/8, y = the_y_type2, label = "Type II-Error", hjust=1)+
  annotate("text", x = z+se/8, y = the_y_power, label = paste( "Statistical Power = ", round(power,2),sep = ""), hjust=0)+
  annotate("text", x = z+se/8, y = the_y_power-the_y_max/20, label = expression(paste("1-",beta,sep="")), hjust=0)+

  annotate("text", x = 0, y = the_y_max + the_y_max/40, label = expression(H[0]), hjust=0.5)+
  annotate("text", x = tau, y = the_y_max + the_y_max/40, label = expression(H[1]), hjust=0.5)+
annotate("text", x = z+se/8, y = the_y_max + the_y_max/10, label = "z=critical value", hjust=0)+
    theme_void()

  
  return(fig_power)
}

```

:::: panel-tabset

## Concept

:::{.nonincremental}

- Consider two distributions of statistics under 
  - a null of no effect ($H_0$) 
  - an effect of $\tau$ ($H_1$)
- For a significance threshold of $\alpha$ we would:
  - Fail to reject the null $\beta$  (Type II Errors)
  - Correctly reject the null $1 -\beta$ (Statistical Power)

:::

## Power

Try changing $\tau$ (the effect size), and se (the standard deviation of the effect)

```{webr-r}
#| label: power
#| autorun: true
#| context: interactive
#| message: false
power_function(tau = 2, se = 1, pval = 0.05)
```

## Comments

Power is a function of:

- Sample size ($N$)
  - Larger samples, smaller standard errors (LLN)

- Effect size ($\tau$)
  - Bigger effects less overlap
  
- Significance threshold ($\alpha$)
  - Decrease Type 1 (False Positives) error leads to increased Type 2 (False Negatives)
  
- The distribution of the data 
  - Variance, asympotitc approximations
  
::::

# {{< fa concept>}} Final Projects {.inverse}

## Strucutre of Final Paper and Drafts {.smaller}

[Assignment 4:](https://pols1600.paultesta.org/assignments/a4) Seven sections

1.  Introduction (5 percent, \~ 4 paragraphs)
2.  Theory and Expectations (10 percent, \~4+ paragraphs)
3.  Data (20 percent \~ 4+ paragraphs)
4.  Design (25 percent \~ 5+ paragraphs)
5.  Results (25 percent \~ 5+ paragraphs)
6.  Conclusion (5 percent \~ 3+ paragraphs)
7.  Appendix (10 percent \~ Variable codebook and all the R code for your project)

## For Thursday {.smaller}

- [Assignment 3](https://pols1600.paultesta.org/assignments/a3)

- [Download template](https://pols1600.paultesta.org/assignments/assignments/pols1600_paper_template.qmd)

- Create shared google drive.

- Make progress on:
  - 3.  **Data** (20 percent \~ 4+ paragraphs)
  - 4.  *Design* (25 percent \~ 5+ paragraphs)
  - 5.  **Results** (25 percent \~ 5+ paragraphs)

## Motivating Questions {.smaller}

In the reset of today's class, we'll get some practice putting together the various skills you need for your drafts by exploring the following:

- How does partisanship shape American's perceptions of vaccines?

- Who is skeptical of the benefits of vaccination?

- Have these perceptions about vaccines changed over time?

## Tasks:{.smaller}

To explore these questions, we need to

- Get setup to work

- Load our data

- Recode our data

- Summarize our data

- Specify our expectations

- Estimate models to test these expectations

- Present and interpret results using

  - Tables
  - Figures
  - Confidence intervals 
  - Hypothesis tests 

## New packages

To easily load survey data for our question, we'll need the `anesr` package, which loads data from the American National Election Studies into R

```{r}
#| label: anesr
# # Uncomment to uninstall package to download NES survey data
# library(devtools)
# install_github("jamesmartherus/anesr")
require(anesr)


```

## Packages for today

```{r}
<<packages>>

```

## Data {.smaller}

Now that we have `anesr` installed, let's load data from the 2016 and 2020 National Election Studies:

```{r}
#| label: anesdata
# Load data
data(timeseries_2016, package = "anesr")
data(timeseries_2020, package = "anesr")
```

And copy those data frames into new dataframes with shorter names

```{r}
#| label: rename
# Rename datasets
nes16 <- timeseries_2016
nes20 <- timeseries_2020
```

## Finding variables: Outcomes {.smaller}

Our primary outcome of interest are beliefs about vaccines.

Variables `V162162x` in the 2016 NES and `V202383x` in the 2020 NES will serve as our primary outcome of interest, summarizing respondents answer to the following question:

> Do the health benefits of vaccinations generally outweigh the risks, do the risks outweigh the benefits, or is there no difference?

## Finding variables: Predictors {.smaller}

Similarly, `V161158x` in the 2016 NES and `V201231x` in the 2020 NES will serve our key predictor (respondent's partisanship).

Finally, we'll control respondents' age, using `V161267` in the 2016 NES and `V201507x` in the 2020 NES


## Examine Distributions: Vaccine Beliefs {.smaller}

The variables in the NES datasets are of a class `labelled` which allows numeric values to have substantive labels

```{r}
#| label: class

class(nes16$V162162x)
```

Our outcome variable has the following labels:

```{r}
#| label: labels
labelled::val_labels(nes16$V162162x)

```

And distribution of responses:

```{r}
#| label: table
table(nes16$V162162x)
```

## Recoding outcome variables

:::: panel-tabset

## Tasks

What transformations do we need to make to `V162162x` in `nes16` and `V202383x` in `nes20` so that these variables are suitable for analysis?


- Recode negative values to be `NA`

- Reverse code so that higher values indicate greater belief vaccines benefits

- Create an indicator of people who are vaccine skeptics

## {{< fa code >}} Code

```{r}
#| label: recodedv

nes16 %>%
  mutate(
    # Make Negative values NA, Reverse Code So Higher Values = Benefits > Risks
    vaccine_benefits = ifelse(V162162x < 0, NA, (V162162x-8)*-1),
    # Indicator of vaccine skepticism (Risks > Benefits)
    vaccine_skeptic01 = case_when(
      vaccine_benefits > 4 ~ 0,
      vaccine_benefits <= 4 ~ 1,
      TRUE ~ NA_real_
    )
  ) -> nes16 # Save recodes to nes16

nes20 %>%
  mutate(
    # Make Negative values NA, Reverse Code So Higher Values = Benefits > Risks
    vaccine_benefits = ifelse(V202383x < 0, NA, (V202383x-8)*-1),
    # Indicator of vaccine skepticism (Risks > Benefits)
    vaccine_skeptic01 = case_when(
      vaccine_benefits > 4 ~ 0,
      vaccine_benefits <= 4 ~ 1,
      TRUE ~ NA_real_
    )
  ) -> nes20 # Save recodes to nes20
```

::::

## Recoding Predictors

:::: panel-tabset

## Tasks

:::{.nonincremental}

Now we repeat this process for our key predictor, partisanship.

- Recode partisanship variables `V161158x` in `nes16` and `V201231x` in `nes20`

- Create indicators from this recoded variable that classify partisanship as categorical variable (with Democrats as the reference category)

And our covariate, age variables `V161267` in `nes16` and `V201507x` in `nes20`

- Recode negative values to be `NA`

:::

## {{<fa code >}} Code 

```{r}
#| label: recode

nes16 %>%
  mutate(
    pid = ifelse(V161158x < 0, NA, V161158x),
    pid3cat = case_when(
      pid < 4 ~ "Democrat",
      pid == 4 ~ "Independent",
      pid > 4 ~ "Republican",
      TRUE ~ "Independent"
    ) %>% factor(., levels = c("Democrat","Independent","Republican")),
    age = ifelse(V161267 < 0, NA, V161267)
  ) -> nes16

## Recoding Partisanship (V201231x) in 2020 NES

nes20 %>%
  mutate(
    pid = ifelse(V201231x < 0, NA, V201231x),
    pid3cat = case_when(
      pid < 4 ~ "Democrat",
      pid == 4 ~ "Independent",
      pid > 4 ~ "Republican",
      TRUE ~ "Independent"
    ) %>% factor(., levels = c("Democrat","Independent","Republican")),
    age = ifelse(V201507x < 0, NA, V201507x)
  ) -> nes20

```

::::

## Progress Report {.smaller}

To explore these questions, we need to

- *Get setup to work* âœ…

- *Load our data* âœ…

- *Recode our data* âœ…

- **Summarize our data**ðŸ“¥

- Specify our expectations

- Estimate models to test these expectations

- Presenting and interpreting results using

  - Tables
  - Figures
  - Confidence intervals 
  - Hypothesis tests 


## Descriptive statistics (2016) {.smaller}

:::: panel-tabset

## Tasks 

1.  Create `the_vars`

2.  Select these variables

3.  Pivot the data

4.  Calculate summary statistics

5.  Format as an html table

## {{< fa code >}} Code

```{r}
#| label: sumcode

# 1. Create a object with the names of the variables you want to summarize
the_vars <- c("vaccine_skeptic01","pid","age")
# 2. Select these variables
nes16 %>%
  select(all_of(the_vars)) %>%
# 3. Pivot the data
  pivot_longer(
    cols = all_of(the_vars),
    names_to = "Variable"
  )%>%
  mutate(
    Variable = factor(Variable, levels = the_vars)
  )%>%
  arrange(Variable)%>%
  dplyr::group_by(Variable)%>%
  # 3. Calculate summary statistics
  dplyr::summarise(
    min = min(value, na.rm=T),
    p25 = quantile(value, na.rm=T, prob = 0.25),
    Median = quantile(value, na.rm=T, prob = 0.5),
    mean = mean(value, na.rm=T),
    p75 = quantile(value, na.rm=T, prob = 0.25),
    max = max(value, na.rm=T),
    missing = sum(is.na(value))
  ) -> sum_df 

sum_tab <- 
knitr::kable(sum_df,
             caption = "Descriptive Statistics",
             digits = 2) %>%
  kableExtra::kable_styling() %>%
  kableExtra::pack_rows("Outcome", start_row = 1, end_row =1) %>%
  kableExtra::pack_rows("Key Predictors", start_row = 2, end_row =2) %>%
  kableExtra::pack_rows("Covariates", start_row = 3, end_row =3)
```

## {{<fa table >}} Table

```{r}
#| label: sum_tab
#| echo: false
sum_tab
```

::::

## Progress Report {.smaller}

To explore these questions, we need to

- *Get setup to work* âœ…

- *Load our data* âœ…

- *Recode our data* âœ…

- *Summarize our data* âœ…

- **Specify our expectations** ðŸ“¥

- Estimate models to test these expectations

- Presenting and interpreting results using

  - Tables
  - Figures
  - Confidence intervals (review)
  - Hypothesis tests (new!)

## Specificying Expecations {.smaller}

:::{.nonincremental}

Consider our first two motivating questions

- How does partisanship shape American's perceptions of vaccines?

- Who is skeptical of the benefits of vaccination?

And some illustrative stereotypes:

- "Republicans are *anti-science*"
- "Liberal always fall for Goopy *pseudo-science*"
- "Independents love to *do their own research*"

What are the empirical implications of these claims?

:::

## Specificying Expecations {.smaller}

:::{.nonincremental}

Similarly, consider our third question:

- Have these perceptions about vaccines changed over time?

And some similar simplified claims:

- "The Covid-19 vaccine is a miracle of modern science"
- "Social media is rife with misinformation about the Covid-19 vaccine"
- "Politicians are politicizing vaccine politics for political benefits"

What are the empirical implications of these claims?

:::

## Specificying Expecations {.smaller}

Our goal is to take claims/conventional wisdom/theories, and derive their empirical implications:

- **H1: Partisan Differences in Vaccine Skepticism**
  - **H1a:** Republicans will be the most skeptical of vaccines
  - **H1b:** Democrats will be the most skeptical of vaccines
  - **H1c:** Independents will be the most skeptical of vaccines
  
## Specificying Expecations {.smaller}


- **H2: Temporal Differences in Vaccine Skepticism**
  - **H2a:** Vaccine skepticism will decrease from 2016 to 2020 with the widespread roll out of the Covid-19 vaccine
  - **H2b:** Vaccine skepticism will increase from 2016 to 2020 with increased amounts of misinformation about the Covid-19 vaccine
  
- **H3: Partisan Difference in Vaccine Skepticism Over Time** Partisan differences in Vaccine Skepticism will increase from 2016 to 2020 with the politicization of Covid-19 policies

## Motivating your expectations {.smaller}

In your final papers, unlike in these slides, your expectations should be grounded in existing theory, research, and evidence. For the present question, we might cite sources such as:

- Enders, Adam M., and Steven M. Smallpage. "Informational cues, partisan-motivated reasoning, and the manipulation of conspiracy beliefs." Political Communication 36.1 (2019): 83-102.

- Stecula, Dominik A., and Mark Pickup. "How populism and conservative media fuel conspiracy beliefs about COVID-19 and what it means for COVID-19 behaviors." Research & Politics 8.1 (2021): 2053168021993979.

- Jennings, Will, et al. "Lack of trust, conspiracy beliefs, and social media use predict COVID-19 vaccine hesitancy." Vaccines 9.6 (2021): 593.

- Hollander, Barry A. "Partisanship, individual differences, and news media exposure as predictors of conspiracy beliefs." Journalism & Mass Communication Quarterly 95.3 (2018): 691-713.

## Model Specification {.smaller}

Translate these expectations into empirical models requires choices about **how to specify our models**

- How should we measure/operationalize our outcome

  - Should we measure beliefs about vaccines with 7-point ordinal scale or as a binary indicator of vaccine skepticism

- How should we measure/operationalize our key predictor(s)

  - Should we measure partisanship using a 7 point scale or as categorical variable?

- What should we control for in our model?

  - Factors likely to predict both our outcome and our key predictor of interest

- There are rarely *definitive* answers to these questions. Instead, we will often estimate **multiple models** to try and show that our findings are **robust** to alternative specifications

## Model Specification {.smaller}

For your projects, every group will almost surely estimate some form of the following:

1.  Baseline bivariate model: The simplest test of the relationship between your outcome and key predictor

2.  Multiple regression model: A test of the robustness of this relationship, controlling for alternative explanations

## Model Specification {.smaller}

In practice, I suspect you may estimate multiple regression models such as:

- Alternative specifications/operationalizations of outcomes and predictors

- Interaction models to test conditional relationships

- Polynomial models to test non-linear relationships

## {.smaller}
#### Translating Theoretical Claims into Empirical Expectations

Before we estimate our models in R, we will write down our models formally and empirical implications of our theoretical expectations in terms of the coefficients of our model.

For example, our baseline model might be:

$$\text{Vaccine Skepticism} = \beta_0 + \beta_1 \text{PID}_{7pt} + X\beta + \epsilon$$ 

If $\beta_1$ is positive this is consistent with **H1a** (greater skepticism among Republicans), - If $\beta_2$ is negative this is consistent with **H1b** (greater skepticism among Democrats),

- But how could we test **H1c** -- greater skepticism among Independents, who are "4s" on $\text{PID}_{7pt}$?

## {.smaller}
#### Translating Theoretical Claims into Empirical Expectations

We could fit a polynomial regression, including both partisanship and "partissanship squared" to allow the relationship between partisanship and vaccine skepticism to vary non-linearly

$$\text{Vaccine Skepticism} = \beta_0 + \beta_1 \text{PID}_{7pt} +  \beta_2 \text{PID}_{7pt}^2+ X\beta+ \epsilon$$ 

## {.smaller}
#### Translating Theoretical Claims into Empirical Expectations

Or we could estimate a model treating Partisanship as a **categorical** variable rather than an **ordinal interval** variable. 

In our recoding, we set `"Democrat"` to be the first level of the variable `pid3cat`, so the model R will estimate by default is:

$$\text{Vaccine Skepticism} = \beta_0 + \beta_1 \text{PID}_{Ind} +  \beta_2 \text{PID}_{Rep}+ X\beta + \epsilon$$

## Testing differences over time {.smaller}

Testing Hypotheses 2 and 3 involve making comparisons across models estimated on data from different surveys.

Formally, testing these expectations is a little more complicated

- we could pool our two surveys together include an interaction term for survey year

For our purposes, we'll treat these as more qualitative/exploratory hypotheses:

- H2a/b implies overall rates of vaccine skepticism will be lower/higher in 2020 compared to 2016

- H3 implies that whatever partisan differences we find in 2016 should be larger in 2020.

## Progress Report {.smaller}

To explore these questions, we need to

- *Get setup to work* âœ…

- *Load our data* âœ…

- *Recode our data* âœ…

- *Specify our expectations* âœ…

- **Estimate models to test these expectations** ðŸ“¥

- Presenting and interpreting results using

  - Tables
  - Figures
  - Confidence intervals 
  - Hypothesis tests 


## Estimating Empirical Models 

Having derived empirical implications of our theoretical expectations expressed in terms of linear regressions, now we simply have to estimate our models in R.

When estimating the **same model** on **different datasets** we can write the formulas once

```{r}
#| label: formula
f1 <- formula(vaccine_skeptic01 ~ pid + age)
f2 <- formula(vaccine_skeptic01 ~ pid + I(pid^2) + age)
f3 <- formula(vaccine_skeptic01 ~ pid3cat + age)
```

## Estimating Empirical Models

And then pass it to `lm()` with different `data` arguments:

```{r}
#| label: models
m1_2016 <- lm(formula = f1, data = nes16)
m1_2020 <- lm(formula = f1, data = nes20)
m2_2016 <- lm(formula = f2, data = nes16)
m2_2020 <- lm(formula = f2, data = nes20)
m3_2016 <- lm(formula = f3, data = nes16)
m3_2020 <- lm(formula = f3, data = nes20)
```

## Estimating Empirical Models {.smaller}

:::{.nonincremental}

If you've:

- coded your data correctly

- developed clear testable implications from your theoretical expectations

Specifying and estimating empirical models is straightforward. Literally a few lines of code.

:::

## Progress Report {.smaller}

To explore these questions, we need to

- *Get setup to work* âœ…

- *Load our data* âœ…

- *Recode our data* âœ…

- *Specify our expectations* âœ…

- *Estimate models to test these expectations* âœ…

- *Present our results* ðŸ“¥

  - Tables
  - Figures
  - Confidence intervals 
  - Hypothesis testing

## Presenting and Interpreting Your Results {.smaller}

Presenting and interpreting your results is requires both art and science.

Your goal is to tell a story with your results,

Let's start by producing a regression table, which provides a concise summary of multiple regression models.


## Regression Tables {.smaller}

:::: panel-tabset

## Tasks

:::{.nonincremental}

- Giving the variables in substantive names

- Reporting coefficients to 3 decimal places

- Using a single significance threshold of $p < 0.05$

- Giving the models custom names

- Adding a header to group models by year

- Changing the caption of the table

:::

## {{< fa code >}} Code
```{r}
#| label: regtabs

# Basic
tab_basic <- texreg::htmlreg(
  list(m1_2016,m2_2016,m3_2016,
       m1_2020,m2_2020,m3_2020)
)

# Formatted
tab_fetch <- texreg::htmlreg(
  list(m1_2016,m2_2016,m3_2016,
       m1_2020,m2_2020,m3_2020),
  # Reporting coefficients to 3 decimal places
  digits = 3,
  # Using a single significance threshold 
  stars = 0.05,
  # Giving the variables in substantive names
  custom.coef.names = c(
    "(Intercept)",
    "PID (7pt)",
    "Age",
    "PID<sup>2</sup> (7pt)",
    "Independent",
    "Republican"
  ),
  # Use SE instead o CIs
  include.ci = F,
  # Giving the models custom names
  custom.model.names = paste("(",c(1:6),")", sep=""),
  # Adding a header to group models by year
  custom.header = list("NES 2016" = 1:3, "NES 2020" = 4:6),
  # Changing the caption of the table
  caption = "Partisanship and Vaccine Skepticism"
)
```

## {{< fa table >}} Basic

```{r}
#| label: tab_basic
#| echo: false
#| results: asis

tab_basic
```

## {{< fa table >}} Fetch

```{r}
#| label: tab_fetch
#| echo: false
#| results: asis


tab_fetch
```

::::

## Telling a Story with Regression {.smaller}

:::{.nonincremental}

First, provide an overview the models presented in the table

- Explain what each model is doing conceptually

Then start with your simplest model (first column)

- Use this as a chance to explain core concepts from the course
  - What is regression
  - How should I interpret a coefficient substantively
  - How should I interepret the statistical signficance of a give coefficient
- As you move from left to right (simple to more complex)
  - you need not interpret every single coefficient in the model
  - instead highlight the factors that are important for the reader to note (e.g. a comparison between one coefficient in model or another.)

:::

## Example {.smaller}

Table 1 presents the results of three specifications exploring the relationship between partisanship and vaccine skepticism using data from the 2016 (Models 1-3) and 2020 (Models 4-5) National Election Studies.

Models 1 and 4 operationalize partisanship as a 7-point scale, where 1 corresponds to Strong Democrats, 4 to Indepndents, and 7 to Strong Republicans in the 2016 (Model 1) and 2020 (Model 2) surveys.

Models 2 and 5 allow the relationship between partisanship and vaccine skepticism to vary non-linear again for the 2016 (Model 2) and 2020 (Model 5) elections.

Models 3 and 6 treat partisanship as categorical variable, describing how Independents and Republicans differ from Democrats, the reference category in these models.

All models control age, since (put in substantive justification for controlling for age here)

## Story: Testing for Partisan Differences {.smaller}

- The results from Model 1 provide little initial evidence for partisan differences in vaccine skepticism in the 2016 Election.

  - The coefficient on the partisanship variable is -0.005, suggesting that a unit increase in partisanship (going from being a Strong Democrat to just a Democrat, or an Independent to an independent who leans Republican), is associated with just a 0.5 percentage point increase in the probability of being a vaccine skeptic (believing that the risks of vaccination outweigh the benefits or that their is no difference in the risks versus benefits).

- Furthermore the 95-percent confidence interval for this estimate (-0.011, 0.002) brackets 0, suggesting the true population estimate from this model could be either positive or negative. Similarly, we fail to reject the null hypothesis that the true coefficient on partisanship in this model is 0 as the test statistic for this estimate ( -1.38) corresponds to a p-value of 0.168 suggesting that we would see test statistics this large or larger fairly often when the true relationship was 0.

- In sum, the results from Model 1 provide little support for any of the expectations described by *H1*

## Testing for Partisan Differences: Model 2 {.smaller}

- While coefficients from Model 1 suggest little evidence of partisan differences in vaccine skepticism, the coefficients on both partisanship, and partisanship squared are statistically significant (p < 0.05).

## Interpreting Model 2 {.smaller}

:::: panel-tabset

## Task

- The coefficients from polynomial regressions can be difficult to interpret jointly and so Figure 1 presents the predicted values from Model 2, holding age constant at its sample mean.

## {{< fa code >}}

```{r}
#| label: predm2
pred_df_m2 <- expand_grid(
  pid = 1:7,
  age = mean(nes16$age, na.rm=T)
)
pred_df_m2 <- cbind(pred_df_m2, predict(m2_2016,pred_df_m2, interval ="confidence"))

fig_m2 <- pred_df_m2 %>%
  ggplot(aes(pid, fit, ymin =lwr, ymax =upr))+
  geom_line()+
  geom_ribbon(alpha=.2, fill="grey")+
  theme_bw()+
  labs(x = "Partisanship",
       y = "Predicted Vaccine Skepticism",
       title = "Independents are the most skeptical of vaccines",
       subtitle = "Data: 2016 NES"
       )
```

## {{< fa chart-lines>}} Figure

```{r}
#| label: pred
fig_m2

```

## Interpretation

We see from Model 2 that 29.7 percent \[27.3%, 32.1%\] of Independents in the 2016 NES were predicted to be vaccine skeptics compared to 23.7 percent \[20.8%, 26.5%\] of Strong Democrats and only 20.1 percent \[16.9%, 23.3%\] of Strong Republicans.

::::

## Interpreting Model 3 {.smaller}

:::: panel-tabset

## Interpretation

Model 3 tells a similar story to model 2. Again, adjusting for differences in vaccine skepticism explained by age, Model 3 predicts that 41.7 percent \[37.7%, 45.6%\] of Independents in the 2016 NES are vaccine skeptics compared to 24.2 percent \[22.1%, 26.2%\] of Democrats, and 22.6 percent \[20.4%, 24.8%\] of Republicans.

Note the coefficients from Model 3 imply that the differences between Independents and Democrats are statistically significant ($\beta_{Ind} = 0.175, p < 0.05$), the differences between Republicans and Democrats are not ($\beta_{Rep} = -0.004, p = 0.31$)

## {{< fa code >}} Code

```{r}
pred_df_m3 <- expand_grid(
  pid3cat = c("Democrat", "Independent","Republican"),
  age = mean(nes16$age, na.rm=T)
)
pred_df_m3 <- cbind(pred_df_m3, predict(m3_2016,pred_df_m3, interval ="confidence"))
pred_df_m3
```

::::

## {.smaller}


```{r}
#| results: asis
tab_fetch
```


## Testing for Differences Over Time {.smaller}

The results for the 2016 NES suggest political independents are most skeptical of vaccines.

The results for 2020 suggest the relationship between partisanship and vaccine skepticism has changed overtime.

- The coefficient on partisanship in model 4 is now positive and statistically significant (p \< 0.05), suggesting that as respondents become more Republican, they are more likely to be skeptical of vaccines

- The coefficients from Model 5 suggest the relationship between partisanship skepticism is non linear, which is confirmed by model 6.

- In Model 6, we see that independents remain the most skeptical of vaccines in 2020 $(\beta = 0.20,\, p <0.05)$, but that Republicans now tend to be more skeptical of vaccines than Democrats $(\beta = 0.10,\, p <0.05)$