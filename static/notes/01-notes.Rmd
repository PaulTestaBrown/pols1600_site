---
title: "POLS 1600: Data and Measurement"
date:  " Updated `r format(Sys.time(), '%B %d, %Y')`"
always_allow_html: yes
output: 
    html_document:
        number_sections: no
        toc: yes
        toc_float: true
---


## Overview

\tableofcontents


```{r init, echo = F, results = F, message = F}
## Easy way to look for and install missing packages and load them
if (!require("pacman")){ install.packages("pacman") }
pacman::p_load("knitr", "tidyverse", "foreign", "noncensus","car")

## Set some default options R Markdown
opts_chunk$set(tidy = F, echo = TRUE, results = 'markup', strip.white = TRUE, cache = F, highlight = TRUE, width.cutoff = 132, size = 'footnotesize', message = FALSE, warning = TRUE, comment = NA)

# Default options in R
options(digits = 4, width = 100, scipen = 8)

```





# Principles of Data and Measurement

## A Survey of (former) Midwesterners

- Paul is a ~~32~~ ~~33~~ 34-year-old man, married, who  likes chocolate, and went to the 450th best school in the country for college
- Aleks is  a married woman who really likes chocolate, and went to the 15th best school
- David is 27-year-old man, unmarried, who refused to state his chocolate preferences, and went to the 17th best school.

**How should we structure this information?**

## How should we structure this information?

- How many observations/cases are there? \pause 3
- How many variables/attributes are there associated with each case? \pause Lets find out

## How should we structure this information?

\[
\overbrace{\color{purple}{Paul}}^{Name} \text{ is a } \overbrace{\color{orange}{32-year-old}}^{Age}  \overbrace{\ \color{green}{man}}^{Gender},  \overbrace{\color{blue}{married}}^{Marital\ Status}, \text{who }  \overbrace{\color{brown}{likes\ chocolate}}^{Candy}
\]
\[
\text{and went to the} \underbrace{\color{red}{450^{th}\ best\ school}}_{Go\ Big\ Red}\text{ in the country for college}
\]

\pause
Six possible attributes/variables

## Levels of Measurement: NOIR

- Categorical
    - Nominal (name, gender, married01)
    - Ordinal (strength of chocolate preference)
- Numerical
    - Interval (college ranking?)
    - Ratio (age)


## Organizing data into data frames

- In this class, we'll work with data in data frames, a special type of object in R, that allows you to have columns with data of different classes (e.g. character data in one column and numeric data in the next)
- Data frames are structured like $n\times m$ matrices where:
    - $n$ refers to the number of rows in the data frame with each row corresponding to an observation
    - $m$ refers to the number of columns with each column corresponding to a variable (characteristic)


## Example dataframe

```{r example_df, echo = F}
example.df <- data.frame(id = 1:3, 
                  name = c("Paul", "Aleks", "David"), 
                  gender = c("M", "F", "M"), 
                  age = c(30, NA, 27), 
                  married01 = c(1, 1, 0), 
                  chocolate = c("Likes", "Really Likes", NA), 
                  college = c(450, 15, 17))
```

```{r}
example.df
```



## What's the Unit of Analysis?

- A survey of 300 likely voters
- Statistics in the UN's Human Development Index
- Standardized test data from the state of Rhode Island


# Basic Data Analysis

## Overview

- Loading Data
- Quickly viewing data
- Recoding and cleaning data
- Aggregating and merging data
- Simple descriptive statistics and plots

## General remarks

- As is typical of R, there are generally numerous ways to accomplish what you want to do.
- Often, you'll do something with 20 lines of code at first, that you'll later simplify

## Loading Data

- For now, we'll download data from the web. In your lab you'll load data that you've downloaded to your desktops
- Some formats require different special functions to be read into R
- Today, let's keep working with the Police Shootings database from the *Washington Post*. Below we'll plug the following url into the url() function and send that to the read.csv() function:

"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/fatal-police-shootings-data.csv"

```{r}
# Load police data
pol <- read.csv(url("https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/fatal-police-shootings-data.csv"))

```


## Viewing data

First let's get a sense of the basic dimensions of this data set:

```{r}
dim(pol) # tell me the rows and columns
```

The dim function tell us there are `r dim(pol)[1]` shootings in the data set, and `r dim(pol)[2]` columns/variables

## Viewing the data

Now let's take a look at the first 6 rows (observations):
```{r}
# Shows you the first six rows
head(pol, 6)
tail(pol, n=10L)
```

## Viewing Specific Portions of the data

Use indexing ([]) + logical operators to select specific rows or columns

```{r}
pol[, 1:4]

```

## Viewing Specific Portions of the data

Use `filter()` plus a pipe `%>%`

```{r}
pol%>%
  filter(id < 19)
```


## Quickly summarizing the data

- table() function: very useful for categorical data
- summary() quickly provides summary of numerical distributions

```{r}
table(pol$manner_of_death)
summary(pol$age)
```


## Coding and Recoding Variables

1. Look at the raw variable
2. Copy to raw variable into a new variable with a meaningful name
3. Recode the new variable using logical indexing or functions
4. Compare the new and old variable 

## Recode body_camera

```{r}
#1. Look at the raw variable
table(pol$body_camera)


#2. Copy to raw variable into a new variable with a meaningful name
pol$bodycam01 <- as.character(pol$body_camera)
```

## Recode body_camera

```{r}
#3. Recode the new variable using logical indexing or functions
pol$bodycam01[pol$bodycam01 == "True"] <- 1
pol$bodycam01[pol$bodycam01 == "False"] <- 0
pol$bodycam01 <- as.numeric(pol$bodycam01)
#4. Compare the new and old variable 
with(pol, table(body_camera, bodycam01, useNA = "ifany"))
```

## Recode body_camera

```{r, eval = F}
mean(pol$body_camera)
pol$body_cameraTF <- pol$body_camera == "True"
pol$bodycam01 <- 0
pol$bodycam01[pol$body_camera == "True"] <- 1
pol$bodycam01[10:16]
```

## Create unarmed indicator using recode() function

```{r}
#install.packages(car)
library(car)
pol$unarmed01 <- recode(pol$armed, 
                      "'unarmed' = 1;else = 0")
```

## Create unarmed indicator using recode() function

```{r}
table(pol$unarmed01)
table(pol$armed)
# Check
sum(pol$armed != "unarmed")
sum(pol$armed == "unarmed")
```

## Create Female Indicator 

```{r}
pol$female01 <- ifelse(pol$gender == "F", 1, 0)
table(pol$female01, pol$gender)
```

## Create Age Quartiles

```{r}
age4q <- quantile(pol$age, na.rm = T)
age4q
```

## Create Age Quartiles

```{r}
pol$age_q[pol$age < age4q[2]] <- "Q1 (age < 27)"
pol$age_q[pol$age >= age4q[2] & pol$age<age4q[3]] <- "Q2 (27 <=  age <34)"
pol$age_q[pol$age >= age4q[3] & pol$age<age4q[4]] <- "Q3 (34 <=  age <45)"
pol$age_q[pol$age >= age4q[4]] <- "Q4 (age >= 45)"
table(pol$age_q)

```


## What state has the most shootings per capita?

\pause

1. Need to aggregate the data by state
2. Merge in information on state population
3. Create variable of shootings per capita (or per 100, 000 residents)


## Aggregating data dplyr

Basic idea is: 

1. Split the data by some grouping variable (e.g state)
2. Apply a function over each group (e.g. length() to count how many obs. are in each group)
3. Combine the data into an aggregate data set with each row corresponding to values for your grouping variable

## Aggregating data dplyr



## Aggregating data

```{r}
pol_states <- pol %>%
  group_by(state) %>%
  summarize(
   shootings = n(),
   age = mean(age, na.rm = T), 
   bodycam_pr = mean(bodycam01, na.rm = T), 
   min_pr = mean(race != "W", na.rm = T), 
   min_cnt = sum(race != "W", na.rm = T)
  )

```

## Aggregating data

```{r}
pol_states[1:3, ]
```

## Merging Data

- Basic idea is the have at least one (sometimes more) common variable in two data sets.
- Here we'll use the state variable to merge in data on state populations

## Merging Data

```{r}
install.packages("https://cran.r-project.org/src/contrib/Archive/noncensus/noncensus_0.1.tar.gz", repos=NULL, type="source")
# install.packages("noncensus")
library(noncensus)
data(states) # Dataset containing 2010 census data
pol_states <- merge(pol_states, states, by = "state")
pol_states[1:3, c("state", "shootings", "population")]
```


## Merging Data using join functions

```{r, echo=F}
# Recreate our pol_states dataset for a "fresh" merge.
pol_states <- pol %>%
  group_by(state) %>%
  summarize(
   shootings = n(),
   age = mean(age, na.rm = T), 
   bodycam_pr = mean(bodycam01, na.rm = T), 
   min_pr = mean(race != "W", na.rm = T), 
   min_cnt = sum(race != "W", na.rm = T)
  )
```

Same idea, slightly different syntax

```{r}
pol_states <- inner_join(pol_states, states, 
                         by = "state")
pol_states[1:3, c("state", "shootings", "population")]
```


## Shootings per 100, 000 residents

```{r}
# Turn character data into numeric
pol_states$population <- as.numeric(pol_states$population)
pol_states$shootings_pc <- pol_states$shootings/
    (pol_states$population/100000)
summary(pol_states$shootings_pc)

```


## Which states have the most and fewest police shootings per capita

```{r}
summary(pol_states$shootings_pc)
with(pol_states, state[which.max(shootings_pc)])
with(pol_states, state[which.min(shootings_pc)])
```


# Basic Descriptive Statistics

## Measures of Central Tendency

- mean
- median
- mode

## Mean
\[
\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i
\]

```{r}
# Mean
mean(pol$age, na.rm = T)
```

## Median

\[
M_x = X_i : \int_{-\infty}^{x_i} f_x(X)dx=\int_{x_i}^\infty f_x(X)dx=1/2
\]

- The value of the middle observation
- Robust to outliers

```{r}
# Median
median(pol$age, na.rm = T)
```

## Mean and Median

```{r,echo=F}
hist(pol$age)
abline(v=mean(pol$age,na.rm=T),col="blue")
abline(v=median(pol$age,na.rm=T),col="red")
```

## Median as rank stastics

```{r}
plot(sort(pol$age),col=ifelse(sort(pol$age)<=median(pol$age,na.rm=T),"red","black"),main="Median")
abline(h=median(pol$age,na.rm=T),col="red")

```

## Median as rank stastics

```{r}
plot(pol$age,col=ifelse(pol$age<=median(pol$age,na.rm=T),"red","black"))
```

## The p-th percentile

\[
p_x = X_i : \int_{-\infty}^{x_i} f_x(X)dx= p; \int_{x_i}^\infty f_x(X)dx=1-p
\]

- The value of the observation such that 100\*p percent of the data are to the left and 100-100\*p are two the right.
- The median is just the 50th percentile


## Mode

\[
m_x = X_i: n(X_i)> n(X_j) \forall j \neq i
\]

-The most frequently observed value in the data

```{r}
# Mode
sort(table(pol$armed), decreasing = T)[1]
```

## Ranges and Intervals

```{r}
# Min and max
#min(pol$age, na.rm = T);max(pol$age, na.rm = T)
range(pol$age, na.rm = T)
# 25 th and 75th percentiles
quantile(pol$age, na.rm = T, probs = c(.25, .75))
```

## Ranges and Intervals

```{r}
# 90 percent coverage interval
quantile(pol$age, c(.05, .95), na.rm = T)
mean(pol$age >= 19 & pol$age<= 60, na.rm = T)

```

## Measures of Dispersion

- Variance
- Standard Deviation
- Others...

## Sample variance

\[
\Var(X)=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2
\]

- Sum of squared deviations from the sample mean, divided by the number of observations minus 1
    - What happens as n grows?
    - Why n-1? (Has to do with fact that we're producing an estimate from our sample of a parameter in the population) 

## Standard deviation

\[
SD(X)=\sqrt{\Var(X)}=\sqrt{\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2}
\]

```{r}
# variance
var(pol$age, na.rm = T)
# Standared Deviatino
#sqrt(var(pol$age, na.rm = T))
sd(pol$age, na.rm = T)

```

# Basic Visualizations

## Histograrms

```{r}
hist(pol$age)
boxplot(age ~ body_camera, data=pol)
```

## Histograrms

```{r}
hist(pol_states$shootings_pc)
```

## Boxplots

```{r}
boxplot(pol_states$age)
```

## Boxplots

```{r}
boxplot(pol_states$shootings_pc)

```


## Scatterplots

```{r}
with(pol_states, plot(shootings_pc, min_pr, pch = NA))
with(pol_states, text(shootings_pc, min_pr, state))
```

## Body Cams

```{r}
with(pol_states, plot(bodycam_pr, min_pr, pch = NA))
with(pol_states, text(bodycam_pr, min_pr, state))
```
