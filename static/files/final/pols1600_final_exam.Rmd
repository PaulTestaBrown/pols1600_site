---
title: "POLS 1600 Take Home Final"
author: "YOUR NAME HERE"
date: 'DUE 11:59 pm, May 12, 2022 on Canvas'
output:
  html_document:
    theme: journal
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
    number_sections: TRUE
---

# Grade {-}



- Statistical Programming 
- Casual Inference (20 Points)
- Interpreting Linear Models (20 points)
- Quantifying Uncertainty through Statistical Inference (20 points)
- Conducting applied empirical analysis (30 points)



# Statistical Programming

## Write the name of a function that accomplishes each task (5 points)

- Transform a dataframe by adding new columns: `mutate()`

- Pipe the output of one function into another function: ` %>% `

- Estimate a linear regression model `lm()`

- Present a linear regression model as a formatted html regression table `texreg::htmlreg()`

- Subset a dataframe based on set of logical statements `filter(X == x)`




## To produce a graphic in R using the package `ggplot2` you need at least three components, what are they? (5 points)

- To create a figure in R using ggplot2 you need at a minimum:

  - a **data** set
  - from which which you map columns onto specific **aesthetics**
  - which are then presented given a specificed **geometry**

```{r, eval = F}
# Write pseudo code 

# Component 1
data %>% 
# Component 2
ggplot(aes(x=x, y=y))+
# Component 3
geom_point()

```



# Causal Inference (20 points)

## What is the fundamental problem of causal inference? (3 points)

-   The fundamental problem of causal inference is that we only observe one of potentially many potential outcomes. For example, if we wanted to know the effect of taking aspirin on my headache we would want to compare my headache status having taken aspirin to my headache status having not taken aspirin. The problem is we only observe one of these two potential outcomes. Thus causal effects at the level of individual units are unidentified.

## How does random assignment help solve this fundamental problem? (3 points)

- Random assignment ensures that treatment status $Z_i$ is independent of potential outcomes $(Y_i(1), Y_i(0))$, observed covariates $(X_i)$ and unobserved -- potentially confounding -- covariates $(U_i)$:

$$
Y_i(1), Y_i(0), X_i, U_i \perp Z_i
$$

Random assignment allows us to produce unbiased estimates of the *Average Treatment Effect*, using the observed differences in the average outcomes of groups assigned to treatment and control.

When treatment has been randomly assigned, what we can observe ( $E[Y_i|Z=0], E[Y_i|Z=1]$ ), provides good (unbiased) estimates of theoretical quantities we want observe

$$E[Y_i|Z=0] = E[Y_i(0)|Z=0] = E[Y_i(0)] = E[Y_i(0)|Z=1]$$

$$E[Y_i|Z=1] = E[Y_i(1)|Z=1] = E[Y_i(1)] = E[Y_i(1)|Z=0]$$

If we treatment as been randomly assigned, we can estimate the ATE by taking the difference of means between treatment and control:

$$\begin{align*}
E \left[ \frac{\sum_1^m Y_i}{m}-\frac{\sum_{m+1}^N Y_i}{N-m}\right]&=\overbrace{E \left[ \frac{\sum_1^m Y_i}{m}\right]}^{\substack{\text{Average outcome}\\
\text{among treated}\\ \text{units}}}
-\overbrace{E \left[\frac{\sum_{m+1}^N Y_i}{N-m}\right]}^{\substack{\text{Average outcome}\\
\text{among control}\\ \text{units}}}\\
&= E [Y_i(1)|D_i=1] -E[Y_i(0)|D_i=0]
\end{align*}$$

That is, the ATE is causally identified by the **difference of means** estimator in an experimental design

## What's the difference between an observational and experimental design? (2 points)

- **Experimental designs** are studies in which a causal variable of interest, the *treatement*, is manipulated by the researcher to examine its causal effects on some *outcome* of interest

- **Observational designs** are studies in which a causal variable of interest is assigned by someone other than the researcher (nature, governments, people)

Experimental design are often said to have high *internal validity*: if treatment has been randomly assigned we are confident that such designs credibly identify an average treatment effect. Experimental designs however can be criticized for lacking **external** or **ecological** validity. Observational designs, by contrast may require more assumptions to credibly identify causal effects (and thus may have weaker internal validity), but may possess higher **external** or **ecological** validity.

## Explain the concept of collider bias. How can avoid introducing collider bias into our analyses (2 points)

-  **Collider bias:** is bias we create when we condition on a *common consequence* of our outcome and predictor(s). Collider bias can come in many forms, but one classic example comes from debates about the gender wage gap between men and women in the U.S. If we estimated a simple regression model controlling only for gender, we would likely find an coefficient on gender suggesting women earn less than men. However if we also controlled for occupation, we risk introducing collider bias into our estimates, since gender discrimination may influence not only the wages men and women are paid but also the jobs for which they are hired. Assuming ability is correlated with both wages and jobs, controlling for occupation (but not ability) may introduce collider bias into our estimates of the gender wage gap.

Avoiding collider bias requires a strong theory. That is we need to think clearly about our causal model, and where variables fit in that model. One easy way to avoid collider bias in a experimetnal designs, is to avoid controlling for post-treatment covariates when estimating average treatment effects.


## What are three common designs for making credible causal claims with observational data? (10 points)


### Difference in Difference Designs

## Summary

- A Difference in Differences (DiD, or diff-in-diff) design combines a pre-post comparison, with a treated and control comparison
  
  - Taking the pre-post difference removes any fixed differences between the units
  
  - Then taking the difference between treated and control differences removes any common differences over time

- The key identifying assumption of a DiD design is the "assumption of parallel trends". This assumption implies that absent treatment, treated and control groups
would see the same changes over time. While this is hard to prove, we can assess it's credibility by comparing pre-treatment trends in the outcomes of treated and control groups.

### Regression Discontinuity Designs

- Regression discontinuity designs (RDD) leverages natural **discontinuities** in the probability of receiving treatment to estimate *local average treatment effects

  - Common discontinuities include: elections, test score cutoffs, time/events

  - A local average treatment effect means the effect applies only to a subset of observations, here those observations at or close to the cutoff.

- The identifying assumption of an RDD is continuity at the cutoff
  - This implies that observations just below the cutoff for receiving treatment provide reasonable counterfactuals to those just above the cutoff
  - We can't prove this, but we can test it's empirical implications for example by comparing covariate balance near the cutoff. We can also test the distribution of observations around the cutoff. If treatment is as-if random, the distribution should be "smooth" with departures suggesting some evidence that units are sorting around the cutoff to select into or out of treatment. 

### Instrumental Variables

Instrumental variables are designs used for dealing with **omitted variable bias**

- We have some non random treatment whose effects we'd like to assess
- We're worried that these effects are **confounded** by some unobserved, omitted variable, that influences both the treatment and the outcome
- We find an **instrumental variable** that satisfies the following:
  - Randomization
  - Excludability
  - First-stage relationship
  - Monotonicity
- Allowing us estimate a Local Average Treatment Effect (LATE) using the only the variation in our treatment is **exogenous** (uncorrelated with ommited variables)

- IV designs require and instrument that is exogenous and relevant. The exogeneity assumption (sometimes called the exclusion restriction) is difficult to prove and generally must be justified by appeals to theory (i.e. knowledge about the world that makes this claim credible). However the relevance criteria (first stage relationship) can generally be tested empirically (i.e. the instrument should have stasitically significant relationship with the causal effect of interest)

# Linear Models (20 points)

## What is a linear regression and why is it useful? (5 points)

  - Simple linear regression estimates a line of best fit that summarizes relationships between two variables

$$y_i = \beta_0 + \beta_1x_i + \epsilon_i $$

  - Multiple regression generalizes this approach to include multiple predictors
  
$$y_i = \beta_0 + \beta_1x_1 +  \beta_2 x_2 + \dots + \beta_j x_j + \epsilon_i $$
$$y_i = X\beta + \epsilon_i $$
- The coefficients in regression models tell us how the outcome $y$ is expected to change as some predictor, $x$ changes.

 - Linear regression chooses $\beta_0$ and $\beta_1$ to minimize the Sum of Squared Residuals (SSR): 

$$\textrm{Find }\hat{\beta_0},\,\hat{\beta_1} \text{ arg min}_{\beta_0, \beta_1} \sum (y_i-(\beta_0+\beta_1x_i))^2$$

  - Linear regression provides a **linear** estimate of the conditional expectation function (CEF): $E[Y|X]$. 

## What does it mean to control for a variable in a multiple regression? (5 points)

- Regression models "partition variance" They separate the variation in the outcome (the thing we're trying to explain), into variation explained by the predictors in our model and the remaining variation not explained by these predictors

- Coefficients in a linear regression describe the "marginal effect" of a change in a predictor on the outcome, after accounting for (holding constant/controlling) the other predictors in the model.

- Residualized regression provides a way of illustrating how multiple regression isolates the  variance explained by specific predictors (and only those predictors)

- Generally we want to control for covariates that are potential common causes of our key predictor and outcome of interest to address "omitted variable bias." We want to avoid controlling for common consequences that can introduce "collider bias."

## Interpreting regression models (10 points)

Suppose we are interested in understanding partisan differences in vaccination rates

Our outcome is a binary indicator which takes a value of 1 if someone was vaccinated, and 0 otherwise.

Our key predictor of interest is people's self-reported partisanship, measured with a 7-point scale where (1 = Strong Democrat, 2 = Democrat, 3 Independent who leans Democratic, 4 = Independent who leans Republican, 5 = Republican, and 7 = Strong Republican)

Please answer the following:

1.  Suppose we expect Democrats are more likely to be vaccinated.

-   Specify a bivariate model predicting vaccination status with partisanship, measured by a 7-point scale to test this expectation (ie fill in the ??? in the equation below):

$$\text{Vaccinated} = \beta_0 + \beta_1 \times \text{PID} + \epsilon$$

-    If your expectations are correct, what is the expected sign and significance of the coefficient on $\beta_1$ 

> We would expect the coefficient to be negative and statistically significant (e.g. p < 0.05)


-   How should we interpret $\beta_0$ in this model?

> Since partisanship is measured on a scale of 1-7, the intercept in this model is not substantively meaningful


2.  Suppose we find the expected relationship in our bivariate model. A skeptic sees your results and says:

    "You claim differences in vaccination rates are a function of partisanship, I think this is really just a matter of geography. Democrats are more likely to live in urban areas. Vaccines were more available in urban areas and the pandemic was more severe so people were more incentived to get the vaccine."

To address the skeptics concerns, you estimate a second model "controlling for geography" with a binary indicator of whether someone lives in a urban setting (`urban` = 1) or not (`urban` = 0)

-   Specify a multiple regression model predicting vaccination status with partisanship and an indicator of whether someone lives in a rural setting.

$$\text{Vaccinated} = \beta_0 + \beta_1 \times \text{PID} + \beta_2 \times \text{Urban} + \epsilon$$

-   Assuming there is some truth behind the skeptic claims, what is the expected sign and significance of the coefficient on urban status in this model?

> Positive and statistically significant (e.g. p < 0.05)


-   If the skeptic is right, and differences in vaccination rates are entirely a function of geography, what should happen to the sign and significance of the coefficient on partisanship in this model compared to the bivariate model?

> It should decrease in magnitude (e.g. get closer to 0) and no longer be statistically significant (e.g. p > 0.05)


-   If the skeptic is only partly right, and only part of the relationship between partisanship and vaccination is actually a function of geographic differences, what should happen to the sign and significance of the coefficient on partisanship in this model compared to the bivariate model?

> The coefficent on partisanship should decrease in magnitude compared to the bivariate model but remain negative and statistically significant.


-   If the skeptic is completely wrong, and geography has no relationship to vaccination rates, what should we expect in terms of the size and significance of the coefficient on rural status? How will the coefficient on partisanship in this model change?

> It should should be small in size and stasticall indistinguishable from 0.


# Statistical Inference (20 points)

## What is confidence interval? (10 points)

Please provide a one-two paragraph explanation of what a confidence interval is, how we construct confidence intervals, and how confidence intervals can be used to conduct statistical inference.

- Statistical inference involves quantifying uncertainty about what could have happened

- We can describe this uncertainty in terms of a sampling distribution (what could have happened had we had a different sample)

- The standard deviation of a sampling distribution describes its width (spread) and is called a standard error

- Standard errors decrease with by the $\sqrt{N}$ where $N$ is the size of our sample 

- We can estimate standard errors via simulation or analytically. 

  - Simulations require fewer assumptions, but take more time. 

  - Analytic estimates are are quick, but require more assumptions.

- We use standard errors to construct confidence intervals which we interpret as describing a range of plausible values for the thing we're trying to estimate.

- Any one 95% confidence interval may or may not contain the truth, but in repeated sampling, 95% of the intervals we construct would contain the truth.

## What is a hypothesis test? (10 points)

Please provide a one-two paragraph explanation of what a hypothesis test is, how we conduct hypothesis tests, and how hypothesis tests can be used to conduct statistical inference.

In your answer, please be sure to explain the following:

- A hypothesis test quantifies how likely it is that we would observe what we did (our test statistic), if some claim about the world were true (our hypothesis).

- Typically, we test a null hypothesis that expresses our belief that their is no relationship between variables.

  - $\tau = E[Y|Z=1] - E[Y|Z=0] = 0 \to$ No average treatment effect 
  - $\beta = 0 \to$ No relationship between predictor and outcome 

- If our claim were true, then under the null, our test statistic would have a distribution centered around the truth.

- We can describe this distribution via:

  - simulation (e.g. permuting the outcome)
  - analytic theory (CLT)

- We quantify our uncertainty using a p-value which describes the probability of observing a test statistic as extreme or more extreme in a world where our null hypothesis was true

  - If our p-value is small (p < 0.05), we reject the null hypothesis 

  - If our p-value is large (p > 0.05), we fail to reject the null, or retain the null hypothesis


# Applied Empirical Analysis (40 points)



## Formalize your question and expectations (5 Points),




## Look at and recode the data (5 points)


## Produce a table of descriptive statistics (10 points)

## Estimtate at least two models (5 points)


## Present and interperet your results (15 points)



