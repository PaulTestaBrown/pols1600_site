---
title: "Week 03:"
subtitle: "Casual Infrence in Experimental Designs"
author: "Paul Testa"
output:
  xaringan::moon_reader:
    css: ["default", "css/brown.css"]
    lib_dir: libs
    nature:
      highlightStyle: atelier-lakeside-light
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300,
  fig.align = "center", out.width = "80%", cache = TRUE)
library("tidyverse")
```

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
```

```{r xaringanExtra-clipboard, echo=FALSE}
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clipboard\"></i>",
    success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
  ),
  rmarkdown::html_dependency_font_awesome()
)
```



class: inverse, center, middle
# Overview

---
## General Plan

- Feedback
- Review
- Lecture consists of a mix of:
  - Topics and concepts
  - Exercises
- Summary

---
class: inverse, center, middle
background-image:url("https://m.media-amazon.com/images/I/51vs7dtZnZL._AC_.jpg")
background-size:contain

# Feedback

```{r, echo=F, message=F}
df <- haven::read_spss("../files/data/wk02.sav")
df <- df[-8,]
df %>%
  mutate(
    Likes = Q1,
    Dislikes = Q2,
    Streaming = Q3
  ) -> df
```

---
## What do we like

```{r, echo=F, out.height='80%'}
DT::datatable(df %>% 
                select(Likes),
              fillContainer = T,
              height = 1000
              )
```


--- 
## What do we dislike


```{r, echo=F, out.height='80%'}
DT::datatable(df %>% 
                select(Dislikes),
               fillContainer = T,
              height = 1000
              )
```

---
# What are we watching

.pull-left[

```{r, echo=F}
knitr::include_graphics("https://flxt.tmsimg.com/assets/p16805962_b_h9_aa.jpg")
```


]

.pull-right[
```{r, echo=F}
knitr::include_graphics("https://www.denofgeek.com/wp-content/uploads/2021/11/AOT_Original-KV_Logo_Copyright.jpg?resize=724,1024")
```
]

---
# What we say we're listening to?


.pull-left[

```{r, echo=FALSE}
knitr::include_graphics("https://assets.simpleviewinc.com/simpleview/image/fetch/c_limit,q_75,w_1200/https://assets.simpleviewinc.com/simpleview/image/upload/crm/desmoines/RKS_DVC_09042020-121-3-_DA0CDDDA-5056-A36A-0696A139DE8F91EE_da0ead9f-5056-a36a-0633632ae182c9c9.jpg")
```

]

.pull-right[
```{r,echo=FALSE}
knitr::include_graphics("https://www.euphoriazine.com/wp-content/uploads/2020/08/02-Galimatias-070-1598390291-scaled.jpg")
```
]

---
class: inverse
background-image:url(https://media.giphy.com/media/3o6gg2VslsUCY1rcLS/giphy.gif)
background-size:cover

# What we're actually listening to

---
# What we're streaming

```{r, echo=F, out.height='80%'}
DT::datatable(df %>% 
                select(Streaming),
              fillContainer = T,
              height = 1000
              )
```


---
## Review

- Set up
- Data wrangling
- Data visualization


---
## Setup

Every time you work in R

- Set your working directory

- Load, and if needed, install packages

- Maybe change some global options in your .Rmd file

---
## Setting your working directory:

- My default code for setting a working directory is:

```{r}
# Set working directory
wd <- "." # Change to file path on your computer
setwd(wd)
```

- This is really just a reminder to someone else using my code that they need to have their working directories set up correctly

- R Studio sets the working directory automatically, when you knit the file

- When I work on a file, I set the working directory manually



---
## Setting your working directory when working "Live"

```{r, echo=F}
knitr::include_graphics("https://statisticsglobe.com/wp-content/uploads/2020/03/figure-2-set-working-directory-to-source-file-location-manually.png")
```




---
## Packages for today


```{r packages, cache=F}
the_packages <- c(
  ## R Markdown
  "kableExtra","DT",
  
  ## Tidyverse
  "tidyverse", "lubridate", "forcats", 
  "haven", "labelled",
  
  ## Extensions for ggplot
  "ggmap","ggrepel", "ggridges", 
  "ggthemes", "ggpubr", "GGally",
  "dagitty", "ggdag", #<< New Packages
  
  # Data 
  "COVID19","maps","mapdata",
  "qss"
)
```

---
## Define a function to load (and if needed install) packages


```{r ipak}
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

```

---
## Load packages for today

```{r}
ipak(the_packages)
```


---
class:inverse, center, middle
# 💪
## Load the Covid-19 Data

---
## Load the Covid-19 Data

```{r covid}
covid <- COVID19::covid19(
  country = "US",
  level = 2,
  verbose = F
)
```


---
## Filter the Covid-19 Data to include Just US States

```{r covidus}
# Vector containing of US territories
territories <- c(
  "American Samoa",
  "Guam",
  "Northern Mariana Islands",
  "Puerto Rico",
  "Virgin Islands"
  )

# Filter out Territories and create state variable
covid_us <- covid %>%
  filter(!administrative_area_level_2 %in% territories)%>%
  mutate(
    state = administrative_area_level_2
  )
```


---
## Setting global options

- Lets you control the default behavior of R and R Markdown
  - Do you want to print warnings when you knit?
  - How big should your figures be
- I'll typically set these for you

---
## The global options for these slides



```{r, echo=T, eval=F}
options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE, 
  comment = NA, 
  dpi = 300, fig.align = "center", out.width = "80%", 
  cache = FALSE) # <<
```



---
## Data transformations


You want to:

- Load some data
- Look at your data
- Recode your data
- Transform your data

---
## Data transformations

.pull-left[
You want to:

- Load some data
- Combine multiple functions
- Look at your data
- Recode your data
- Transform your data
]

.pull-right[
You could use

- `read_*` functions
- `%>%` the "pipe" operator
- `glimpse()` `head()`, `filter()`, `select()`, `arrange()`
- `mutate()`, `case_when()`, `ifelse()`
- `summarize()`, `group_by()`

]


---
# 🔍
# Recoding categorical data in R

Let's clarify what's going on when we create the `face_masks` variable from the `facial_coverings` variable

- Why are we doing this
- What does `mutate()` do
- What does `case_when()` do
- What does `factor()` do

---
## Why are we doing this?

When we looked at the raw data, `facial_coverings` was a numeric variable with both positive and negative values

```{r}
table(covid_us$facial_coverings)
```

---
## Why are we doing this?

Substantively, the absolute value of these numeric values correspond to increasingly restrictive face mask policies:

- 0 - No policy
- 1 - Recommended
- 2 - Required in some specified shared/public spaces outside the home with other people present, or some situations when social distancing not possible
- 3 - Required in all shared/public spaces outside the home with other people present or all situations when social distancing not possible
- 4 - Required outside the home at all times regardless of location or presence of other people

With negative values denoting "best guesses" of the policy in effect for most people in a state
  - Example: Illinois is coded as a negative 4 when Chicago adopts a stringent face mask policy

---
## Why are we doing this?

- The numbers for these policies reflect an *ordinal* ranking:
  - No policy is less restrictive than Recommendations is less restrictive than requirements ...
- Beyond this ordering, the numbers themselves don't convey any additional meaning:
  - A partial requirement (2) is not "twice as restrictive" as a recommendation (1).
- How to treat statewide policies (positive numbers) vs mixed regimes (negative) is tricky
  - Ideally, we'd use more granular data (e.g. counties)
  - In practice, we'll collapse this distinction in our code
  - As social scientists, we'd then want explore how our results change using alternative coding rules
- By converting the numeric `facial_coverings` variable into the categorical, ordered factor `face_masks` we get a variable that:
  - Has meaningful labels
  - Retains the subtantive ordering of policies

---
## Creating the `face_masks` variable

Here's the snippet of code I've given you in the past:

```{r}
covid_us %>%
mutate(
    face_masks = case_when(
      facial_coverings == 0 ~ "No policy",
      abs(facial_coverings) == 1 ~ "Recommended",
      abs(facial_coverings) == 2 ~ "Some requirements",
      abs(facial_coverings) == 3 ~ "Required shared places",
      abs(facial_coverings) == 4 ~ "Required all times",
    ) %>% factor(.,
      levels = c("No policy","Recommended",
                 "Some requirements",
                 "Required shared places",
                 "Required all times")
    ) 
    ) -> covid_us
```

---
## Creating the `face_masks` variable

Here's a slightly clearer way of doing the same thing

```{r}
covid_us %>%
mutate(
  # Recode facial_coverings to create face_masks
    face_masks = case_when(
      facial_coverings == 0 ~ "No policy",
      abs(facial_coverings) == 1 ~ "Recommended",
      abs(facial_coverings) == 2 ~ "Some requirements",
      abs(facial_coverings) == 3 ~ "Required shared places",
      abs(facial_coverings) == 4 ~ "Required all times",
    ),
    # Turn face_masks into a factor with ordered policy levels
    face_masks = factor(face_masks,
      levels = c("No policy","Recommended",
                 "Some requirements",
                 "Required shared places",
                 "Required all times")
    ) 
    ) -> covid_us
```

---
## Understanding what `case_when()` does

Let's take a (pseudo) random slice of our data:

```{r}
set.seed(123)
covid_us %>%
  select(date, state, facial_coverings, face_masks)%>%
  slice(sample(1:dim(covid_us)[1], size=10, replace = F))
```

---
## Understanding all that other stuff did

.pull-left[
- `set.seed(123)` sets the "seed" that your computer uses to generate pseudo random numbers
- `select()` selects just the `date`, `state`, `facial_coverings`, and `face_masks` columns from the data
- `slice()` selects a slice of rows from the data
- `sample()` takes random sample from the sequence of numbers 1 to 40,889 (`dim(covid_us)`) of size 10, without replacement (no duplicates), which `slice()` interprets as the rows you want to select

]

.pull-right[

```{r, eval = F}
set.seed(123)
covid_us %>%
  select(date, state, facial_coverings, face_masks)%>%
  slice(sample(1:dim(covid_us)[1], size=10, replace = F))
```

]

---
## Data visualization

A basic graphic requires at minimum:

- `data:` the dataset containing the variables of interest.
- `aes`: aesthetic attributes of the geometric object. For example, x/y position, color, shape, and size. Aesthetic attributes are mapped to variables in the dataset.
- `geom:` the geometric object in question. This refers to the type of object we can observe in a plot For example: points, lines, and bars.

---
## Data visualization

Basic graphics are made even better with:

- `facets`
- `statistics`
- `coordinates`
- `themes`





---
## Topics

- Causal inference

- Notations to describe causal claims
  - Potential Outcomes
  - Directed Acyclic Graphs

- Causal Identification
  - Experimental designs (this week)
  - Observational designs (next week)

- Causal Identification in Experimental Designs
  - How random assignment creates credible counter factual comparisons


---
## Exercises

1. What kinds questions have causal interpretations?

2. Estimating an average treatment effect with the `resume` data

3. Exploring the data for Broockman and Kalla 2016



---
class: inverse, center, middle
# 💡
# Causal Inference
## *Causal claims imply counterfactual comparisons*

---
## Causal claims imply counterfactual comparisons

  
- Causal claims imply claims about counterfactuals
  - What would have happened if we were to change some aspect of the world?

--

- What's the counter factual for these claims:  
  - Foreign aid increases develop
  - Wikileaks cost Hillary Clinton the 2016 election
  - Democracies don't fight wars with other democracies
  - Universal Pre-K improves child development


---
## Casual claims are are all around us

.pull-left[
```{r, echo=F}
knitr::include_graphics("https://images-na.ssl-images-amazon.com/images/I/A1qhBebbu6L.jpg")
```

]

--

.pull-right[

```{r, echo=F}
knitr::include_graphics("https://press.uchicago.edu/.imaging/mte/ucp/medium/dam/ucp/books/jacket/978/02/26/11/9780226112374.jpg/jcr:content/9780226112374.jpg")
```


]

---
## Casual claims are are all around us

What are some questions that interest you?

What are the counterfactual comparisons they imply?




---
class: inverse, center, middle
# 💡
# Notations to describe causal claims

---

In this course, we will use two forms of notation to describe our causal claims.

- Directed Acyclic Graphs
- Potential Outcomes Notation

---
## Directed Acyclic Graphs

- Directed Acyclic Graphs provide a way of encoding assumptions about casual relationships
  - **Directed** Arrows $\to$ describe a direct causal effect ($Y_i(d) \neq Y_i(d^\prime)$)
  - No arrow = no effect ($Y_i(d) = Y_i(d^\prime)$)
  - **Acyclic:** No cycles. A variable can't cause itself
- Used by Pearl ([2009](http://bayes.cs.ucla.edu/jp_home.html), [2017](http://bayes.cs.ucla.edu/jp_home.html)) to describe and assess causal structural models


> Basically, they're math's fancy pants version of flow chart

---
## Why we use Directed Acyclic Graphs

- Directed Acyclic Graphs are flexible ways of representing complex relationships
- They're great for illustrating sources of potential bias in our models:
- Two types of bias we'll talk about today:
  - Confounder bias: Bias that exists because two variables have a common cause
  - Collider bias: Bias we create when we condition on a common consequence


---
## What do we mean by bias

We'll talk about lots of types of bias throughout this course.

Formally, we'll say an estimate, $\hat{\theta}$ (theta hat) is an unbiased estimator of a parameter, $\theta$ (theta) if:

\[
E[\hat{\theta}] = \theta
\]

Bias or error, $\epsilon$, is the difference between our estimate and the truth

\[
\epsilon = \hat{\theta} -\theta
\]

An estimator is unbiased if, on average, the errors equal 0

\[
E[\epsilon] = E[\hat{\theta} -\theta] = 0
\]

---
## The bias versus the variance of an estimate

```{r, echo=F}
knitr::include_graphics("https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/images/bias_variance/bullseye.png")
```

---
## The Bias-Variance Tradeoff

```{r,  echo=F}
knitr::include_graphics("http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png")
```

---
## Drawing DAGs in R

- Let's draw some dags to consider some simple examples:
  - Does drinking coffee cause lung cancer? (Confunding bias)
  - Does chicken pox cause influenza? (Collider bias)
- Nice examples of DAGs from [ggdag](https://ggdag.malco.io/index.html)


---
## Confounding = Common Causes

```{r, echo=F}
confounder_triangle(x = "Coffee", y = "Lung Cancer", z = "Smoking") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label")+
  theme_void()
  

```

---
## Controlling for a confounding variable

```{r, echo=F}

confounder_triangle(x = "Coffee", y = "Lung Cancer", z = "Smoking") %>% 
  ggdag_drelationship(controlling_for = "z",text = FALSE, use_labels = "label")+
  theme_void()

```

---
## Colliders = Common Consequence

```{r, echo=F}
fever_dag <- collider_triangle(x = "Influenza", 
                  y = "Chicken Pox", 
                  m = "Fever") 

ggdag(fever_dag, text = FALSE, use_labels = "label")+
  theme_void()
```

---
## Don't Condition on a Collider

```{r, echo=F}
ggdag_dseparated(fever_dag, text = FALSE, use_labels = "label")+
  theme_void()
```

---
## Don't Condition on a Collider

```{r, echo=F}
ggdag_dconnected(fever_dag, controlling_for = "m",text = FALSE, use_labels = "label")+
  theme_void()
```

---
## Potential Outcomes

- DAGs are great for representing a wide array of relationships
- Doing [causal inference with DAGs](https://mixtape.scunning.com/dag.html) is a bit beyond the scope of this class
- Instead, we'll typically talk about causal claims using the logic of potential outcomes to describe the counterfactual comparisons we want to make.
- Do this, we'll need to get comfortable with some basic notation.

---
## Some general notes on notation

- Notation can seem scary, overwhelming, confusing. 
- Notation can be incredibly helpful for communicating precisely and clearly
- Our goal is to demistify notation

---
## General Notation: Populations and Samples

- $U$: Population of units:
  - Finite population $U = {1,2,3,\dots,N}$
  - Infinite super population $U = {1,2,3,\dots,\infty}$
- $S$: sample of size $n$ from population $U$

---
## General Notation: Variables

- $Y_i$: Observed outcome from unit $i$
- $D_i$: An indicator for the receipt of treatment. $D_i$ = 1 if treated, $D_i$ = 0 if untreated,
  - Generalizes to multiple treatments
- $Z_i$: An indicator for the assignment of treatment. $Z_i$ = 1 if assigned to treatment, $Z_i$ = 0 if assigned to control,
- $X_i$ pre-treatment covariates.
- $U_i$ unobserved potential confounds

---
## General Notation: Expected Values

- The $E[Y]$ reads as "the expected value of Y" and is defined as a probability weighted average based on the uncoditional probability of Y ($f(y)$)

$$
\operatorname{E}[Y] = \int_{-\infty}^\infty y f(y)\, dy.
$$

The $E[Y|X=x]$ reads as "the expected value of Y conditional on the value of X" and is defined as a probability weighted average of Y based on the conditional probability of Y given X ($y f_{Y|X}(y|x)$)

$$
\operatorname{E} (Y | X=x) =  \int_{-\infty}^\infty y f_{Y|X}(y|x) \mathrm{d}y
$$

---
## General Notation: Expected Values

- Don't worry about the math in this course.
- We'll talk more expected values during our discussion of probability
- For now, just think of $E[Y]$ and $E[Y|X=x]$ as a theoretical averages which we can estimate from the empirical means in our data (`mean(data$y)`, `mean(data$y[data$x == 1]`))

---
## Potential Outcomes Notation:

- Potentiall outcomes notation is a way of describing counterfactuals
- $Y_i(d)$ is the value of the outcome if $D_i$ was $d$
  - $Y_i(1)$ is the vote share of Rep. Smith when they support \#MeToo
  - $Y_i(0)$ is the vote share of Rep. Smith when they do not support \#MeToo.
- Potential outcomes are fixed, but we only observe one (of many) potential outcomes $\to$ *Fundamental Problem of Causal Infernece*

---
## *Fundamental Problem of Causal Infernece*

The individual causal effect $\tau_i$ of some treatment $d_i$ on some observation $i$ is 

\[
\tau_i \equiv Y_i(1) - Y_i(0)
\]

- The **fundamental problem of causal inference** is that we only ever see one potential outcome for an individual, and so it's **impossible to know** the causal effect of some intervention for that individual

- The ICE is unidentified

---
class: inverse, center, middle
# 💡
# Causal Identification
## *What assumptions do we need to make for a causal claim to be credible*

---
## Identification

- Identification refers to what we can learn from the data available


- A quantity of interest is *identified* if, with infinite data it can only take one value

- Mathematically, we'll sometimes say a coefficient in a an equation is unidentified if we have more predictors than observations, or some of predictors are really just linear transformations of other predictors.

---
## Causal Identification

- **Casual Identification** refers to "the assumptions needed for statistical estimates to be given a causal interpretation" [Keele (2015)](http://lukekeele.com/wp-content/uploads/2016/03/causal.pdf)

- **What's  Your Casual Identification Strategy:** What are the assumptions that make your research design credible?

- Identification > Estimation

---
## Observational vs Experimental Designs

- **Experimental designs** are studies in which a causal variable of interest, the *treatement*, is manipulated by the researcher to examine its causal effects on some *outcome* of interest
- **Observational designs** are studies in which a causal variable of interest is assigned by someone other than the researcher (nature, governments, people)


---
class: inverse, center, middle
# 💡
# Causal Identification in Experimental Designs

---
## The FPoCI is a problem of missing data

That an individual causal effect $\tau_i$, is defined as:

\[
\tau_i \equiv Y_i(1) - Y_i(0)
\]

The problem is that for any one individual, we only observe $Y_i(1)$  or $Y_i(0)$, but never both.



---
## A statistical solution to the FPoCI
    
Rather than individual causal effects:

\[
\tau_i \equiv Y_i(1) - Y_i(0)
\]

Focus on average causal effects

- \[
E[\tau_i] = \overbrace{E[Y_i(1) - Y_i(0)]}^{\text{Average of a difference}} = \overbrace{E[Y_i(1)] - E[Y_i(0)]}^{\text{Difference of Averages}}
\]

When does the difference of averages provide us with a good estimate of the average difference?

---
## The hospital example

```{r}
knitr::include_graphics("https://i.pinimg.com/originals/1d/1e/dd/1d1eddaa79918e9cca7e7dc857d95ffe.jpg")
```


## The hospital example

Want to know the effect of going to the hospital on people need to go to the hospital

\[
\text{What we want} = E[Y(1|D=1) - Y(0|D=1)]
\]

\[
\text{What we want} = E[\text{Mortality}(\text{Hospital}|\text{Sick}) - \text{Mortality}(\text{No Hospital}|\text{Sick})]
\]

## The hospital example


Instead we might end up comparing outcomes among the sick and non-sick

\[
\text{What we estimate} = E[Y(1|D=1)] - E[Y(0|D=0)]
\]

\[
\text{What we estimate} = E[\text{Mortality}(\text{Hospital})] - E[\text{Mortality}(\text{No Hospital})]
\]

## Selection bias

The hospital example illustrates the general problem of selection bias

\[
\widehat{SATE}=\overbrace{\textbf{E[Y(1)|D=1]} - E[Y(0)|D=1]}^{\text{Average Effect of Treatment on Treated}}\\
\underbrace{+ E[Y(0)|D=1]- \textbf{E[Y(0)|D=0]}}_{\text{Selection Bias}}
\]

- When is selection bias 0? 
    - When E[Y(0)|D=1] = E[Y(0)|D=0]
- When does, E[Y(0)|D=1] = {E[Y(0)|D=0]? 
    - If D has been randomly assigned

---
## Random Assignment "Solves" the Problem of Selection Bias

Randomly assigning treatments creates *statistical independence* between treatment ($D$) and potential outcomes ($Y(1),Y(0)$) as well as any observed ($X$) or unobserved confounders ($U$):

\[
Y_i(1),Y_i(0),\mathbf{X_i},\mathbf{U_i} \unicode{x2AEB} D_i
\]

---
## Random Assignment "Solves" the Problem of Selection Bias

When treatment has been randomly assigned, what we can observe ($E[Y_i|D=0], E[Y_i|D=1]$), provides good (unbiased) estimates of theoretical quantities we want observe

\[
E[Y_i|D=0] = E[Y_i(0)|D=0] = E[Y_i(0)] = E[Y_i(0)|D=1]
\]
\[
E[Y_i|D=1] = E[Y_i(1)|D=1] = E[Y_i(1)] = E[Y_i(1)|D=0]
\]

---
## Estimating an Average Treatment Effect

If we treatment as been randomly assigned, we can estimate the ATE by taking the difference of means between treatment and control:

\[
\begin{align*}
E \left[ \frac{\sum_1^m Y_i}{m}-\frac{\sum_{m+1}^N Y_i}{N-m}\right]&=\overbrace{E \left[ \frac{\sum_1^m Y_i}{m}\right]}^{\substack{\text{Average outcome}\\
\text{among treated}\\ \text{units}}}
-\overbrace{E \left[\frac{\sum_{m+1}^N Y_i}{N-m}\right]}^{\substack{\text{Average outcome}\\
\text{among control}\\ \text{units}}}\\
&= E [Y_i(1)|D_i=1] -E[Y_i(0)|D_i=0]
\end{align*}
\]

That is, the ATE is causally identified by the difference of means estimator in an experimental design

---
## Causal Identification with Experimental Designs

Causal identification for an experiment, requires very few assumptions:

- **Independence** (Satisfied by Randomization)
  - $Y(1), Y(0),X,U, \perp D$
- **SUTVA** Stable Unit Treatment Value Assumption (Depends on features of the design)
  - No interference between units $Y_i(d_1, d_2, \dots, d_N) = Y_i(d_i)$
  - No hidden values of the treatment/Variation in the treatment 


---
## Random Assignment creates testable implications

- If treatment has been randomly assigned, we would expect that there should be few differences between **pre-treatment covariates** in our treatment and control groups.

- That is, on average, the only the thing that should differ between these groups is that one group got the treatment and one group did not.

- If the treatment had an effect, than we can credibly claim that that effect was due to the presence or absence of the treatment, and not some alternative explanation.

- This type of clean counterfactual comparison is what people mean when they talk about an *experimental ideal*

## No Causation without Manipulation?

- "No causation without manipulation" - [Holland (1986)](https://www.jstor.org/stable/2289064)
- Causal effects are well defined when we can imagine manipulating (changing) the value of $D_i$ and only $D_i$
- But what about the "effects" of things like:
  - Race
  - Sex
  - Democracy
- Studying the effects of these factors requires strong theory and clever design [Sen and Wasow (2016)](https://scholar.harvard.edu/files/msen/files/race_causality.pdf)




---
class: inverse, center, middle
# 💪  
# Estimating an average treatment effect with the `resume` data

---
## The Resume Experiment (p. 33)

Let's take a look at the resume experiment from your text book and compare some of Imai's code to its `tidyverse` equivalent

```{r}
# make sure qss package is loaded
library(qss)
data("resume")
```

---
## High level Overview (p. 34)

```{r}
dim(resume)
head(resume)
```

---
## High level Overview (p. 34)

```{r}
summary(resume)
```


---
## Cross Tabs

```{r}
race.call.tab <- table(race = resume$race,
                       call = resume$call)
race.call.tab
addmargins(race.call.tab)

```

---
## Tidy cross tab

```{r}
resume %>%
  group_by(race, call)%>%
  summarise(
    n = n()
  )%>%
  pivot_wider(names_from = call, values_from = n)
```

---
## Calculating Call Back Rates

```{r}
# Overall
sum(race.call.tab[,2])/nrow(resume)

# Black names
cb_bl <- sum(race.call.tab[1,2])/sum(race.call.tab[1,])
# White Names
cb_wh <- sum(race.call.tab[2,2])/sum(race.call.tab[2,])

# ATE
cb_wh - cb_bl


```

---
## Calculating Call Back Rates with group_by()

```{r}
resume %>%
  group_by(race)%>%
  summarise(
    call_back = mean(call)
  )
```




---
## Factor variables in Base R

```{r}
resume$type <- NA
resume$type[resume$race == "black" & resume$sex == "female"] <- "BlackFemale"
resume$type[resume$race == "black" & resume$sex == "male"] <- "BlackMale"
resume$type[resume$race == "white" & resume$sex == "female"] <- "WhiteFemale"
resume$type[resume$race == "white" & resume$sex == "male"] <- "WhiteMale"

```

---
## Factor variables in Tidy R

```{r}
resume %>%
  mutate(
    type_tidy = case_when(
      race == "black" & sex == "female" ~ "BlackFemale",
      race == "black" & sex == "male" ~ "BlackMale",
      race == "white" & sex == "female" ~ "WhiteFemale",
      race == "white" & sex == "male" ~ "WhiteMale"
    )
  ) -> resume
```

---
## Comparing approaches

```{r}
table(base= resume$type, tidy= resume$type_tidy)
```



---
## Visualizing Call Back Rates by Name

```{r, eval = F}
resume %>%
  group_by(race, sex,firstname)%>%
  summarize(
    Y = mean(call),
    n = n()
  )%>%
  arrange(desc(Y)) %>%
  mutate(
    firstname = forcats::fct_reorder(firstname,Y)
  )%>%
  ggplot(aes(Y, firstname,col=race, size=n))+
  geom_point() + 
  facet_grid(sex~.,scales = "free_y")
```


---
## Visualizing Call Back Rates by Name


```{r, echo = F}
resume %>%
  group_by(race, sex,firstname)%>%
  summarize(
    Y = mean(call),
    n = n()
  )%>%
  arrange(desc(Y)) %>%
  mutate(
    firstname = forcats::fct_reorder(firstname,Y)
  )%>%
  ggplot(aes(Y, firstname,col=race, size=n))+
  geom_point() + 
  facet_grid(sex~.,scales = "free_y")
```


---
class:inverse, center, middle
# 💪  
# Exploring the data for Broockman and Kalla 2016

---
# Reading Academic Papers

- Reading academic papers is a skill and takes practice. 
- You should aim to answer the following:
  - What's the research question?
  - What's the theoretical framework?
  - What's the empirical design?
  - What's are the main results?

---
## Broockman and Kalla (2016)

- What's the research question?
- What's the theoretical framework?
- What's the empirical design?
- What's are the main results?


---
## Study Design :A placebo-controlled field experiment

1. Recruited from voter files to complete a baseline survey
2. Among those who complete the survey, half are assigned to receive an intervention  and half are assigned to receive a placebo 
3. Only some are actually home or open the door when the canvassers knock. 
4. These people are then recruited to participate in a series of surveys 3 days, 3 weeks, 6 weeks, and 3 months after the initial intervention.

---
## Data for Thursday

Let's load the data from the orginal study

```{r}
load(url("https://pols1600.paultesta.org/files/data/03_lab.rda"))
```



---
## Codebook

- `completed_baseline` whether someone completed the baseline survey ("Survey") or not ("No Survey")
- `treatment_assigned` what intervention someone who completed the baseline survey was assigned two (treatment= "Trans-Equality", placebo = "Recycling")
- `answered_door` whether someone answered the door ("Yes") or not ("No") when a canvasser came to their door
- `treatment_group` the treatment assignments of those who answered the door (treatment= "Trans-Equality", placebo = "Recycling")
- `vf_age` the age of the person in years
- `vf_female` the respondent's sex (female = 1, male = 0)
- `vf_democrat` whether the person was a registered Democract (Democrat=1, 0 otherwise)
- `vf_white` whether the person was white (White=1, 0 otherwise)
- `vf_vg_12` whether the person voted in the 2012 general election (voted = 1, 0 otherwise)


---
## HLO

```{r}
glimpse(df)
```


---
## Study Design

```{r}
table(df$completed_baseline)
table(df$treatment_assigned)
table(df$answered_door)
table(df$treatment_group)

```



---
## Assessing balance in covariates

```{r}
df %>%
  filter(completed_baseline == "Survey") %>%
  select(treatment_assigned,starts_with("vf_"))%>%
  group_by(treatment_assigned)%>%
  summarise(across(starts_with("vf_"), mean))->pretreatment_balance

```

---
## Assessing balance in covariates

```{r}
pretreatment_balance
```

---
## Assessing balance in covariates

```{r}
pretreatment_balance %>%
  gather(.,key = covariate, value = value, -treatment_assigned) %>%
  spread(treatment_assigned, value) %>%
  mutate(
    Difference = `Trans-Equality` - Recycling
  )

```


