{
  "hash": "91bb62c67d3136a0095dda2def3a0d56",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Comments for Lab 09 - Exploring Russians' Attitudes About the War in Ukraine with OLS and Logistic Regression\"\nauthor: \"Your Group Members Names Here\"\ndate: \"Last Updated 2024-01-24\"\nformat:\n  html:\n    toc: true\n    toc-location: left\n    toc-float: true\n    toc-depth: 2\n    number-sections: true\n---\n\n\n\n\n# Overview {.unnumbered}\n\nToday, we will return to exploring Russians' support the war in Ukraine using a public opinion survey from Russia conducted by Alexei Miniailo's [\"Do Russians Want War\"](https://www.dorussianswantwar.com/en) project.\n\nThe survey was conducted by phone using a random sample of mobile phone numbers to produce a sample of respondents representative of the population in terms of age, sex, and geography. It was in the field from February 28 to March 2.\n\nFirst, we will explore how support for the war varies with the demographic predictors `age`, `sex` and `education`. We will compare the results of modeling this relationship using **Ordinary Least Squares** regression and **Logisitic Regression**\n\nWe'll talk more about the [technical aspects](https://pols1600.paultesta.org/slides/09-slides.html#116){target=\"_blank\"} of logistic regression next week. For today we'll simply compare the results from these two approaches.\n\nNext, we will gain insight into how our estimates from these models might vary using the statistical process of **bootstrapping**. Specifically, we will simulate the idea of **repeated sampling** that is the foundation of frequentist interpretations of probability, by sampling from our sample **with replacement**.\n\nWe'll walk through the mechanics of simulation together. Then you'll quantify the uncertainty described by these bootstrapped sampling distributions.\n\nFinally, we'll see what other questions we might ask of these data and practice various skills we've developed through out the course.\n\nPlan to spend the following amount of time on each section\n\n1.  Get set up to work (5 minutes)\n\n2.  Model the relationship between demographic predictors and war support using OLS and Logistic regression (20 minutes)\n\n3.  Assess the uncertainty around your estimated coefficients (15 minutes)\n\n4.  Quantify the uncertainty described by your sampling distributions (10 minutes)\n\n5.  Explore other relationships in the data. (30 minutes)\n\nThe graded question for today is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(472022)\ngraded_question <- sample(1:5,size = 1)\npaste(\"Question\",graded_question,\"is the graded question for this week\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Question 5 is the graded question for this week\"\n```\n\n\n:::\n:::\n\n\nYou will work in your assigned groups. Only one member of each group needs to submit the html file produced by knitting the lab.\n\nThis lab **must** contain the names of the group members in attendance.\n\nIf you are attending remotely, you will submit your labs individually.\n\nYou can find your assigned groups in previous [labs](https://pols1600.paultesta.org/labs/06-lab-comments.html){target=\"_blank\"}\n\n# Goals {.unnumbered}\n\nToday's lab covers a little bit of everything. You will\n\n-   learn how to model binary outcomes using logistic regression\n\n-   develop an intuition for how to think about uncertainty using simulations to describe what might have happened\n\n-   practice formulating, estimating, presenting and interpreting regression models.\n\n# Workflow {.unnumbered}\n\n# Please knit this .Rmd file {.unnumbered}\n\nAs with every lab, you should:\n\n-   Download the file\n-   Save it in your course folder\n-   **Update the `author:` section of the YAML header to include the names of your group members in attendance.**\n-   Knit the document\n-   Open the html file in your browser (Easier to read)\n-   Write yourcode in the chunks provided\n-   Comment out or delete any test code you do not need\n-   **Knit the document again after completing a section or chunk** (Error checking)\n-   Upload the final lab to [Canvas](https://canvas.brown.edu/courses/1087979/assignments/7870531?module_item_id=10762404){target=\"_blank\"}.\n\n# Get setup to work\n\n## Load Packages\n\nFirst lets load the libraries we'll need for today.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_packages <- c(\n  ## R Markdown\n  \"kableExtra\",\"DT\",\"texreg\",\"htmltools\",\n  \"flair\", # Comments only\n  ## Tidyverse\n  \"tidyverse\", \"lubridate\", \"forcats\", \"haven\", \"labelled\",\n  \"modelr\", \"purrr\",\n  ## Extensions for ggplot\n  \"ggmap\",\"ggrepel\", \"ggridges\", \"ggthemes\", \"ggpubr\", \n  \"GGally\", \"scales\", \"dagitty\", \"ggdag\", \"ggforce\",\n  # Data \n  \"COVID19\",\"maps\",\"mapdata\",\"qss\",\"tidycensus\", \"dataverse\",\n  # Analysis\n  \"DeclareDesign\", \"boot\"\n)\n\n# Define function to load packages\nipak <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n\nipak(the_packages)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in contrib.url(repos, \"source\"): trying to use CRAN without setting a mirror\n```\n\n\n:::\n:::\n\n\nThere are three packages in particular that we'll need to maker sure are installed and loaded\n\n-   `modelr`\n-   `purrr`\n-   `broom`\n\nIf `ipak` didn't return `TRUE` for each of these, please uncomment and run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"modelr\")\n# install.packages(\"purrr\")\n# install.packages(\"broom\")\n```\n:::\n\n\n## Load the data\n\nNext we'll load the recoded data for the lab\n\nOur primary outcome of interest (dependent variable) for today is a binary measure of support for war:\n\n-   `support_war01` \"Please tell me, do you support or do not support Russia's military actions on the territory of Ukraine?\" (1=yes, 0 = no)\n\nOur key predictors (independent variables) are the following demographic variables:\n\n-   `age` \"How old are you?\"\n\n-   `sex` \"Gender of respondent\" (As assessed by the interviewer)\n\n-   `education_n` \"What is your highest level of education (confirmed by a diploma, certificate)?\" (1 = Primary school, 2 = \"High School\", 3 = \"Vocational School\" 4 = \"College\", 5 = Graduate Degree)[^1]\n\n[^1]: I think, google translate was a bit unclear. But higher numbers equal more education.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(url(\"https://pols1600.paultesta.org/files/data/df_drww.rda\"))\n\ndf_drww %>%\n  mutate(\n    person_id = 1:n()\n  ) -> df_drww\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in df_drww %>% mutate(person_id = 1:n()): could not find function \"%>%\"\n```\n\n\n:::\n:::\n\n\n# Model the relationship between demographic predictors and war support using OLS and Logistic regression.\n\n## Fit the models\n\nPlease estimate the following models:\n\n-   An OLS regression model called `m1` using `lm()`\n-   A Logistic regression model called `m2` using `glm()` with `family=binomial`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# OLS\nm1 <- lm(support_war01 ~ age + sex + education_n, df_drww)\n\n# Logisitic \nm2 <- glm(support_war01 ~ age + sex + education_n, df_drww,\n          family = binomial)\n```\n:::\n\n\n## Display the results in a regression table\n\nNext, please display the results of your regressions in a table using `htmlreg()`\n\n\n\n```{.r .cell-code}\n# Regression Table\nhtmlreg(list(m1,m2))\n```\n\n```\nError in htmlreg(list(m1, m2)): could not find function \"htmlreg\"\n```\n\n\n## Produce predicted values from the model\n\nThe coefficients from a logistic regression aren't easy to directly interpret.\n\nInstead, we will produce predicted values for each model\n\nTo do this, we will need to create a **prediction dataframe** called `pred_df` Every variable in your model, needs to be represented in your prediction data frame.\n\n-   Use `expand_grid()` to create a data frame where\n\n    -   `age` varies from 18 to 99\n    -   `sex` is held constant at \"Female\"\n    -   `education_n` is held constant at it's mean\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Create prediction data frame\npred_df <- expand_grid(\n  age = 18 : 99,\n  sex = \"Female\",\n  education_n = mean(df_drww$education_n, na.rm = T)\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in expand_grid(age = 18:99, sex = \"Female\", education_n = mean(df_drww$education_n, : could not find function \"expand_grid\"\n```\n\n\n:::\n:::\n\n\nThen you use the `predict()` function to produce predicted values from each model.\n\nSave the output of `predict()` for `m1` to a new column in pred_df called `pred_ols`.\n\nFor `m2` you need to tell are to transform the predictions from `m2` back into the units of the **response** (outcome) variable, by setting the argument `type = \"response\"`. Save the output of `predict()` for `m1` to a new column in pred_df called `pred_logit`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# #Predicted values for m1\npred_df$pred_ols <- predict(m1,\n                            newdata = pred_df)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'pred_df' not found\n```\n\n\n:::\n\n```{.r .cell-code}\n# Predicted values for m2\n# Remember to add type = \"response\"\npred_df$pred_logit <- predict(m2,\n                            newdata = pred_df,\n                            type = \"response\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'pred_df' not found\n```\n\n\n:::\n:::\n\n\n## Plot the predicted values and interpet the results\n\nNow we can compare the predictions of OLS and Logistic regression by plotting the predicted values of support for the war from each model.\n\nTo produce this plot you'll need to\n\n-   specify `data` (you want to use the values from `pred_df`)\n-   map values from your data `aes`thetics in `ggplot`\n    -   put `age` on the x axis and and `pred_ols` on the y-axis\n-   specify the `geom`etries to plot\n    -   add *two* `geom_line()` to the plot\n    -   leave the first one empty (e.g. `geom_line()`)\n    -   for the second, specify a new `aes` of `y=pred_logit`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data\npred_df%>%\n  # aesthetics\n  ggplot(aes(age, pred_ols, col = \"OLS\"))+\n  # geometries\n  geom_line()+\n  geom_line(aes(y = pred_logit, col = \"Logistic\"))+\n  geom_jitter(data=df_drww, aes(age, support_war01),\n              col = \"black\",\n              height = .05,\n              size = .5,\n              alpha = .5)+\n  labs(\n    col = \"Model\",\n    x = \"Age\",\n    y = \"Predicted Values\"\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in pred_df %>% ggplot(aes(age, pred_ols, col = \"OLS\")): could not find function \"%>%\"\n```\n\n\n:::\n:::\n\n\n**How do the predictions of the two models compare**\n\nSo the predictions from OLS produce impossible values (levels of support above 100 percent) at for very old respondents, while the predictions from logistic regression are constrained to be between 0 and 1.\n\nIf we think that logistic regression provides a more credible way of modeling support for the war, then our OLS regression appears to overstate the level of support among young and old, while possibly understating the level of support among the middle age. The differences aren't huge -- a few percentage points -- but for a binary outcome we will often prefer to model it with logistic regression.\n\nAlso note that marginal effect for age in the logistic regression is not constant. An increase in age from 25 to 26 is associated with a larger increase in support, than an increase in age from 75 to 76.\n\n------------------------------------------------------------------------\n\n# Assess the uncertainty around your estimated coefficients\n\nHow confident are we that the true relationship between age and support for the war is positive? How different might the coefficient be if we had taken a different random sample of Russians in early March 2022?\n\nIn this section, we will explore how we can simulate the idea \"repeated\" sampling using just the sample we have to quantify uncertainty about the estimates in our model.\n\nTo do this we will.\n\n1.  Take 1,000 *bootstrap* samples from `df_drww` **with replacement** using the `bootstrap` function from the `modelr` package.\n\n-   By sampling with replacement, we allow the same observation to be included multiple times (or not all), in our bootstrapped sample.\n\n2.  For each bootstrap sample, we will estimate the same model as above, using the `map` function from the `purrr` package.\n\n-   We will end up with 1,000 bootstrapped estimates for each coefficient in our model\n-   These bootstrapped estimates describe the **sampling distribution** of coefficient.\n\n3.  Put the coefficients from this bootstrapped model into into a **tidy** data frame, using the `tidy` function from the `broom` package, and the `map_df` function from the `purrr` package.\n\n4.  Visualize the sampling distribution for coefficients in our model.\n\nIn the code below I demonstrate this process for `m1`. Then you will repeat this process for `m2`\n\n## Take 1,000 bootstrap samples from `df_drww`\n\nBelow we create 1,000 boostrapped samples\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make sure these packages are loaded\nlibrary(modelr)\nlibrary(purrr)\nlibrary(broom)\n# Set random seed for reproducability\n\nset.seed(1234)\n\n# 1,000 bootstrap samples\nboot <- modelr::bootstrap(df_drww, 1000)\n```\n:::\n\n\nLet's take a moment to understand what `boot` is and why we're sampling with replacement.\n\nThe object `boot` contains 1,000 bootstrapped samples from `df_drww`.\n\nIf we look at the first bootstrap we see:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot$strap[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<resample [1,807 x 42]> 1308, 1018, 1125, 1004, 623, 905, 645, 934, 400, 900, ...\n```\n\n\n:::\n:::\n\n\nThe numbers `1308, 1018, 1125, 1004, 623, 905, ...` correspond to rows in `df_drww`. So person `1308` is the first observation in this boot strap sample, then person `1018` and so on.\n\nBecause we are sampling **with replacement** observations from `df_drww` can appear multiple times. In our first bootstrap sample:\n\n-   666 observations appeared once\n-   342 appeared twice\n-   105 appeared three times\n-   27 appeared four times\n-   5 appeared five times.\n-   2 appeared six times\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(table(boot$strap[[1]]$idx))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  1   2   3   4   5   6 \n666 342 104  27   5   2 \n```\n\n\n:::\n:::\n\n\nWhy would we want to sample with replacement?\n\nWell, what we'd really love are 1,000 separate random surveys all drawn from the same population in the same way.\n\nSince that's not feasible, we instead use the one sample we do have to learn things like how much our estimate might vary in repeated sampling. [Efron (1979)](https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full) called this procedure \"bootstrapping\" after the idiom \"to pull oneself up by one’s own bootstraps\"\n\nWe do this by sampling from our sample **with replacement**.\n\nWhen we sample with replacement, we are sampling from our sample, as our sample was sampled from the population.\n\n**With replacement** means that some observations will appear multiple times in our bootstrapped sample (while others will not be included at all).\n\nWhen an observation appears multiple times in a bootstrap sample, conceptually, we're using that original observation to represent the other people like that observation in the population who -- had we taken a different sample -- might have been included in our data.\n\nNote each bootstrap sample is a different random sample with replacement. In our second bootstrap sample, one observation (person 1496) appeared five times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(table(boot$strap[[2]]$idx))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  1   2   3   4   5   6 \n661 342 105  31   1   3 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Person 406\nsum(boot$strap[[2]]$idx == 1496)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n```{.r .cell-code}\n# Person 1 is not in boostrap 2\nsum(boot$strap[[2]]$idx == 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n## Estimate 1,000 models from the 1,000 bootstrapped samples\n\nNow let's estimate our model for each bootstrapped sample, using the `map` function.\n\n-   In the code below, for every sample in `boot`, map estimates the model `lm(support_war01 ~ age + sex + education_n)` plugging in the bootstrap sample into the `data=.`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bootstrap simulations\nbs_ols <- purrr::map(boot$strap, ~ lm(support_war01 ~ age + sex + education_n, data =.))\n```\n:::\n\n\nThe end result is a large list with 1,000 separate linear regression models estimated on each bootstrapped sample.\n\nThe coefficients from each bootstrap vary from one simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First bootstrap\nbs_ols[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = support_war01 ~ age + sex + education_n, data = .)\n\nCoefficients:\n(Intercept)          age      sexMale  education_n  \n   0.305019     0.009746     0.081039    -0.024142  \n```\n\n\n:::\n:::\n\n\nto the next:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Second boostrap\nbs_ols[[2]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = support_war01 ~ age + sex + education_n, data = .)\n\nCoefficients:\n(Intercept)          age      sexMale  education_n  \n   0.245000     0.009142     0.095631    -0.009285  \n```\n\n\n:::\n:::\n\n\nBecause they're estimated off of different bootstrapped samples.\n\nWe will visualize and quantify that variation to describe the uncertainty associated with our estimates.\n\nBut first, we need to transform our large list of linear models, into a more tidy data frame that's easier to manipulate.\n\n## Tidy the results of our bootstrapping\n\nIn the code below we transform this large list of models into a `tidy` data frame of coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tidy bootstrapp sims\nbs_ols_df <- map_df(bs_ols, tidy, .id = \"id\")\n```\n:::\n\n\nIn the resulting data frame the `id` variable identifies the bootstrap simulation (1 to 1,000), the `term` variable indentifies the specific coefficient from the model estimated for that simulation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(bs_ols_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  id    term        estimate std.error statistic  p.value\n  <chr> <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 1     (Intercept)  0.305    0.0522        5.84 6.29e- 9\n2 1     age          0.00975  0.000702     13.9  3.31e-41\n3 1     sexMale      0.0810   0.0222        3.65 2.73e- 4\n4 1     education_n -0.0241   0.0107       -2.26 2.39e- 2\n5 2     (Intercept)  0.245    0.0533        4.60 4.61e- 6\n6 2     age          0.00914  0.000731     12.5  3.36e-34\n```\n\n\n:::\n:::\n\n\n## Plot the bootstrapped sampling distribution of the coefficient for age\n\nFinally, let's get a sense of how our coefficients could vary.\n\nSpecifically, let's compare the the observed coefficient from `m1` for age, to the bootstrapped `sampling distribution` of coefficients in `bs_ols_df`\n\n-   First, we'll create a basic plot called `p_ols_age` that shows the distribution of the coefficients for age from our simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ols_age <- bs_ols_df %>%\n  filter(term == \"age\") %>%\n  ggplot(aes(estimate))+\n    geom_density()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in ggplot(., aes(estimate)): could not find function \"ggplot\"\n```\n\n\n:::\n\n```{.r .cell-code}\np_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n:::\n\n\nNext we'll add some additional geometries and labels to our figure\n\n-   First we'll put a rug to show the individual coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ols_age +\n  geom_rug() -> p_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n\n```{.r .cell-code}\np_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n:::\n\n\n-   Then we'll add a vertical line where our observed coefficient on `age`\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ols_age +\n  geom_vline(xintercept =  coef(m1)[2],\n             linetype = 2) -> p_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n\n```{.r .cell-code}\np_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n:::\n\n\n-   Finally, let's add some nice labels\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ols_age +\n  theme_bw()+\n  labs(\n    x = \"Age\",\n    y = \"\",\n    title = \"Bootstrapped Sampling Distribution of Age Coefficient\"\n  ) -> p_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n\n```{.r .cell-code}\np_ols_age\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n:::\n\n\nCongratulations you've just produced and visualized your first bootstrapped sampling distribution!\n\nConceptually, this distribution describes \\*how much we would expect the coefficient on age in model to vary\\*\\* from sample to sample.\n\nJust from eyeballing the figure above, it looks like the observed the relationship between age and support for war or 0.009 could be about as high as 0.011, and as low as 0.007.\n\nOf course, as the budding quantitative social scientists that we are, we can do better than just eyeballing the data.\n\n# Quantify the uncertainy described by your sampling distributions\n\nSpecifically, please calculate the standard deviations, 97.5 and 2.5 percentiles of each coefficient in `bs_old_df`\n\nYou'll want to\n\n-   `group_by()` the `term` variable in `bs_ols_df`\n-   `summarize()` the output of functions applied to the `estimate` column in `bs_ols_df`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbs_ols_df %>%\n  group_by(term)%>%\n  summarize(\n    mean_estimate = mean(estimate),\n    sd = sd(estimate,na.rm=T),\n    p2_5 = quantile(estimate, prob =.025),\n    p97_5 = quantile(estimate, prob =.975)\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in summarize(., mean_estimate = mean(estimate), sd = sd(estimate, : could not find function \"summarize\"\n```\n\n\n:::\n:::\n\n\nPlease compare these these estimates to those by the following functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# summary(m1)\n# confint(m1)\n```\n:::\n\n\nThey're similar to a few thousandsth of a decimal place.\n\nIn fact, we can approximate the sampling distribution of coefficients two ways:\n\n-   Using simulation based approaches like the bootstrap procedure we implemented above\n\n-   Using asymptotic theory (i.e the Central Limit Theorem) to derive the theoretical sampling distributions\n\nBelow we see compare the two approaches (bootstrapped distribution in black, asymptotic normal distribution in red dots) and see they look quite similar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ols_age +\n  stat_function(\n    fun = \"dnorm\", \n    args = list(mean =coef(m1)[2],\n                sd = summary(m1)$coef[2,2]),\n    col = \"red\",\n    linetype = 3\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'p_ols_age' not found\n```\n\n\n:::\n:::\n\n\n# Explore other relationships in the data.\n\nFinally, let's take some time to explore other variables and relationships in the data.\n\nPlease do the following:\n\n-   **Research Question**: Formulate a brief research question here\n\n-   **Data**: Identify the relevant outcome and predictor variables in the data.\n\n    -   Outcome:\n    -   Key Predictor:\n    -   Covariates:\n        -   Covariate 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Explore the data\n```\n:::\n\n\n-   If necessary, transform and recode the data as needed\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data transformations if necessary\n```\n:::\n\n\n-   **Models and Expecations** Specify a model or models to test your question in terms of our outcome and predictor variables.\n\n$$\\text{Outcome} = \\beta_0 + \\beta_1 \\text{Key Predictor} + \\beta_2 \\text{Covariate}$$\n\n-   **Expectations** Discuss the expected sign and significance of the coefficients in your model. If you think a coefficient could be either positive or negative, explain what each of these results means in the context of your question.\n\n-   **Estimation** Estimate a model or models to test your question.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Models\n```\n:::\n\n\n-   **Results** Present and interpret your results using tables and figures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regression table\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Figures\n```\n:::\n\n\n------------------------------------------------------------------------\n\n-   Research Question: What effect does social media use have on Russian's Support for the War? Does the effect of social media vary with age\n\n-   Data:\n\n    -   Outcome: `support_war01`\n\n    -   Key Predictor: `total_social_media_use` a count from 0 (none) to 9 social media sites\n\n    -   Additional predictors:\n\n        -   Age\n        -   Sex\n        -   Education\n        -   Employment\n\n-   Data transformations: To simplify interpretation, I will create some indicator variables\n\n    -   `under30` an indicator that takes a value of 1 the respondent is under 30 and 0 otherwise\n\n-   Models and Expectations\n\n-   Baseline Model:\n\n$$\\text{Support} = \\beta_0 + \\beta_1 \\text{social media}  +\\epsilon$$ - Expectations:\n\n-   If $\\beta_1$ is positive this would suggest that higher social media use associated with greater support for the war. Perhaps respondents in russia are more likely to encounter state propaganda\n\n-   If $\\beta_1$ is negative, this implies that greater social media use is associated with less support. Perhaps sites like Twitter/Facebook/TikTok in early March allowed Russians to encounter non-state media\n\n-   Baseline Model with Controls:\n\n$$\\text{Support} = \\beta_0 + \\beta_1 \\text{social media} + X\\beta +\\epsilon$$ - Expectations: - If the coefficient on $\\beta_1$ is no longer signficant, this suggests that the bivariate relationship was spurious, driven by factors $X$ that predict both support and social media use. For example, it may be that the educated are more likely to use social media and less likely to support the war. Controlling for education then might remove the association between social media use and support.\n\n-   Interaction Model with Controls:\n\n$$\\text{Support} = \\beta_0 + \\beta_1 \\text{Social Media} +\\beta_2\\text{Under 30} + \\beta_3\\text{SM}\\times\\text{U30} + X\\beta +\\epsilon$$ - Expectations: - The key coefficient in this model is $\\beta_3$ which assesses whether the relationship between social media use and support differs for those under 30 compared to those over 30. It's possible that young people use social media differently than older folks, and so I'd expect this coefficient to be negative.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## ---- Data\ndf_drww %>%\n  mutate(\n    under30 = case_when(\n      age < 30 ~ 1,\n      T ~ 0\n    ),\n    any_social = case_when(\n      total_social_media_use ==0 ~ 0,\n      T ~ 1\n    )\n  ) -> df_drww\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in mutate(., under30 = case_when(age < 30 ~ 1, T ~ 0), any_social = case_when(total_social_media_use == : could not find function \"mutate\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_ex <- glm(support_war01 ~ total_social_media_use, \n             df_drww, family = binomial)\n\nm2_ex <- glm(support_war01 ~ total_social_media_use + \n               age + sex + education_n +employ_working, \n             df_drww, family = binomial)\n\nm3_ex <- glm(support_war01 ~ total_social_media_use*under30 + \n               sex + education_n + employ_working, \n             df_drww, family = binomial)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(predvars, data, env): object 'under30' not found\n```\n\n\n:::\n:::\n\n\n```{.r .cell-code}\nhtmlreg(list(m1_ex,m2_ex, m3_ex))\n```\n\n```\nError in htmlreg(list(m1_ex, m2_ex, m3_ex)): could not find function \"htmlreg\"\n```\n\n\nOverall, social media use appears to be associated with less support for the war in Ukraine among Russians.\n\nAs the first figure below shows, the baseline model, predicting support with only social media use appears to show a dramatic decline of nearly 40 percentage points in support.\n\nControlling for other factors likely to predict support and social media use, the decrease is less dramatic, but still, going from no social media use to a using a lot (nine) sites is associated with a about a 17 percentage point decrease in support for the war.\n\nContray to my expectations, the effect of social media doesn't appear to vary by age cohort. Support decreases with social medial use for both those over and under 30 but the rate of decrease is not statistically different.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_df_ex1 <- expand_grid(\n  total_social_media_use = 0:9,\n  age = mean(df_drww$age, na.rm = T),\n  sex = \"Female\",\n  education_n = mean(df_drww$education_n, na.rm = T),\n  employ_working = 1\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in expand_grid(total_social_media_use = 0:9, age = mean(df_drww$age, : could not find function \"expand_grid\"\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex1$pred_m1 <- predict(m1_ex, pred_df_ex1, type =\"response\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'pred_df_ex1' not found\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex1$pred_m2 <- predict(m2_ex, pred_df_ex1, type =\"response\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'pred_df_ex1' not found\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex1%>%\n  ggplot(aes(total_social_media_use, pred_m1))+\n  geom_line(aes(col = \"Bivariate\"))+\n  geom_line(aes(y=pred_m2, col = \"Controls\"))+\n  theme_bw()+\n  labs(\n    col = \"Model\",\n    x = \"Number of Social Media Sites Used\",\n    y = \"Predicted Support for the War\"\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in ggplot(., aes(total_social_media_use, pred_m1)): could not find function \"ggplot\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred_df_ex2 <- expand_grid(\n  total_social_media_use = 0:9,\n  under30 = c(0,1),\n  sex = \"Female\",\n  education_n = mean(df_drww$education_n, na.rm = T),\n  employ_working = 1\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in expand_grid(total_social_media_use = 0:9, under30 = c(0, 1), : could not find function \"expand_grid\"\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex2$pred_m3 <- predict(m3_ex, pred_df_ex2, type =\"response\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'm3_ex' not found\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex2%>%\n  mutate(\n    Age = case_when(\n      under30 == 1 ~ \"Under 30\",\n      T ~ \"30 and Over\"\n    )\n  ) %>%\n  ggplot(aes(total_social_media_use, pred_m3, col = Age))+\n  geom_line()+\n  theme_bw()+\n  labs(\n    x = \"Number of Social Media Sites Used\",\n    y = \"Predicted Support for the War\"\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in ggplot(., aes(total_social_media_use, pred_m3, col = Age)): could not find function \"ggplot\"\n```\n\n\n:::\n:::\n\n\nYoung folk are considerably more likely to use social media\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_drww %>%\n  mutate(\n    Age = case_when(\n      under30 == 1 ~ \"Under 30\",\n      T ~ \"30 and Over\"\n    )\n  ) %>%\n  ggplot(aes(total_social_media_use,fill =Age))+\n  geom_histogram(aes(y= ..density..))+\n  facet_grid(~Age)+\n  labs(\n    x = \"Social Media Sites Used\"\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in ggplot(., aes(total_social_media_use, fill = Age)): could not find function \"ggplot\"\n```\n\n\n:::\n:::\n\n\nIf we were to instead compare those over and under 30 by any social media use vs no social media use, we see that the decrease in support is much larger among the young (although not statistically significant...)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm4_ex <- glm(support_war01 ~ any_social*under30 + \n               sex + education_n + employ_working, \n             df_drww, family = binomial)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(predvars, data, env): object 'any_social' not found\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(m4_ex)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'm4_ex' not found\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex3 <- expand_grid(\n  any_social = 0:1,\n  under30 = c(0,1),\n  sex = \"Female\",\n  education_n = mean(df_drww$education_n, na.rm = T),\n  employ_working = 1\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in expand_grid(any_social = 0:1, under30 = c(0, 1), sex = \"Female\", : could not find function \"expand_grid\"\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex3$pred_m4 <- predict(m4_ex, pred_df_ex3, type =\"response\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): object 'm4_ex' not found\n```\n\n\n:::\n\n```{.r .cell-code}\npred_df_ex3%>%\n  mutate(\n    Age = case_when(\n      under30 == 1 ~ \"Under 30\",\n      T ~ \"30 and Over\"\n    ),\n    Media = case_when(\n      any_social == 1 ~ \"Social Media\",\n      T ~ \"No Social Media\"\n    )\n  ) %>%\n  ggplot(aes(Media, pred_m4, fill = Age))+\n  geom_bar( stat = \"identity\")+\n  facet_grid(~Age)+\n  theme_bw()+\n  labs(\n    x = \"Number of Social Media Sites Used\",\n    y = \"Predicted Support for the War\"\n  )\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in ggplot(., aes(Media, pred_m4, fill = Age)): could not find function \"ggplot\"\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/clipboard-2.0.6/clipboard.min.js\"></script>\n<link href=\"../../site_libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js\"></script>\n<script>window.xaringanExtraClipboard(null, {\"button\":\"<i class=\\\"fa fa-clipboard\\\"><\\/i>\",\"success\":\"<i class=\\\"fa fa-check\\\" style=\\\"color: #90BE6D\\\"><\\/i>\",\"error\":\"Press Ctrl+C to Copy\"})</script>\n<link href=\"../../site_libs/font-awesome-6.4.2/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome-6.4.2/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}