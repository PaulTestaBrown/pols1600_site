{
  "hash": "31f11fe98fb9fbac9e95a965897dab98",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Comments for Lab 07 - Exploring Russians' Attitudes About the War in Ukraine\"\nauthor: \"Your Group Members Names Here\"\ndate: \"Last Updated 2024-01-24\"\nformat:\n  html:\n    toc: true\n    toc-location: left\n    toc-float: true\n    toc-depth: 2\n    number-sections: true\n---\n\n\n\n\n\n# Overview {.unnumbered}\n\nToday, we'll explore Russians' support the war in Ukraine using a public opinion survey from Russia conducted by Alexei Miniailo's [\"Do Russians Want War\"](https://www.dorussianswantwar.com/en) project.\n\nThe survey was conducted by phone using a random sample of mobile phone numbers to produce a sample of respondents representative of the population in terms of age, sex, and geography. It was in the field from February 28 to March 2.\n\nWe will look at how support for the war varies with the demographic predictors `age`, `sex` and `education`. We will see how multiple regression can be used to describe more complex relationships. From our baseline model, we will ask:\n\n-   Does the relationship between age and support for the war vary among male and female respondents (Interaction model)\n\n-   Does the relationship between age and support vary at different levels of age (Polynomial regression model)\n\n-   Does the relationship between age and support vary at different levels of age and does the nature of this variation differ among male and female respondents (Polynomial regression model with an interaction term)\n\nTo accomplish this, we will do the following:\n\n1.  Get set up to work and describe our data (10 minutes)\n\n2.  Get practice interpreting long chunks of codes with lots of `%>%`s (10 minutes)\n\n3.  Estimate four models of increasing complexity (15 minutes)\n\n4.  Present these models in a regression table and interpret the results (10 minutes)\n\n5.  Evaluate the relative performance of these models in terms of their variance explained $R^2$'s (15 minutes)\n\n6.  Produce predicted values to help us interpret and compare our baseline model to a model where the \"effect\" of an increase in age changes with age (10 minutes)\n\n7.  Produce predicted values to help us interpret and compare models where the \"effect\" of age is allowed to vary with respondent's sex (10 minutes)\n\nFinally, if there's time, we will:\n\n8.  Explore additional questions of our choosing in the data\n\nOne of questions 1-7 will be randomly selected as the graded question for the lab.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3172022)\ngraded_question <- sample(1:7,size = 1)\npaste(\"Question\",graded_question,\"is the graded question for this week\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Question 5 is the graded question for this week\"\n```\n\n\n:::\n:::\n\n\nYou will work in your assigned groups. Only one member of each group needs to submit the html file produced by knitting the lab.\n\nThis lab **must** contain the names of the group members in attendance.\n\nIf you are attending remotely, you will submit your labs individually.\n\nYou can find your assigned groups in previous [labs](https://pols1600.paultesta.org/labs/06-lab-comments.html){target=\"_blank\"}\n\n# Goals {.unnumbered}\n\nBroadly, our goals in this assignment are to:\n\n::: sidenote\n$$y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\overbrace{\\beta_3 x\\cdot z}^{\\text{Interaction term}} $$\n:::\n\n-   Get comfortable estimating and interpreting regression models with **interaction terms**\n\n    -   Including an interaction between two variables is useful if we think the \"effect\" of one variable depends on the value of another variable.\n\n    -   Today, we test whether the association between support for the war and age differs between male and female respondents.\n\n::: sidenote\n$$x^1 = x; \\, x^2 = x\\cdot x; \\,   x^{nth} = \\prod_{i=1}^{i=n} x_i = x_1\\cdot x_2 \\cdot x_3 \\dots \\cdot x_n $$\n:::\n\n-   Get comfortable estimating and interpreting regression models with **polynomial terms**\n\n    -   Polynomial terms are a way of incorporating non-linearity in our predictors.[^1]\n\n    -   If we think the relationship between a predictor and an outcome varies at different levels of the predictor, we can include a polynomial term(s) for that predictor. Now our model will describe the relationship between $x$ and $y$ with a curve (varying slope), rather than a line (constant slope)\n\n-   Learn how to generate predicted values from our model to help us interpret **complex regression models**\n\n    -   Regression tables are great for summarizing basic regression models.\n\n    -   Models with interaction terms or polynomial terms (or both) are difficult to interpret by looking at just the coefficients themselves\n\n    -   Producing predicted values that show how the model's predictions change as variables in a interaction or polynomial change help us understand what these coefficients are telling us.\n\n-   Practice **comparing *nested* models** using the proportion of the variance explained by each model.\n\n    -   Recall that a model's $R^2$ describes the proportion of the total variance in our outcome, explained by the model's predictions.\n\n    -   When we add predictors to a model, the model becomes more flexible, and can explain more variance in the outcome.\n\n    -   *adjusted* $R^2$ adjusts models's $R^2$ by penalizing models for total number of predictors needed to explain given amount of variance\n\n    -   When models are *nested* (the predictors in a smaller model are a subset of the predictors in a larger model), we can compare the relative performance of the two using tools like $R^2$ and adjusted $R^2$.\n\n    -   When comparing models, we make trade offs between our desire to explain as much variation in the outcome as possible with a general preference for more parsimonious models.[^2]\n\n        -   For example, a simple bivariate regression and a complicated multiple regression could have the same $R^2$ (i.e. the both explain 50 percent of the total variance in the outcome), but the adjusted $R^2$ will be higher for the simple regression compared to the multiple regression, because it needed fewer predictors to explain the same amount of variance.\n\n[^1]: Mathematically, recall that the slope/first derivative of the line $y = f(x) = 2x$ is constant $(f'(x) = 2)$. If we increase x by 1, we expect y to increase by 2, while the derivative of a parabola $y = f(z) = z^2$ varies with $z$ $(f'(z) = 2x)$. Going from z= 2 to z= 3 is associated with a greater increase in y, then going from z=1 to z=2. Our model, however, is still [linear in *parameters*](https://blog.minitab.com/en/adventures-in-statistics-2/what-is-the-difference-between-linear-and-nonlinear-equations-in-regression-analysis#:~:text=In%20statistics%2C%20a%20regression%20equation,produce%20a%20U%2Dshaped%20curve.) $\\beta$. That is, it is still a linear regression. If our model included some parameter $\\theta^2$, then it would be a non-linear regression.\n\n[^2]: In a machine learning framework, we trying to find an [optimal tradeoff](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229) between reducing bias in our predictors by including more predictors and minimizing variance in predictions by not overfitting the data.\n\n# Workflow {.unnumbered}\n\n# Please knit this .Rmd file {.unnumbered}\n\nAs with every lab, you should:\n\n-   Download the file\n-   Save it in your course folder\n-   **Update the `author:` section of the YAML header to include the names of your group members in attendance.**\n-   Knit the document\n-   Open the html file in your browser (Easier to read)\n-   Write yourcode in the chunks provided\n-   Comment out or delete any test code you do not need\n-   **Knit the document again after completing a section or chunk** (Error checking)\n-   Upload the final lab to [Canvas](https://canvas.brown.edu/courses/1091286/assignments/7925689?module_item_id=10882050){target=\"_blank\"}.\n\n# Get setup to work\n\n## Load Packages\n\nFirst lets load the libraries we'll need for today.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_packages <- c(\n  ## R Markdown\n  \"kableExtra\",\"DT\",\"texreg\",\"htmltools\"\n  , # Comments only\n  ## Tidyverse\n  \"tidyverse\", \"lubridate\", \"forcats\", \"haven\", \"labelled\",\n  ## Extensions for ggplot\n  \"ggmap\",\"ggrepel\", \"ggridges\", \"ggthemes\", \"ggpubr\", \n  \"GGally\", \"scales\", \"dagitty\", \"ggdag\", \"ggforce\",\n  # Data \n  \"COVID19\",\"maps\",\"mapdata\",\"qss\",\"tidycensus\", \"dataverse\",\n  # Analysis\n  \"DeclareDesign\", \"zoo\"\n)\n\n# Define function to load packages\nipak <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n\nipak(the_packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   kableExtra            DT        texreg     htmltools     tidyverse \n         TRUE          TRUE          TRUE          TRUE          TRUE \n    lubridate       forcats         haven      labelled         ggmap \n         TRUE          TRUE          TRUE          TRUE          TRUE \n      ggrepel      ggridges      ggthemes        ggpubr        GGally \n         TRUE          TRUE          TRUE          TRUE          TRUE \n       scales       dagitty         ggdag       ggforce       COVID19 \n         TRUE          TRUE          TRUE          TRUE          TRUE \n         maps       mapdata           qss    tidycensus     dataverse \n         TRUE          TRUE          TRUE          TRUE          TRUE \nDeclareDesign           zoo \n         TRUE          TRUE \n```\n\n\n:::\n:::\n\n\n## Load the data\n\nNext we'll load the recoded data for the lab.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(url(\"https://pols1600.paultesta.org/files/data/df_drww.rda\"))\n```\n:::\n\n\n## Describe the data\n\nAs always, it's important to get a high level overview of data when we first load it into R.\n\nBelow we take a look at the first few values of all the data. You'll see that `df_drww` includes both the Russian data and recoded revisions of the data (which are typically appended with `_n` for numeric data or `_f` for factor data).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(df_drww)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in glimpse(df_drww): could not find function \"glimpse\"\n```\n\n\n:::\n:::\n\n\nIn the first part of this lab, we'll work with the following variables\n\n-   `support_war01` \"Please tell me, do you support or do not support Russia's military actions on the territory of Ukraine?\" (1=yes, 0 = no)\n\n-   `age` \"How old are you?\"\n\n-   `sex` \"Gender of respondent\" (As assessed by the interviewer)\n\n-   `education_n` \"What is your highest level of education (confirmed by a diploma, certificate)?\" (1 = Primary school, 2 = \"High School\", 3 = \"Vocational School\" 4 = \"College\", 5 = Graduate Degree)[^3]\n\n[^3]: I think, google translate was a bit unclear. But higher numbers equal more education.\n\nIn the code chunk below, I create a data frame of summary statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_vars <- c(\"support_war01\",\"age\", \"is_female\", \"education_n\")\n\ndf_drww %>%\n  mutate(\n    is_female = ifelse(sex == \"Female\",1, 0)\n  ) %>%\n  select(all_of(the_vars)) %>%\n  pivot_longer(\n    cols = all_of(the_vars ),\n    names_to = \"Variable\",\n    values_to = \"Value\"\n  ) %>%\n  group_by(Variable) %>%\n  summarise(\n    `N obs` = n(),\n    Missing = sum(is.na(Value)),\n    Min = min(Value, na.rm = T),\n    `25th perc` = quantile(Value, .25, na.rm=T),\n    Mean = mean(Value, na.rm=T),\n    Median = median(Value, na.rm = T),\n    `75th perc` = quantile(Value, .75, na.rm=T),\n    Max = max(Value, na.rm = T)\n  ) %>%\n  mutate(\n    Variable = case_when(\n      Variable == \"age\" ~ \"Age\",\n      Variable == \"education_n\" ~ \"Education\",\n      Variable == \"is_female\" ~ \"Female\",\n      Variable == \"support_war01\" ~ \"Support for War\",\n      \n    ),\n    Variable = factor(Variable, levels = c(\"Support for War\",\"Age\",\"Female\",\"Education\"))\n    ) %>%\n  arrange(Variable) ->  summary_table\n\nsummary_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 9\n  Variable     `N obs` Missing   Min `25th perc`   Mean Median `75th perc`   Max\n  <fct>          <int>   <int> <dbl>       <dbl>  <dbl>  <dbl>       <dbl> <dbl>\n1 Support for…    1807     334     0           0  0.720      1           1     1\n2 Age             1807       0    18          34 46.6       45          60    99\n3 Female          1807       0     0           0  0.470      0           1     1\n4 Education       1807      13     1           3  3.17       3           4     5\n```\n\n\n:::\n:::\n\n\nWhich we can then format into a table of summary statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(summary_table,\n      digits = 2) %>% \n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  kableExtra::pack_rows(\n    group_label = \"Outcome\",\n    start_row = 1,\n    end_row = 1\n  )%>%\n  kableExtra::pack_rows(\n    group_label = \"Predictors\",\n    start_row = 2,\n    end_row = 4\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> N obs </th>\n   <th style=\"text-align:right;\"> Missing </th>\n   <th style=\"text-align:right;\"> Min </th>\n   <th style=\"text-align:right;\"> 25th perc </th>\n   <th style=\"text-align:right;\"> Mean </th>\n   <th style=\"text-align:right;\"> Median </th>\n   <th style=\"text-align:right;\"> 75th perc </th>\n   <th style=\"text-align:right;\"> Max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr grouplength=\"1\"><td colspan=\"9\" style=\"border-bottom: 1px solid;\"><strong>Outcome</strong></td></tr>\n<tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Support for War </td>\n   <td style=\"text-align:right;\"> 1807 </td>\n   <td style=\"text-align:right;\"> 334 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.72 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr grouplength=\"3\"><td colspan=\"9\" style=\"border-bottom: 1px solid;\"><strong>Predictors</strong></td></tr>\n<tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Age </td>\n   <td style=\"text-align:right;\"> 1807 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 46.65 </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 99 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Female </td>\n   <td style=\"text-align:right;\"> 1807 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.47 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Education </td>\n   <td style=\"text-align:right;\"> 1807 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 3.17 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Please use this table to describe a typical respondent to the survey** YOUR DESCRIPTION HERE\n\nThe median respondent in this sample is about 45 years old and has complete some form of vocational school. About 47 percent of the respondents are female, and 72 percent of the respondents support Russia's actions in Ukraine.\n\nAlso note that 334 respondents (over 18 percent) declined to give an answer on the support for war question. If all of these respondents supported the war, total support would rise to 77 percent, while if all of these respondents opposed the war, support would drop to 59 percent. I suspect that that 72 percent support may overstate the true level of support, if those who are opposed to war are less likely to answer the question or more likely to misrepresent their views.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(is.na(df_drww$support_war01))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1848367\n```\n\n\n:::\n\n```{.r .cell-code}\n# What if these missing respondents all supported or opposed the war?\n\ndf_drww %>%\n  mutate(\n    support_war01_NAsupport = ifelse(is.na(support_war01),1,support_war01),\n    support_war01_NAoppose = ifelse(is.na(support_war01),0,support_war01)\n  ) %>%\n  select(starts_with(\"support_war01\")) %>%\n  summarise_all(mean, na.rm=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  support_war01 support_war01_NAsupport support_war01_NAoppose\n1     0.7202987               0.7719978               0.587161\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Interpretting long chunks of code\n\nThe previous section contained a fairly long chunk of code.\n\nI suspect you had little trouble interpreting the table of summary statistics produced by the second code chunk (`summary_table`), but may not have followed everything that was happening in the first code chunk (`summary_stats`).\n\nIn this section, I want you to practice interpreting large chunks of code with lots of `%>%`\n\n-   Recall, that the pipe command takes the outcome from a function that comes before the `%>%` and `pipes` it into the **first argument** of the function that comes after it.\n\n-   Each function in `summary_stats` expects a `data.frame` in its first argument. The function then does something to this inputted data frame (add a column, pivot columns, etc) and returns a new data.frame which `%>%` then passes on to next function.\n\nTo learn how to produce a table of summary statistics (a common task for empirical work), it's helpful to understand what's happening at each step of the process in the `summary_stats` code chunk.\n\nIn the code chunk below, starting from `df_drww %>%` please\n\n-   Copy and paste the all the code up until the next `%>%`\n\n-   Run this code in your console\n\n-   Write a comment above this code in code chunk\n\nRunning code line-by-line, is great way to learn how to code, by understanding what happens in each line of code.\n\nThere are about 8 or 9 steps of code to explain (depending on how you copy and paste.) I've done steps 1-3 below. Please take the next 10 minutes or so to fill in the rest.\n\n\n\n\n\nHere's my commented version of the code\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-error}\n\n```\nError in knit_print.with_flair(.): could not find function \"knit_print.with_flair\"\n```\n\n\n:::\n:::\n\n\nI've made a lot of tables of summary statistics in my life, so I have an idea what the end results should look like. When I wrote the code for this section, I did it sequentially, looking at the output of each Step, and saying ok, now I need to do this. My thought process looked like this:\n\n-   To summarize the distribution of `sex`, I first needed to create a numeric indicator, `is_female`, which will tell me the proportion of the sample identifying as female.\n\n-   Then I selected just the columns of the data I wanted to summarize using the `select()` with my vector of variable names `the_vars`\n\n-   Then I pivoted them from a wide data frame into a long dataframe using `pivot_longer()` so I could use `group_by()` to calculate various statistics for each of the four variables.\n\n-   Then I recoded the variable names into something that looks like English (and not R code) using `case_when()`,\n\n-   I know that R can `arrange()` things by levels of factor, so I turn the `Variable` variable into a factor with `Support for War` as the first level, because I want my outcome variable at the top of the table.\n\n-   Finally, when the resulting output looks like a data frame I want, I save it to `summary_table`\n\nThat seems like a lot when read all at once.\n\nIf I had asked you to produce a table of summary statistics and given you no guidance, I suspect might have taken a long time, since, well you've never had to do this before. But we've got better things to do in this lab.\n\nBut now that you've seen how to do this, and walked through the code to understand what's happening at each stage, hopefully, you could adapt this code for your group projects.\n\nYou will almost certainly encounter complications (portals of discovery), along the way.\n\nBy running your code sequentially, you can see step-by-step what's happening, and say, did my code produce the expected output. If yes, on to the next step. If no, why? The answer may be a syntantical error like a missing comma, or something more arcane. Try googling, asking your group mates, and me.\n\n------------------------------------------------------------------------\n\n# Explore the demographic predictors of Russians' Support for the War in Ukraine\n\nToday, we will estimate four models to explore how Russian support for the war in Ukraine varies with demographic predictors.\n\n-   `m1` provides a baseline model that predicts support for the war as a linear function of `age`, `sex`, and `education_n` measured as numeric scale (1 = Primary School, 5 = Graduate Degree).\n\n-   `m2` is an **interaction regression model** that asks whether the relationship between `age` and `support` varies by `sex`\n\n-   `m3` is a **polynomial regression model**, that includes a term for \"age-squared\" which allows the relationship between age and support to vary over different levels of age\n\n-   `m4` adds an interaction term to the *polynomial* regression from `m3` essentially allowing for separate curves for male and female respondents.\n\n------------------------------------------------------------------------\n\n## Describe your expectations for these models\n\nBefore you estimate these models, please answer the following:\n\n**In the baseline model, `m1`** what do you expect the sign of the coefficient for each predictor to be:\n\n-   *Age* (Positive/Negative)\n\n-   *Sex* (Positive/Negative)[^4]\n\n-   *Education* (Positive/Negative)\n\n[^4]: This is tricky, you need to know what the reference (excluded) category will be.\n\n**In the interaction model, `m2`**\n\n-   Do you think the relationship between age and support will vary by sex (Yes/No)\n\n-   If you said yes, do you think the coefficient on the interaction between age and sex will be positive or negative (Positive/Negative)\n\n**In the polynomial model, `m3`**\n\n-   If the coefficient on `age` is positive and the coefficient on `age^2` is positive, then as age increases, the increase in the predicted level of support will be (increasing/decreasing)\n\n-   If the coefficient on `age` is positive and the coefficient on `age^2` is negative, then as age increases, the increase in the predicted level of support will be (increasing/decreasing)\n\n**In `m4`**\n\n-   If the coefficients on the interaction terms between the `sex` variable and the age variables (`age` and `age^2`) is statistically significant, this implies that the relationship between `age` and support for the war is (similar/different) for male and female respondents.\n\n**In the baseline model, `m1`** what do you expect the sign of the coefficient for each predictor to be:\n\n-   *Age* I'd expect the coefficient to be **Positive** reflecting my weak prior belief that young people tend to be less supportive of war than old people (maybe because they're more likely to be the ones fighting and dying in the war.)\n\n-   *Sex* The coefficient on the `sex` variable describes the difference between male and female respondents (controlling for age and education). Because `sex` is a character string, R converts it into a binary indicator, `sexMale`, which takes a value of 1 when respodents are Male and 0 otherwise (when respondents are Female). R chose `Female` as the reference category because the letter `F` comes before `M` alphabetically. The coefficient on `sexMale` tells us how Male respondents differ from Female respondents. Again I don't have strong prior beliefs, but my hunch is that men tend to be more supportive of War than women for some complex set of reasons that reflect mixture of Nature vs Nurture type explanations.\n\n-   *Education* I'd expect the coefficient on education to be **negative**, because education, in the U.S. context tends to be correlated with more liberal or progressive policy views which tend to be more Doveish on matters of foreign policy.\n\nHonestly though, you could probably make the case for opposite sign on each of these coefficients.\n\n-   Maybe age is associated with less support, because older people lived through Russia's wars in Afghanistan\n-   Maybe Men are more likely to be opposed to war because they are more likely to fight in it.\n-   Maybe the educated in Russia are more likely to support the war because they are more likely to be part of the ruling elite/consume more media (and state media)/less likely to have to fight, etc.\n\nThe real point of this question is to give you practice thinking about how to test the empirical implications of your theoretical expectations with regression.\n\n**In the interaction model, `m2`**\n\n-   Do you think the relationship between age and support will vary by sex? **No.** But then I've already seen the data.\n\n-   If you said yes, do you think the coefficient on the interaction between age and sex will be positive or negative? This question required you to know what the term R would choose to represent `sex`. In `m2` the coefficient on `age` describes the relationship between `age` and `support` for female respondents. The coeficient on `age:sexMale` describes how this slope/relationship changes for `men`.\n\nIf the relationship for age is \\*\\*positive for female respondents, and the coefficient on the interaction term is negative, this implies that support for the war increases more slowly with age for male respondents compared to female respondents.\n\nSimilarly, if the coefficient on the interaction term was positive, this implies that support for war increases more rapidly with age for men compared to women.\n\n**In the polynomial model, `m3`**\n\n-   If the coefficient on `age` is positive and the coefficient on `age^2` is positive, then as age increases, the increase in the predicted level of support will be **increasing** (Think of $\\cup$-shaped parabola )\n\n-   If the coefficient on `age` is positive and the coefficient on `age^2` is negative, then as age increases, the increase in the predicted level of support will be **decreasing** (Think of $\\cap$-shaped parabola )\n\n**In `m4`**\n\n-   If the coefficients on the interaction terms between the `sex` variable and the age variables (`age` and `age^2`) is statistically significant, this implies that the relationship between `age` and support for the war is **different** for male and female respondents.\n\nIn general, interaction terms allow relationships to vary accross groups or values of predictors.\n\nIf both `m2` and `m3` had yielded statistically signficiant results, maybe `m4` would have been justified, but honestly I had you fit `m4` primarily for pedagogical reasons so you could see that even very complciated models can be understood using predicted values.\n\n------------------------------------------------------------------------\n\n## Estimate the regression models\n\nUncomment the code below, and replace the `???` with the appropriate terms to fit the following models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# # Baseline Model\n# m1 <- lm(support_war01 ~ age + sex + education_n, df_drww)\n# \n# # Interaction model: Allow coefficient for age to vary with sex\n# m2 <- lm(support_war01 ~ age*??? + education_n, df_drww)\n# \n# # Polynomial model: Allow coefficient for age to vary by age\n# m3 <- lm(support_war01 ~ age + I(???^2) + sex + education_n, df_drww)\n# \n# # Separate Polynomial: Allow coefficient for age to vary by age separately  by sex\n# m4 <- lm(support_war01 ~ (age + I(???))*??? + education_n, df_drww)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Baseline Model\nm1 <- lm(support_war01 ~ age + sex + education_n, df_drww)\n\n# Interaction model: Allow coefficient for age to vary with sex\nm2 <- lm(support_war01 ~ age*sex + education_n, df_drww)\n\n# Polynomial model: Allow coefficient for age to vary by age\nm3 <- lm(support_war01 ~ age + I(age^2) + sex + education_n, df_drww)\n\n# Separate Polynomial: Allow coefficient for age to vary by age separately  by sex\nm4 <- lm(support_war01 ~ (age + I(age^2))*sex + education_n, df_drww)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n# Display your models in a regression table and offer some initial interpretations\n\nUsing code from previous labs and lectures, please display the models from the previous section in a regression table and offer some initial interpretations.\n\nYou can use the [code from last week's lab as a guide.](https://pols1600.paultesta.org/labs/06-lab-comments.html#4_Estimate_a_model_controlling_for_age_and_income){target=\"_blank\"}\n\n-   Try adding the argument, `digits = 4` to `htmlreg`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntexreg::htmlreg(list(m1,m2,m3,m4), digits = 4) %>% HTML %>% browsable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<table class=\"texreg\" style=\"margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;\">\n<caption>Statistical models</caption>\n<thead>\n<tr>\n<th style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 1</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 2</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 3</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 4</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">(Intercept)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.2775<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.2690<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.1159</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.1193</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0529)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0638)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.1019)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.1437)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">age</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0092<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0094<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0280<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0276<sup>&#42;&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0007)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0010)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0042)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0060)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">sexMale</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0943<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1107</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0861<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0825</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0225)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0721)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0225)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.1979)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">education_n</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0158</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0157</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0217<sup>&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0215<sup>&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0108)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0108)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0108)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0109)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">age:sexMale</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0003</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.0012</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0014)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0084)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">age^2</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0002<sup>&#42;&#42;&#42;</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0002<sup>&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0000)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0001)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">age^2:sexMale</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.0000</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.0001)</td>\n</tr>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1074</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1074</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1197</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1199</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Adj. R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1055</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1050</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1172</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.1163</td>\n</tr>\n<tr style=\"border-bottom: 2px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">Num. obs.</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1463</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1463</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1463</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1463</td>\n</tr>\n</tbody>\n<tfoot>\n<tr>\n<td style=\"font-size: 0.8em;\" colspan=\"5\"><sup>&#42;&#42;&#42;</sup>p &lt; 0.001; <sup>&#42;&#42;</sup>p &lt; 0.01; <sup>&#42;</sup>p &lt; 0.05</td>\n</tr>\n</tfoot>\n</table>\n\n```\n\n:::\n:::\n\n\n**In particular, please answer the following:**\n\nFor `m1` (Model 1) how do predicted levels of support for the war, change with\n\n-   **Age**\n-   **Sex**\n-   **Education**\n\nFor `m2`(Model 2) does the relationship between age and support appear to differ for male and female respondents\n\nFor `m3` (Model 3) Does the relationship between age and support appear to be constant or does the predicted marginal effect of an increase in age differ[^5]\n\n[^5]: Basically, I'm asking whether the coefficient on `I(age^2)` is statistically significant. If it is, then the change in predicted support for the war among say 20-year-olds compared to 30-year-olds, would be different than change between 30- to 40-year-olds. Interpreting polynomials terms and interaction models is much easier if, as we do later, we simply obtain and plot the predicted values from this model\n\n-   (The marginal effect of age is constant / The marginal effect of age varies)\n\nFor `m4` (Model 4) do the varying marginal effects of age appear to also vary by gender?[^6]\n\n[^6]: As in the previous question, basically you need to look at the table and see if the coefficients on the interaction terms are statistically significant. It's a little more complicated than this, but if they are significant, this is evidence of differences across Sex.\n\n-   (Yes/No)\n\n**In particular, please answer the following:**\n\nFor `m1` (Model 1) how do predicted levels of support for the war, change with\n\n-   **Age** Older respondents tend to be more supportive of the war, by about 1 percentage point\n-   **Sex** Men tend to support the war by about 9 percentage points more than women\n-   **Education** Education appears to be unrelated to support for the war in `m1`\n\nFor `m2`(Model 2) does the relationship between age and support appear to differ for male and female respondents\n\n-   It does not. The coefficient on the interaction term in is substantively small and statisticallly insignficant.\n\nFor `m3` (Model 3) Does the relationship between age and support appear to be constant or does the predicted marginal effect of an increase in age differ[^7]\n\n[^7]: Basically, I'm asking whether the coefficient on `I(age^2)` is statistically significant. If it is, then the change in predicted support for the war among say 20-year-olds compared to 30-year-olds, would be different than change between 30- to 40-year-olds. Interpreting polynomials terms and interaction models is much easier if, as we do later, we simply obtain and plot the predicted values from this model\n\n-   The marginal effect of age varies. While increases in age are still associated with higher levels of support for war, the size of this increased effect is smaller for older respodents compared to younger respondents.\n\nFor `m4` (Model 4) do the varying marginal effects of age appear to also vary by gender?[^8]\n\n[^8]: As in the previous question, basically you need to look at the table and see if the coefficients on the interaction terms are statistically significant. It's a little more complicated than this, but if they are significant, this is evidence of differences across Sex.\n\n-   No. The interaction terms between age, age-squared and sex are not statstically significant.\n\n------------------------------------------------------------------------\n\n# Use $R^2$ to compare models\n\nNow take a look at the bottom rows in your regression table which show each model's $R^2$ and adjusted $R^2$.\n\nRecall from class, that $R^2$ describes the proportion of the variance in our outcome (support for the war), explained by the predictors in our model (age, sex, education, and some interactions/polynomials).\n\nYou may also remember that $R^2$ always increases as we add more predictors to the model. To account for this, we often look at the adjusted $R^2$ which weights the increase in variance explained (decrease in variance unexplained) by the number of additional predictors needed to produce that increase.\n\nYou regression table only reports results to a few decimal places.\n\nLet's use the `summary()` function to extract and save the $R^2$ (`r.squared`) and adjusted $R^2$ (`adj.r.squared`) for each model. The code for `m1` is there as an example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# m1\nm1_r_squared <- summary(m1)$r.squared\nm1_adj_r_squared <- summary(m1)$adj.r.squared\n\n# m2\nm2_r_squared <- summary(m2)$r.squared\nm2_adj_r_squared <- summary(m2)$adj.r.squared\n\n# m3\nm3_r_squared <- summary(m3)$r.squared\nm3_adj_r_squared <- summary(m3)$adj.r.squared\n\n# m4\nm4_r_squared <- summary(m4)$r.squared\nm4_adj_r_squared <- summary(m4)$adj.r.squared\n\nm2_adj_r_squared - m1_adj_r_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.0005784547\n```\n\n\n:::\n\n```{.r .cell-code}\nm3_adj_r_squared - m1_adj_r_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01169598\n```\n\n\n:::\n\n```{.r .cell-code}\nm4_adj_r_squared - m3_adj_r_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.0009559246\n```\n\n\n:::\n:::\n\n\nPlease answer the following:\n\n-   **How does the** $R^2$ change from `m1` to `m4` The $R^2$ increases from 0.1073749 in `m1` to 0.1199063 in `m4`\n\n-   **How does the adjusted** $R^2$ change from `m1` to `m4` The adjusted $R^2$ actually decreases from `m1` to `m2`, suggesting that allowing the relationship between age and support to vary by sex does not improve our model's prediction. The adjusted $R^2$ increases from `m1` to `m3` by 0.011696, suggesting that modeling age with a polynomial term provides a better fit to the data. Finally The adjusted $R^2$ decreases from `m3` to `m4` by -9.5592461\\times 10^{-4}, suggesting that fitting separate polynomials by sex is uncessary.\n\n-   **Overall, which model should we prefer?** `m3` appears to provide the best fit to the data.\n\nIn practice, we can compare the relative performance of [nested models](https://www.statology.org/nested-model/) using an `F-Test` from an Analysis of Variance.\n\nBroadly, an F-Test, tests the hypothesis that the additional coefficients in the larger model are jointly 0. To test this claim, we calculate an F-statistic:\n\n$$ F =  \\frac{(SSR_1 - SSR_2)/(df_1 -df_2)}{SSR_2/df_2}$$\n\nIn words:\n\n-   $(SSR_1 - SSR_2)$ Is the difference in the Sum of Squared Residuals of the smaller model $(SSR_1)$) and the larger model $(SSR_2)$\n-   $(df_1 -df_2)$ is the difference in the \"degrees of freedom\" (total number of observations - total number of predictors) which reflects the number of additional predictors in the model.\n-   $(SSR_2)/df_2$ is the sum of squared residuals divided by the degrees of freedom in the larger model.\n\nThis statistic follows an [F-Distribution](https://en.wikipedia.org/wiki/F-distribution). If the added predictors don't produce big reductions in the Sum of Squared Residuals, this statistic will be close to 0. Likewise, if our predictors explained a lot of additional variation, this statistic would be fairly large. The larger the statistic, the less likely it is that the coefficients in the larger model are jointly 0.\n\nThe code chunk below shows how we could formally test each of our models. Comparing `m1` to `m2` (which adds an interaction term), we see the reduction in unexplained variance (SSR) is small. In short, `m2` doesn't seem to be an improvement over `m1`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_m1_vs_m2 <- anova(m1,m2)\nanova_m1_vs_m2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: support_war01 ~ age + sex + education_n\nModel 2: support_war01 ~ age * sex + education_n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1   1459 263.41                           \n2   1458 263.40  1  0.010309 0.0571 0.8112\n```\n\n\n:::\n\n```{.r .cell-code}\n# ---- Calculate F Stat by hand ----\n## Residual Sums of Squares\nanova_m1_vs_m2$RSS\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 263.4129 263.4026\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(resid(m1)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 263.4129\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(resid(m2)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 263.4026\n```\n\n\n:::\n\n```{.r .cell-code}\n# m resitrictions (how many additional coefficients in m2)\nanova_m1_vs_m2$Df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] NA  1\n```\n\n\n:::\n\n```{.r .cell-code}\nm_m2 <- length(coef(m2)) - length(coef(m1))\nm_m2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Degrees of Freedom  (n obs  - predictors)\nanova_m1_vs_m2$Res.Df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1459 1458\n```\n\n\n:::\n\n```{.r .cell-code}\ndf_m1 <- dim(m1$model)[1] - length(coef(m1))\ndf_m1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1459\n```\n\n\n:::\n\n```{.r .cell-code}\ndf_m2 <- dim(m2$model)[1] - length(coef(m2))\ndf_m2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1458\n```\n\n\n:::\n\n```{.r .cell-code}\n# F-Stat\nanova_m1_vs_m2$F\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]         NA 0.05706293\n```\n\n\n:::\n\n```{.r .cell-code}\nf_stat_m1_vs_m2 <- ((sum(resid(m1)^2) - sum(resid(m2)^2))/m_m2)/((sum(resid(m2)^2)/df_m2))\nf_stat_m1_vs_m2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05706293\n```\n\n\n:::\n\n```{.r .cell-code}\n# p-value for test that additional coefficient (interaction between age and sex) is 0\nanova_m1_vs_m2$`Pr(>F)`\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]        NA 0.8112334\n```\n\n\n:::\n\n```{.r .cell-code}\npf(f_stat_m1_vs_m2,df1 = m_m2, df2 = df_m2, lower.tail=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8112334\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize F-Stat, \n\nggplot(data.frame(x = 0:7), aes(x)) +\n  # F Distribution\n  stat_function(fun = df,\n                geom = \"area\",\n                fill = \"steelblue\",\n                alpha =.5,\n                n = 1000,\n                args = list(\n                  df1 = m_m2,\n                  df2 = df_m2                \n                  ))+\n  # F Stat\n    geom_vline(xintercept = f_stat_m1_vs_m2)+\n    annotate(\"segment\", x = .8, xend = f_stat_m1_vs_m2+.1, y = 2, yend = 2, size=1, \n             arrow=arrow(length=unit(0.30,\"cm\"), ends=\"last\", type = \"closed\"))+\n    annotate(\"text\", x = 1, y = 2, label = \"F-stat = 0.57\", hjust=0)+\n  # P-value is area under the curve to right of F Stat\n    stat_function(fun = df,\n                geom = \"area\",\n                fill = \"coral4\",\n                n = 1000,\n                alpha =.5,\n                xlim = c(f_stat_m1_vs_m2,7),\n                args = list(\n                  df1 = m_m2,\n                  df2 = df_m2                \n                  ))+\n    annotate(\"segment\", x = .8, xend = f_stat_m1_vs_m2+.5, y = 1, yend = .5, size=1, \n             arrow=arrow(length=unit(0.30,\"cm\"), ends=\"last\", type = \"closed\"))+\n    annotate(\"text\", x = 1, y = 1.1, label = \"Pr(>F) = 0.81\", hjust=0)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](07-lab-comments_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nComparing `m1` to `m3`yields significant reduction in the amount of unexplained variance. Modeling age with a polynomial term `I(age^2)` improves our model's fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_m1_vs_m3 <- anova(m1,m3)\nanova_m1_vs_m3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: support_war01 ~ age + sex + education_n\nModel 2: support_war01 ~ age + I(age^2) + sex + education_n\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1   1459 263.41                                  \n2   1458 259.79  1    3.6226 20.331 7.036e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nFinally, estimating separate polynomial's for male and female respondents doesn't appreciably improve our model's predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_m3_vs_m4 <- anova(m3, m4)\nanova_m3_vs_m4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: support_war01 ~ age + I(age^2) + sex + education_n\nModel 2: support_war01 ~ (age + I(age^2)) * sex + education_n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1   1458 259.79                           \n2   1456 259.71  2  0.075431 0.2114 0.8094\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Produce and visualize predicted values for m1 and m3\n\nNow let's produce and visualize predicted values to help us interpret the relationship between age and support for the war `m1` (our baseline model) and `m3` (our polynomial model)\n\nWe demonstrated the steps for producing predicted values in Tuesday's [lecture](https://pols1600.paultesta.org/slides/07-slides.html#64)\n\nTo review: you'll need to\n\n1.  Fit a model (already done)\n2.  Create a prediction data frame (`pred_df`)\n\n-   use `expand_grid()`\n-   vary `age` using `seq()`\n-   hold `sex` and `education` constant at typical values\n\n3.  Use this prediction data frame to obtain predicted values from each model and save the output as a new column in `pred_df`\n\n-   for example `pred_df$fit_m1 <- predict(m1, newdata = pred_df)`\n\n4.  Visualize the results using ggplot.\n\n-   use `pred_df` as your data\n-   map `age` to x axis\n-   map `fit_m1` or `fit_m3` to the y axis\n-   tell ggplot to draw a line using `geom_line()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Create a prediction data frame (`pred_df`)\npred_df <- expand_grid(\n  age = seq(\n    min(df_drww$age, na.rm = T),\n    max(df_drww$age, na.rm = T),\n    length.out = 20\n    ),\n  sex = \"Male\",\n  education_n = mean(df_drww$education_n,na.rm=T)\n    )\n\n\n# 3  Use this prediction data frame to obtain predicted values from our model\n# Save the output from predict() back into our prediction data frame\n\npred_df$fit_m1 <- predict(m1, newdata = pred_df)\npred_df$fit_m3 <- predict(m3, newdata = pred_df)\n\n# 4. Visualize the results using ggplot.\n\n\npred_df %>%\n  ggplot(aes(age, fit_m1))+\n  geom_line() +\n  ylim(.3,1.3)+\n  labs(x = \"Age\",\n       y = \"Predicted support for the war in Ukraine\",\n       title = \"Baseline Regression\")+\n  theme_bw() -> fig_m1\n\npred_df %>%\n  ggplot(aes(age, fit_m3))+\n  geom_line()+\n  ylim(.3,1.3) +\n  labs(x = \"Age\",\n       y = \"Predicted support for the war in Ukraine\",\n       title = \"Age Polynomial Regression\")+\n  theme_bw() -> fig_m3\n\n\nggarrange(fig_m1, fig_m3)\n```\n\n::: {.cell-output-display}\n![](07-lab-comments_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n**Please offer a brief interpretation of these two figures**\n\nThe left hand panel of the figure shows the predicted values from our baseline model `m1`. In general, as age increases support for the war tends to go up, although note that for a male respondent with an average level of education over the age of about 75, our model predicts greater rates of support greater than 100 percent, which is outside the range of feasible values.\n\nThe righ hand panel shows the predicted values from `m3` which model the support for the war as using a polynomial function of age --- that is\n\n$$\\text{support} = \\beta_0 + \\beta_1 \\text{age} + \\beta_2 \\text{age}^2 + \\beta_3 \\text{sex} + \\beta_4 \\text{education} + \\epsilon$$ The marginal effect of age in this model varies with the level of age:\n\n$$\\frac{\\partial \\text{support}}{\\partial \\text{age}}=\\beta_1+ 2\\times\\beta_2\\text{age}$$\n\nAn increase in age for a 19 year old is associated with marginal increase in support for the war of about 2 percentage points\n\n$$\\frac{\\partial \\text{support}}{\\partial \\text{age}}=0.0279593+2\\times-0.0001892\\times\\text{19} = 0.0207686$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m3)[2] + 2*coef(m3)[3]*(19)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      age \n0.0207686 \n```\n\n\n:::\n:::\n\n\nWhile the marginal effect for increase in age at 89 year's old is associated with a marginal decrease in support for the war of of about 0.5 percentage points.\n\n$$\\frac{\\partial \\text{support}}{\\partial \\text{age}}=0.0279593+2\\times-0.0001892\\times\\text{89} = -0.005723384$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m3)[2] + 2*coef(m3)[3]*(89)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         age \n-0.005723384 \n```\n\n\n:::\n:::\n\n\nI'd suggest some caution though in interpreting the decreased levels of support for very old respondents. There are only 50 respondents over the age of 75 in the sample (or about 2.7 percent of the overall sample).\n\nPolynomial regressions are very sensitive to /influenced by values at the end points of distributions.\n\nThe general trend is increasing support for the war with age.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(df_drww$age >75)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 50\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(df_drww$age >75)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02767017\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Produce and visualize predicted values for m2 and m4\n\nFinally, let's see how to produce and interpret predictions for models `m2` and `m4`.\n\nRecall, that in `m2` we allowed the coefficient on `age` to vary by `sex` and in `m4` our model estimates separate age curves for male and female respondents.\n\nIn the code chunk below\n\n2.  Create a new prediction data frame (`pred_df_int`)\n\n-   use `expand_grid()`\n-   vary `age` using `seq()`\n-   vary `sex = c(\"Male\",\"Female\")`\n-   hold `education` constant at a typical value\n\n3.  Use this prediction data frame to obtain predicted values from each model and save the output as a new column in `pred_df_int`\n\n-   for example: `pred_df_int$fit_m2 <- predict(m2, newdata = pred_df_int)`\n\n4.  Visualize the results using ggplot.\n\n-   use `pred_df_int` as your data\n-   map `age` to x axis\n-   map `fit_m2` or `fit_m4` to the y axis\n-   map `sex` to `col` to produce separate lines by the values of `sex`\n-   tell ggplot to draw a line using `geom_line()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Create a prediction data frame (`pred_df`)\npred_df_int <- expand_grid(\n  age = seq(\n    min(df_drww$age, na.rm = T),\n    max(df_drww$age, na.rm = T),\n    length.out = 20\n    ),\n  sex = c(\"Male\",\"Female\"),\n  education_n = mean(df_drww$education_n,na.rm=T)\n    )\n\n\n# 3. Use this prediction data frame to obtain predicted values from our model\n# Save the output from predict() back into our prediction data frame\n\npred_df_int$fit_m2 <- predict(m2, newdata = pred_df_int)\npred_df_int$fit_m4 <- predict(m4, newdata = pred_df_int)\n\n# 4. Visualize the results using ggplot.\n\n\npred_df_int %>%\n  ggplot(aes(age, fit_m2, col=sex))+\n  geom_line() +\n  ylim(.3,1.3)+\n  labs(x = \"Age\",\n       y = \"Predicted support for the war in Ukraine\",\n       col = \"Sex\",\n       title = \"Baseline Regression\")+\n  theme_bw() -> fig_m2\n\npred_df_int %>%\n  ggplot(aes(age, fit_m4, col=sex))+\n  geom_line()+\n  ylim(.25,1.3) +\n  labs(x = \"Age\",\n       y = \"Predicted support for the war in Ukraine\",\n       col = \"Sex\",\n       title = \"Age Polynomial Regression\")+\n  theme_bw() -> fig_m4\n\n\nggarrange(fig_m2, fig_m4)\n```\n\n::: {.cell-output-display}\n![](07-lab-comments_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n**Again,please offer a brief interpretation of these two figures**\n\n-   The left hand panel shows the predictions from the interaction model `m2` which allows the relationship between age and support for the war to vary by gender. While men tend to be more supportive of the war and older people tend to be more supportive of the war, there doesn't appear to be much of a difference in the relationship between age and support by gender. If the coefficient on the interaction term had been positive stastitically, the blue line of predicted values for male respondents would have been noticeably steeper. Similiarly, if the coefficient on the interaction term had be negative and statistically significant, the slope on the blue line would have been flatter compared to the slope for female respondents.\n\n-   The right hand panel shows the predicted values for `m4` which allows the marginal effect of age to vary by age **and** sex. The predicted values suggest the gap between male and female respondents gets a little larger with age, and then closes for vary old respondents, but I wouldn't put too much stock in this model. As the figure below shows, there are only a handful of respondents over the 80 or over in the data, which drive the downward trend in support. The main point of `m4` was to illustrate how predicted values help us interpret complicated models. In practice, unless we have a strong theoretical reason to expect non-linear marginal effects that vary by groups, we should probably stick to more parsimonious models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_drww %>%\n  ggplot(aes(age, support_war01, col = sex))+\n  geom_jitter(height = .1)+\n  geom_smooth(method =\"lm\", formula = y ~ poly(x,2))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 334 rows containing non-finite values (`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 334 rows containing missing values (`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](07-lab-comments_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Explore another relationship in the data (Optional)\n\nFinally, if you're finished with all the sections above, take some time to explore the data:\n\n1.  Formulate a question you could ask of the data\n2.  Estimate a model (or models) that provides insights into this question\n3.  Produce a table(s) and figure(s) that helps you interpret your model(s)\n\nFor fun, let's say the group that produces the most combination of question/model/interpretation, gets some candy next class.\n\nSome questions you might explore:\n\n-   How do demographic factors predict trust in Russia's government\n-   Are their systematic differences in who chooses not to answers questions about support for the war or trust in government?\n-   Are there noticeable regional differences in support/trust?\n-   Should we model education as numeric scale or as a categorical factor?\n-   How does the use of social media (either in general or particular types of social media) predict support for the war or Trust in government\n\n# Take the Class Survey {.unnumbered}\n\nPlease take a few moments to complete the [class survey](https://brown.co1.qualtrics.com/jfe/form/SV_5d2ZbPxo6uFcjRQ){target=\"_blank\"} for this week.\n\nThis week we're asking questions you submitted in last weeks survey. To encourage participation, let's say that if we get a 100 percent completion rate, **I will bring donuts to class on Tuesday.**\n\nIf you really hate these surveys but like donuts, you can just click through without answering any of the questions. As long as we get to 24 responses, donuts for all.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/clipboard-2.0.6/clipboard.min.js\"></script>\n<link href=\"../../site_libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js\"></script>\n<script>window.xaringanExtraClipboard(null, {\"button\":\"<i class=\\\"fa fa-clipboard\\\"><\\/i>\",\"success\":\"<i class=\\\"fa fa-check\\\" style=\\\"color: #90BE6D\\\"><\\/i>\",\"error\":\"Press Ctrl+C to Copy\"})</script>\n<link href=\"../../site_libs/font-awesome-6.4.2/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome-6.4.2/css/v4-shims.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}