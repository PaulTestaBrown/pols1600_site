{
  "hash": "f12d04c5b42a1e02d3f52ac1dafb8217",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Lab 01 - Exploring data on COVID-19 in the U.S.'\nauthor: \"Your Name HERE\"\ndate: \"Last Updated 2025-01-27\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    toc-float: true\n    toc-depth: 2\n    number-sections: true\n    embed-resources: true\n---\n\n\n\n# Overview {.unnumbered}\n\nToday, we'll continuing exploring the COVID-19 data for the U.S.\n\nWe covered a lot of ground in our last lecture. Conceptually, talked about how to\n\n-   Write and code in R Markdown\n-   Install and load packages\n-   Download and inspect data\n-   Clean and recode data\n-   Calculate simple descriptive statistics with that data\n\nTo do this, we copied and pasted a lot of code. Today, we'll **get practice writing our own code.** Specifically we will\n\n-   Repeat some steps from lecture to get our workspace and data set up\n-   Recode some additional variables\n-   Investigate what negative values mean for face mask policy\n-   Explore, in greater depth, tools for descriptive inference\n-   Revisit the question of face masks and new cases, *conditioning* on time.\n\n# Getting set up\n\n1.  Save this document in a folder for the class\n2.  Set your working director: Session \\> Set Working Directory \\> Source file location\n\n-   It's not vital today, but it's a good habit to develop.\n\n3.  Render your .qmd file to produce an `html` file\n\n# Install some additional packages\n\n-   In the code chunk below, we'll use the `install.packages()` function to install the `lubridate` and `DT` package packages\n-   Uncomment the code by removing \\#\n-   Run the code \"Live\" by sending the command to your console\n-   Once `lubridate` is installed, comment the code out by placing a \\# at the start of the line\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(c(\"lubridate\",\"DT\"))\n```\n:::\n\n\nThe `lubridate` package is a collection of functions that makes it easier to work with dates\n\nThe `DT` package allows us to display data tables in a searchable format in our html output.\n\n# Load the packages we'll be using today\n\n-   Create a code chunk\n-   Label your code chunk `packages`\n-   Use `library()` to load the following packages\n    -   `tidyverse`\n    -   `COVID19`\n    -   `lubridate`\n    -   `DT`\n\n# Download the COVID19 Data for U.S.\n\nOpen up the [slides](https://pols1600.paultesta.org/slides/01-slides#/loading-state-level-covid-data-1) from last class and copy and paste the relevant code into the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the COVID-19 data\n```\n:::\n\n\n# Replicate the data cleaning and recoding from class\n\nSpecifically please do the following, uncommenting the code and replacing the `???` with the appropriate terms\n\n1.  Create a object called `territories` that is a vector containing the names of U.S. territories\n\n-   Use `<-` and `c()` ([slides](https://pols1600.paultesta.org/slides/01-slides#/create-a-vector-of-the-territories-we-dont-want)\n\n2.  Create a new dataframe, called `covid_us`, by filtering out observations from the U.S. territories `- Use`\\<-`,`%\\>%`,`filter()`,`!`and`%in%\\` ([slides](https://pols1600.paultesta.org/slides/01-slides#/use-the-filter-command-to-filter-out-these-territories)\n3.  Create a `state` variable that is a copy of the `administrative_area_level_2`\n\n-   Use `%>%`, `mutate()` and `->`\n\n4.  Create a variable called `new_cases` from the `confirmed`. Create a variable called `new_cases_pc` that is the number of new Covid-19 cases per 100,000 citizens\n\n-   Use `%>%`,`group_by()`,`mutate()` and `lag()`, \\``/` and `*` ([slides](https://pols1600.paultesta.org/slides/01-slides#/calculate-new-covid-19-cases)\n\n5.  Create a variable called `face_masks` from the `facial_coverings` variable. ([slides](https://pols1600.paultesta.org/slides/01-slides#/create-face-mask-policy-variable)\n\n-   Treat negative and positive values the same.\n-   Recode numeric values so that they have meaningful labels\n-   Save as a factor variable so that the labels are ordered in terms of increasing levels of severity/restrictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- 1. Create territories object\n\n# territories <- c(\n#   \"American Samoa\",\n#   \"Guam\",\n#   \"Northern Mariana Islands\",\n#   \"Puerto Rico\",\n#   \"Virgin Islands\"\n#   )\n\n# ---- 2. Create covid_us data frame\n\n# covid_us <- covid %>%\n#   filter(???)\n\n# ---- 3-5. Recode variables in covid_us\n\n# covid_us %>%\n#   mutate(\n#     state = ???\n#   ) %>%\n#   dplyr::group_by(???) %>%\n#   mutate(\n#     new_cases = ??? - lag(???),\n#     new_cases_pc = ??? / ??? *100000\n#     ) %>%\n#   mutate(\n#     face_masks = case_when(\n#       ??? == 0 ~ \"No policy\",\n#       abs(???) == 1 ~ \"Recommended\",\n#       abs(???) == 2 ~ \"Some requirements\",\n#       abs(???) == 3 ~ \"Required shared places\",\n#       abs(???) == 4 ~ \"Required all times\",\n#     ) %>% factor(.,\n#       levels = c(\"No policy\",\"Recommended\",\n#                  \"Some requirements\",\n#                  \"Required shared places\",\n#                  \"Required all times\")\n#     ) \n#     ) -> ???\n```\n:::\n\n\nNext let's compare our new `face_mask` variable to the original `facial_coverings` variable using the table command.\n\nUncomment the following code and replace the generic terms `data`, `variable1`, and `variable2` with appropriate terms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# table(data$variable1, data$variable2, useNA=\"ifany\")\n```\n:::\n\n\nYou've just created a \"crosstab\" a frequency table showing the joint distribution of two variables.\n\n::: callout-note\nCrosstabs are powerful tools for getting a sense of your data and for checking whether a recode did what you wanted it to do.\n:::\n\nFinally, let's create a few more variables called `year_month` from the `date` variable and a variable describing the percent of a state's population that is fully vaccinated (`percent_vaccinated`), which we'll use later in the lab.\n\n## Uncomment and run the following code\n\nHighlight the commented code below from `# covid_us %>%` to `#   ) -> covid_us` and press `shift + cmd + C` on a mac or `shift + ctrl + C` on PC to uncomment the code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# covid_us %>%\n#   mutate(\n#     year = year(date),\n#     month = month(date),\n#     year_month = paste(year, str_pad(month, width = 2, pad=0), sep = \"-\"),\n#     percent_vaccinated = people_fully_vaccinated/population*100  \n#     ) -> covid_us\n```\n:::\n\n\n-   The `year(date)` extracts the year from our `date` variable and saves it in new column called `year`\n-   Similarly, the `month(date)` extracts the month from our `date` variable and saves it in a new column called `month`\n-   Finally the `paste()` command pastes these two variables together, with the `str_pad()` adding a leading 0 to single digit months.\n-   To calculate the percent of states population that is fully vaccinated on a given date we divide the total number of fully vaccinated by the state's population and multiply by 100 to make it a percent.\n\n# Exploring our data\n\nFrom the [documentation](https://covid19datahub.io/articles/docs.html) of the COVID19 package, we see that the numeric values of the `facial_coverings` correspond to following substantive policy regimes:\n\n-   0 - No policy\n-   1 - Recommended\n-   2 - Required in some specified shared/public spaces outside the home with other people present, or some situations when social distancing not possible\n-   3 - Required in all shared/public spaces outside the home with other people present or all situations when social distancing not possible\n-   4 - Required outside the home at all times regardless of location or presence of other people\n\nThese data come from the [Oxford Covid-19 Government Response Tracker](https://github.com/OxCGRT/covid-policy-tracker). Oxford distinguishes between policies that are in effect for the entire administrative unit (e.g. the State of New York) and policies that may be in effect in only parts of the administrative unit (e.g. New York city)\n\n> In short: positive integers identify policies applied to the entire administrative area. Negative integers are used to identify policies that represent a best guess of the policy in force, but may not represent the real status of the given area. The negative sign is used solely to distinguish the two cases, it should not be treated as a real negative value.\n\nLet's get some practice using the `filter()`, `select()` `group_by()` and `summarize()`, and `n()` commands from `dplyr` package to understand how common each these negative values are in our data.\n\n## Uncomment and run the code below,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# covid_us %>%\n#   filter(facial_coverings == -4) %>%\n#   select(date, state) %>%\n#   group_by(state) %>%\n#   summarize(\n#     n = n(),\n#     earliest_date = min(date),\n#     latest_date = max(date),\n#   )%>%\n#   arrange(earliest_date)\n```\n:::\n\n\n## Please explainwhat each line of code is doing:\n\n-   `covid_us %>%` Write your explanation here\n-   `filter(facial_coverings == -4) %>%`\n-   `select(date, state) %>%`\n-   `group_by(state) %>%`\n-   `summarize(`\n-   `n = n(),`\n-   `earliest_date = min(date),`\n-   `latest_date = max(date),`\n-   `)%>%`\n-   `arrange(earliest_date)`\n\nYou may find this [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) useful and you can find a more detailed discussion [here](https://r4ds.had.co.nz/transform.html)\n\n### Substantively, what does the previous chunk of code tell us?\n\n::: callout-note\n> Filtering data, selecting specific variables, and summarizing variables are important skills that let us \"know our data\"\n:::\n\n# Look at the source data for face mask policies\n\nTo make sure we understand what this policy variable `facial_coverings` is measuring, let's download the source data from Oxford\n\n\n::: {.cell}\n\n```{.r .cell-code}\noxford_us <- readr::read_csv(\"https://github.com/OxCGRT/USA-covid-policy/raw/master/data/OxCGRT_US_latest.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 56992 Columns: 81\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (32): CountryName, CountryCode, RegionName, RegionCode, Jurisdiction, C1...\ndbl (48): Date, C1_School closing, C1_Flag, C2_Workplace closing, C2_Flag, C...\nlgl  (1): M1_Wildcard\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\nNow let's look at the policy on face masks for Illinois. From Oxford's [codebook](https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md), we learn that variables describing face mask policies all begin with the prefix `H6_`\n\n::: callout-note\n> Using common prefixes for a variable is a good habit that will help you organize and work with your data\n:::\n\n## Please run the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noxford_us |>\n  dplyr::mutate(\n    date = lubridate::ymd(Date)\n  ) |>\n  dplyr::filter(\n    RegionName == \"Illinois\",\n    date > \"2020-08-01\", \n    date < \"2021-01-01\",\n    !is.na(H6_Notes)\n    ) |>\n  dplyr::select(date,starts_with(\"H6_\")) -> il_facemasks\nil_facemasks\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 4\n  date       `H6_Facial Coverings` H6_Flag H6_Notes                             \n  <date>                     <dbl>   <dbl> <chr>                                \n1 2020-08-21                     2       1 \"In Executive Order 2020-52, Executi…\n2 2020-08-26                     2       1 \"Effective from 26 August 2020, the …\n3 2020-09-18                     2       1 \"On 18 September, in Executive Order…\n4 2020-10-01                     4       0 \"Originally coded a 3T, but looking …\n5 2020-10-16                     4       0 \"In Executive Order (EO) 2020-59, Go…\n6 2020-11-13                     4       0 \"Noting that Executive Order 2020-71…\n7 2020-11-20                     4       0 \"Executive Order 2020-73 requires pe…\n8 2020-12-01                     3       1 \"Chicago seems to have changed its g…\n```\n\n\n:::\n:::\n\n\n## Again, explain in words, what the components of this code are doing:\n\n-   `oxford_us |>`\n-   `mutate(date = ymd(Date))|>`\n-   `filter(RegionName == \"Illinois\",`\n-   `date > \"2020-08-01\",`\n-   `date < \"2021-01-01\",`\n-   `!is.na(H6_Notes)) |>`\n-   `select(date,starts_with(\"H6_\")) -> il_facemasks`\n-   `il_facemasks`\n\nLet's take a look at the `H6_Notes` variable for 2020-09-18\n\n\n::: {.cell}\n\n```{.r .cell-code}\nil_facemasks$H6_Notes[3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"On 18 September, in Executive Order 2020-55, the Governor reissued most executive orders, extending a majority of the provisions through 17 October 2020. This includes mask requirements.      https://web.archive.org/web/20200922144918/https://www2.illinois.gov/Pages/Executive-Orders/ExecutiveOrder2020-55.aspx\"\n```\n\n\n:::\n:::\n\n\nNow update the code to select `H6_Notes` variable for 2020-10-01\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# il_facemasks$H6_Notes[???]\n```\n:::\n\n\n## What have we learned about our variables measuring `face_mask` policy\n\n# Explore R's functions for generating summary statistics\n\nIn class, we kind of rushed through our discussion of descriptive statistics. Let's take a little time to review these concepts in more detail and see how to calculate them in R.\n\n## Measures of Central Tendency\n\nMeasures of central tendency describe what a typical value of some variable. In this course, we'll use three measures of what's typical:\n\n-   mean\n-   median\n-   mode\n\n### Mean\n\nOne of the most frequent measures of central tendency we'll use in this course is a mean or average.\n\nSuppose we have $n$ observations of some variable $x$. We can calculate the mean of $\\bar{x}$ (\"x bar), by adding up all the values of x\n\n$$ \n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i \n$$\n\nWe'll see later in the course that means are closely related to the concept of expected values in probability and that conditional means (which we'll calculate below) are central to thinking about linear regression.\n\nFor now, please calculate the mean (average) number of new cases per 100,000 residents in our data:\n\n\n::: {.cell}\n\n:::\n\n\nLast class, when we calculated the the average number of new cases under each type of face mask policy, we were calculating a **conditional mean** the mean of some variable, conditional on some other variable taking a specific value.\n\nLater in the course we'll talk about how we can use something like a mean to estimate an **Expected Value**: Something like\n\n$$ E[Y|X=x] $$\n\nOr to make it more concrete:\n\n$$ E[\\text{New Cases} | \\text{Policy = \"recommended\"}] $$\n\nIn code, we could accomplish this manually, using the index operator:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mean(covid_us$new_cases_pc[covid_us$face_masks == \"No policy\"], na.rm=T)\n```\n:::\n\n\n#### How would we calculate the conditional mean of `new_cases_pc` when `face_masks` equals \"Recommended\"\n\n\n::: {.cell}\n\n:::\n\n\nBy using `group_by()` with `summarise()` we can accomplish this more quickly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# covid_us%>%\n#   group_by(face_masks)%>%\n#   summarise(\n#     new_cases_pc = mean(new_cases_pc, na.rm=T)\n#   )\n```\n:::\n\n\n### Median\n\nThe median is another measure of what's typical for variables that take numeric values\n\nImagine, we took our data new Covid-19 cases and *arranged them in ascending order*, from the smallest value to highest value\n\nThe median would be the value in the exact middle of that sequence, also known as the 50th percentile.[^1]\n\n[^1]: It's a little more complicated as we need to decide how to handle situations where their are ties, or an even number of cases. For now we'll just accept the default rules `R` uses.\n\nFormally, we can define that median as:\n\n$$\nM_x = X_i : \\int_{-\\infty}^{x_i} f_x(X)dx=\\int_{x_i}^\\infty f_x(X)dx=1/2\n$$\n\nWhich might look like Greek to you, which is fine for now. Just think of it as the middle value.\n\n#### Please calculate the median number of new Covid-19 cases per 100,000 using the `median()` function. How does it compare to the mean?\n\n\n::: {.cell}\n\n:::\n\n\n::: callout-note\n> Medians are less influenced by outliers than means\n:::\n\n### Modes\n\nConceptually, a mode describes the most frequent outcome.\n\nModes are useful for describing what's typical of \"nominal\" or categorical data like our measure of face mask policy.\n\nTo calculate the mode of our `face_masks` variable, wrap the output of `table()` with the `sort()` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sort(table(covid_us$face_masks))\n```\n:::\n\n\nFor numeric data, modes correspond to the peak of a variable's density function (more on this later in the class).\n\nYou can get a sense of the relationship between, means, median's and modes from this helpful figure from [Wikipedia](https://en.wikipedia.org/wiki/Mode_(statistics)):\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Visualisation_mode_median_mean.svg/240px-Visualisation_mode_median_mean.svg.png)\n\n## Measures of Dispersion\n\nMeasures of dispersion describe how much the data \"vary.\" Let's discuss the following ways we can summarize how our data vary:\n\n-   range\n-   percentile range\n-   variance\n-   standard deviation\n\n### Range\n\nThe range of a variable is simply it's minimum and maximum value\n\n#### Please calculate the range of our `new_cases_pc` using the `range()` function\n\n\n::: {.cell}\n\n:::\n\n\n#### What states on what dates observed these minimum and maximum values?\n\n\n::: {.cell}\n\n:::\n\n\n### Percentiles Ranges\n\nThe $p$-th percentile is the value of the observation such that 100\\*p percent of the data are to the left and 100-100\\*p are two the right.\n\n$$\np_x = X_i : \\int_{-\\infty}^{x_i} f_x(X)dx= p; \\int_{x_i}^\\infty f_x(X)dx=1-p\n$$\n\nThe median is just the 50th percentile\n\nIn R we calculate the $p$-th percentile using the `quantile()` setting the `probs` argument to the $p/100$ percentile that we we want.\n\n#### Please use the `quantile()` function to calculate the 25th and 75th percentiles of the `new_cases_pc` variable.\n\n\n::: {.cell}\n\n:::\n\n\nThe 25th and 75th percentile define the \"Interquartile Range\" where 50 percent of the observations lie within this range, and 50 percent lie outside the range.\n\n### Variance\n\nVariance describes how much observations of a given measure vary around that measure's mean.\n\nThe variance in a given sample is calculated by taking the average of the sum of squared deviations (i.e. differences) around a measure's mean.\n\n$$ \n\\sigma^2_x=\\frac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})^2\n$$\n\n-   $x_i-\\bar{x}$ is the deviation of each observation from the overall mean\n-   $(x_i-\\bar{x})^2}$ squaring this ensures that we treat positive and negative deviations the same when calculating the overall variance\n-   $\\sum_{i=1}$ sums up all the differences\n-   $\\frac{1}{n-1}$ is like taking the average of these differences (we divide by $n-1$ instead of $n$ for [statistical reasons](https://web.ma.utexas.edu/users/mks/M358KInstr/SampleSDPf.pdf) that we'll return two when we talk about estimation)\n\n#### Use the `var()` function to calculate the variance of the `new_cases_pc` variable.\n\n\n::: {.cell}\n\n:::\n\n\nVariance will be important for thinking about uncertainty and inference (e.g. how might our estimate have been different)\n\n### Standard Deviations\n\nA standard deviation is simply the square root of variable's variance.\n\n$$\n\\sigma_x=\\sqrt{\\sigma^2_x}=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})^2}\n$$\n\nStandard deviations are easier to interpret because their units are the same as variable.\n\nThink of them as a measure of the typical amount of variation for variable.\n\n#### let's use the `sd()` function to calculate the standard deviation of the `new_cases_pc` variable\n\n\n::: {.cell}\n\n:::\n\n\n## Measures of Association\n\nMeasures of association describe how variables relate to each other.\n\n### Covariance\n\nCovariance describes how two variables \"co-vary\".\n\nWhen $x$ is above its mean, $y$ also tends to be above it's mean, these variables have a positive covariance.\n\nIf when $x$ tends to be high, $y$ tends to be low, these variables have a negative variance\n\nFormally, the sample[^2] covariance of two variables can written as follows:\n\n[^2]: Astute readers might ask, why are you talking about samples? We'll come back to this later in the course when we talk about probability, estimation and statistical inference.\n\n$$ \ncov(x,y)=\\frac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})\n$$\n\n#### Please calculate the covariance between the percent of state's population that is fully vaccinated (`percent_vaccinated`) and `new_cases_pc` using the `var()` function\n\n\n::: {.cell}\n\n:::\n\n\n### Correlation\n\nLike variances, covariances don't really have intrinsic meaning, since x and y can be measured on very different scales.\n\nThe correlation between two variables takes their covariance and scales this by the standard deviation of each variable, creating a measure that can range from -1 (perfect negative correlation) to 1 perfect positive correlation.\n\nAgain, we can write this formally\n\n$$ \n\\rho_{x,y} = \\frac{cov(x_y)}{\\sigma_x,\\sigma_y}\n$$\n\nBut don't sweat the formulas too much. I'm just contractually obligated to show you math.\n\n#### Calculate the correlation between the percent of state's population that is fully vaccinated (`percent_vaccinated`) and `new_cases_pc` using the `cor()` function.\n\nYou'll need to set the argument `use=\"complete.obs`\n\n\n::: {.cell}\n\n:::\n\n\nHmm... That seems a little strange. What if we calculated the correlation between vaccination rates and new cases separately for each month in 2021\n\n#### Uncomment and interpret the output of the code below\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# covid_us %>%\n#   filter(year > 2020)%>%\n#   ungroup() %>%\n#   group_by(year,month)%>%\n#   summarise(\n#     mn_per_vax = mean(percent_vaccinated, na.rm=T),\n#     cor = cor(new_cases_pc, percent_vaccinated, use = \"complete.obs\")\n#   )\n```\n:::\n\n\n# Facemasks and New Cases of Covid-19\n\nLet's return to the question of the average number of new Covid-19 cases (per 100,000) for different types of face mask policies.\n\nWe ended our previous class with this result:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# covid_us %>%\n#   filter(!is.na(face_masks))%>%\n#   group_by(face_masks)%>%\n#   summarize(\n#     new_cases_pc = round(mean(new_cases_pc, na.rm=T),2)\n#   ) -> face_mask_summary\n# face_mask_summary\n```\n:::\n\n\n## What do these averages really tell us?\n\n## Add another filter to the code above to caluclate the conditional means for just 1 month in a particular year in the data\n\nIf we limit our comparison to a more narrow time period, say one month in one year, we're making a fairer comparison between states that are likely facing more similar conditions/challenges.\n\n\n::: {.cell}\n\n:::\n\n\n### Add another arguement to the group_by() command from the original code to calcutate the conditional means by face mask policy for each month in each year of the data\n\n-   Save the output of summarize into an object called `cases_by_month_and_policy`\n\n\n::: {.cell}\n\n:::\n\n\n### Uncomment the code below to display `cases_by_month_and_policy` in a searchable table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DT::datatable(cases_by_month_and_policy,\n#               filter = \"top\")\n```\n:::\n\n\n### Uncomment the code below to visualize this `cases_by_month_and_policy`\n\nWhat does this figure tell us?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cases_by_month_and_policy %>%\n#   ggplot(aes(\n#     x= year_month,\n#     y = new_cases_pc,\n#     col=face_masks))+\n#   geom_point()+coord_flip()\n```\n:::\n\n\nSo this figure graphically displays the data `cases_by_month_and_policy`\n\nFrom about August 2020 to October 2020 states with facemask requirements saw much lower rates of new cases than states that only recommended face masks.\n\nAfter October 2020, every state has at least some requirement, and the differences between the stringency of requirements is a little harder to see.\n\nAgain this stuff is complicated. Lots of things are changing and these month comparisons are by no means perfect. Lot's of things differ between states with different mask policies. What we'd really like to know is a sort of counterfactual comparison between the number new cases in a state with a given policy and what those new cases would have been had that state had a different policy.\n\nThe problem is, we don't get to see that counterfactual outcome. So how can we make causal claims about the effects of facemasks, or any other policy that interests us? Finding creative ways to answer these questions is the key to making credible causal claims.\n\nNext week, we'll explore how to make this figure and many more from our data\n\n# Summary\n\nLike lecture, we covered a lot in this first lab. Specifically we:\n\n-   Practiced installing packages and setting up our workspace\n-   Downloaded multiple data sets\n-   Saw how we could use functions to transform and explore data. Specifically we used:\n    -   `%>%`, the pipe command, to chain together multiple functions\n    -   `filter()` to filter data based on logical comparisons\n    -   `select()` to select specific variables from our data\n    -   `group_by()` to apply functions by one or more grouping variables\n    -   `mutate()` to create new columns in our data\n    -   `summarise()` to summarize the output of functions, often by groups\n    -   `arrange()` to sort data by a specific variable\n-   Explored different tools of descriptive inference using:\n    -   `means`, `medians` and `modes` to describe typical values of data\n    -   `ranges`, `percentile ranges`, `variances` and `standard deviations` to describe how our data vary\n    -   `covariances` and `correlations` to describe relationships between variables in our data\n-   Explored how the relationships between face masks and Covid-19 changed when we *conditioned* on time and looked within months as opposed to accross the whole data set.\n\nNot all of this will make sense the first time through. That's OK. The things we've done today, we will do again and again over the course of the semester. Overtime, concepts that seemed crazy or confusing, we'll become second nature.\n\nAfter class, on the course website and canvas, you'll find my \"commented\" solutions today's lab.\n\nIf there are particular parts of the lab where we went too fast, or things didn't make sense. Take a moment to review these notes. Try re-running the code. Changing the code. Break the code and see if you can fix it.\n\nWhen you encounter a problem you can solve, send me an email, or ask your friends, or doctor Google. I guarantee you, someone else has had a similar question or problem.\n\nThe only dumb question in this course is a question you don't ask!\n\nPlease upload the html file produced by your .Rmd file to [Canvas](https://canvas.brown.edu/courses/1098409/assignments)\n\nFinally, please take a moment to complete this weeks [class survey](https://brown.co1.qualtrics.com/jfe/form/SV_bPGJjZUbZ55PR2K)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}