{
  "hash": "630f4216a3a2616cfb3a58586bb9e3de",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 12:\"\nsubtitle: \"Review, Presentations, and Workshops\"\nauthor: \"Paul Testa\"\nformat: \n  revealjs:\n    author: \"Paul Testa\"\n    height: 900\n    width: 1600\n    # css: css/brown.css\n    theme: ../files/slides.scss\n    logo: brown.png\n    footer: \"POLS 1600\"\n    multiplex: false\n    transition: fade\n    slide-number: c\n    incremental: false\n    center: false\n    menu: true\n    scrollable: true\n    highlight-style: github\n    progress: true\n    code-overflow: wrap\n    # title-slide-attributes:\n    #   data-background-image: ../../assets/stat20-hex-bg.png\n    #   data-background-size = contain\n---\n\n\n\n\n\n\n\n\n\n\n\n\nclass: inverse, center, middle\n# Overview\n\n\n## General Plan\n\n- Setup\n- Feedback\n- Review\n  - Statistical Inference\n  - Causal Inference\n  - Linear Models\n  - Confidence intervals and Hypothesis tests\n- Presentations\n\n\n\nclass:inverse, middle, center\n# 💪\n## Get set up to work\n\n\n## New packages\n\nFirst we'll install some packages that you will need for your presentations\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Uncomment and run:\n# install.packages(remotes)\n# remotes::install_github('yihui/xaringan')\n# devtools::install_github(\"gadenbuie/xaringanExtra\")\n# install.packages(\"xaringanthemer\")\n```\n:::\n\n\n\n\n\n\n## Packages for today\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nthe_packages <- c(\n  ## R Markdown\n  \"kableExtra\",\"DT\",\"texreg\",\n  ## Tidyverse\n  \"tidyverse\", \"lubridate\", \"forcats\", \"haven\", \"labelled\",\n  ## Extensions for ggplot\n  \"ggmap\",\"ggrepel\", \"ggridges\", \"ggthemes\", \"ggpubr\", \n  \"GGally\", \"scales\", \"dagitty\", \"ggdag\", \"ggforce\",\n  # Graphics:\n  \"scatterplot3d\", #<<\n  # Data \n  \"COVID19\",\"maps\",\"mapdata\",\"qss\",\"tidycensus\", \"dataverse\", \n  # Analysis\n  \"DeclareDesign\", \"easystats\", \"zoo\"\n)\n```\n:::\n\n\n\n\n## Define a function to load (and if needed install) packages\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nipak <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n```\n:::\n\n\n\n\n## Load packages for today\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nipak(the_packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   kableExtra            DT        texreg     tidyverse     lubridate \n         TRUE          TRUE          TRUE          TRUE          TRUE \n      forcats         haven      labelled         ggmap       ggrepel \n         TRUE          TRUE          TRUE          TRUE          TRUE \n     ggridges      ggthemes        ggpubr        GGally        scales \n         TRUE          TRUE          TRUE          TRUE          TRUE \n      dagitty         ggdag       ggforce scatterplot3d       COVID19 \n         TRUE          TRUE          TRUE          TRUE          TRUE \n         maps       mapdata           qss    tidycensus     dataverse \n         TRUE          TRUE          TRUE          TRUE          TRUE \nDeclareDesign     easystats           zoo \n         TRUE          TRUE          TRUE \n```\n\n\n:::\n:::\n\n\n\n\n\n\nclass:inverse, middle, center\n# 📢\n## Feedback\n\n\n## Feedback on Drafts\n\n- Posted before class on Thursday.\n\n- If you haven't submitted a file on Canvas, do it by COB today.\n\n- For Thursday's class:\n  \n  - Today and tomorrow, work on translating your draft into a slide presentation\n  \n  - Come to class with a set of tasks to work on for your presentation.\n\n- Sunday, May 1st, upload final presentations to Canvas\n\n- Sunday, May 8, upload final papers to Canvas\n  - You can have a 1-week extension, just email, no questions asked, but must submit by May 15.\n  \n\n\n\n\nclass:inverse, middle, center\n# 🔍\n## Review\n\n\n\n## What I hope you've learned:\n\nCore Concepts:\n\n- Statistical Inference\n\n- Causal Inference\n\n- Linear Models\n\n- Confidence intervals and Hypothesis tests\n\nKey Skills:\n\n- How to load, transform, summarize, and visualize data\n\n- How to estimate, evaluate, present, and interpret linear models\n\n\n\n\nclass:inverse, middle, center\n# 🔍\n# Core Concepts\n\n\n## Statistical Inference:\n\n- Statistical inference involves quantifying uncertainty about what could have happened\n\n- We describe uncertainty about what could have happened with distributions\n\n- We can generate these distributions via\n\n  - simulation (Bootstrapping and permutations)\n  \n  - analytic theory (Limit Theorems)\n\n- We quantify uncertainty using confidence intervals and hypothesis tests\n\n\n\n\n## Causal Inference\n\n- Causal inference involves making counterfactual claims about what would have happened had some causal factor $(Z)$ been present or absent.\n\n- The fundamental problem of causal inference is that for an individual observation, we only observe one of many potential outcomes $(Y(Z))$.\n\n- The statistical solution to this problem moves from individual causal effects ($\\tau_i = Y_i(1) - Y_i(0)$) to average causal effects $(\\tau = ATE = E[Y(1)]-E[Y(0)])$\n\n- Experimental designs identify the ATE by randomly assigning treatment $\\to$ $Y(1), Y(0), X, U, \\perp Z$\n  \n- Observational designs approximate the experimental ideal based on identifying assumptions that claim conditional independence $\\to$ $Y(1), Y(0), X, U, \\perp Z |X$. \n  \n  - Difference in Difference $\\to$ Parallel Trends\n  - Regression Discontinuity $\\to$ Continuity at the cut off\n  - Instrumental Variables $\\to$ The exclusion restriction\n  - Regression $\\to$ Selection on observable\n\n\n## Linear Regression\n\n- Linear regression provides a linear estimate of the Conditional Expectation Function\n\n  - Bivariate: $E[Y|x] = \\beta_0 + \\beta_1 x +\\epsilon$\n  - Multiple regression: $E[Y|X] = X\\beta +\\epsilon  = \\beta_0 + \\beta_1 x_1 \\dots \\beta_k x_k +\\epsilon$\n\n- Ordinary Least Linear regression finds coefficients $\\beta$ by minimizing the sum of squared errors $(\\sum \\epsilon^2)$\n\n- Linear regressions partition variance in the outcome into variance explained by the model $(X\\beta)$ and variance not explained by the model ($\\epsilon$). \n\n  - A model's $R^2$ describes the proportion of the overall variance in outcome explained by the predictors\n\n\n## Linear Regression\n\n- The coefficient on a predictor describes how the outcome is expected to change with a 1-unit change in that predictor\n\n- Controlling for multiple variables isolates the variation in the outcome explained by one predictor by removing (controlling for) the variation in the outcome and that predictor explained by the other predictors.\n\n  - We control for covariates that are common causes of both our key predictor and our outcome to address omitted variable bias (spurious correlation)\n\n  - We avoid controlling for covariates that our common consequences of our outcome and predictor (collider bias)\n\n\n## Linear Regression\n\n- We present linear regression using regression tables where:\n\n  - Each column corresponds to a model\n  - Each row corresponds to a coefficient in the model (with standard errors in parentheses and asterisks denoting p<0.05)\n\n- We use generalized linear models to help us incorporate information about our outcomes to improve our models' predictions\n\n  - Logistic regression is commonly used to model binary outcomes\n  \n  - Poisson regression is commonly used to model counts\n  \n\n- Plots of predicted values can help us interpret more complicated regression models such as:\n\n  - polynomial regressions where the marginal effect of one predictor varies non-linearly\n  \n  - interaction models, where the marginal effect of one predictor varies with the value of another predictor\n  \n  - generalized linear models \n\n\n\n## Confidence intervals\n\n- A confidence interval describes a range of plausible values for the true (population) value of our estimate\n\n- Our confidence is about the interval:\n\n  - $(1-\\alpha)\\times 100%$ of the intervals we could construct in repeated sampling are expected to contain the true (population) value of the thing we're estimating\n\n- To construct a confidence interval we need: \n\n  - An estimate $(\\hat{\\theta})$\n  - A standard error $(\\hat{\\sigma_{\\hat{\\theta}}})$ (the standard deviation of sampling distribution)\n  - A critical value derived from the hypothetical sampling $(z_{\\alpha/2})$\n\n- With these three components the $(1-\\alpha)\\times 100%$ is $\\hat{\\theta}\\pm z_{\\alpha/2} \\times \\hat{\\sigma_{\\hat{\\theta}}}$\n\n- We report confidence intervals in text: $\\beta = 0.9$ $[0.7, 0.11]$\n\n- We interpret estimates as being statistically significant, if 0 is outside the confidence interval\n\n\n\n## Hypothesis Tests\n\n- A hypothesis test quantifies how likely it is that we would observe what we did (our test statistic), if some claim about the world were true (our hypothesis).\n\n- Typically, we test a null hypothesis that expresses our belief that their is no relationship between variables.\n\n  - $\\tau = E[Y|Z=1] - E[Y|Z=0] = 0 \\to$ No average treatment effect \n  - $\\beta = 0 \\to$ No relationship between predictor and outcome \n\n- If our claim were true, then under the null, our test statistic would have a distribution centered around the truth.\n\n- We can describe this distribution via:\n\n  - simulation (e.g. permuting the outcome)\n  - analytic theory (CLT)\n\n- We quantify our uncertainty using a p-value which describes the probability of observing a test statistic as extreme or more extreme in a world where our null hypothesis was true\n\n  - If our p-value is small (p < 0.05), we reject the null hypothesis \n\n  - If our p-value is large (p > 0.05), we fail to reject the null, or retain the null hypothesis\n\n\n\nclass:inverse, middle, center\n# 🔍\n# Key Skills\n\n\n## How to load, explore and transform data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load data\nload(\"df.rda\")\ndf <- readr::read_csv(\"df.rda\")\nlibrary(tidyverse)\n## Explore data\nhead(df)\ntable(df$y)\n\n# Transfrom data:\ndf %>%\n  mutate(\n    dv = ifelse(var < 0, NA, y),\n    iv = case_when(\n      x == 1 ~ \"Low\",\n      x == 2 ~ \"Medium\"\n      x == 3 ~ \"High\",\n      T ~ NA_character_\n    ),\n    covar_std = scale(z)\n  ) -> df\n```\n:::\n\n\n\n\n## How to summarize data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(df$dv)\n\ndf %>%\n  group_by(iv) %>%\n  summarize(\n    min = min(dv,na.rm = T),\n    median = median(dv,na.rm = T),\n    mean = median(dv,na.rm = T),\n  )\n```\n:::\n\n\n\n\n\n## How to visualize data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# data\ndf %>%\n  # aesthetics\n  ggplot(aes(x = iv, y = dv))+\n  # geometries\n  geom_point() -> figure1\n```\n:::\n\n\n\n\n\n\n## How to estimate and evaluate\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estimate models\nm1 <- lm(dv ~ iv, df)\nm2 <- lm(dv ~ iv + covar_std, df)\nm3 <- glm(dv ~ iv + covar_std, df, family = binomial)\n\n# evaluate models\nsummary(m1)\nconfint(m2)\n```\n:::\n\n\n\n\n## How to present, and interpret linear models\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Regression Table\ntexreg::htmlreg(list(m1, m2, m3))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Produce Predicted values\n\npred_df <- expand_grid(\n  iv = c(\"Low\",\"Medium\",\"High\"),\n  covar_std = 0\n)\n\npred_df_m2 <- cbind(pred_df, predict(m2, newdata = pred_df), interval = \"confidence\")\n\n# Plot Predicted values\npred_df_m2 %>%\n  ggplot(aes(iv, fit))+\n  geom_pointrange(aes(ymin = lwr, ymax = upr))\n```\n:::\n\n\n\n\n\nclass: inverse, center, middle\n# 💡\n# Final Presentations\n\n\n## Final Presentations\n\n- Next Tuesday your groups will present some of the findings from your projects\n\n  - 10 Minutes per group\n  \n  - 8-12 slides (15 max)\n  \n  - 2 Minute Q&A\n\n- On Thursday, we will work through the templates you've been provided\n\n- Don't have to present the finished product\n\n\n\n## Final Presentation Structure\n\n1. Motivation\n\n2. Research Question\n\n3. Theory\n\n4. Expectations\n\n5. Data \n  - Summary\n  - Descriptive Table and/or Figure (Optional)\n\n6. Design\n\n7. Results\n\n  - Summary\n  - Table (Optional)\n  - Figure (Optional)\n\n8. Conclusion\n\n  - Appendices (Extra Slides Optional)\n\n\n## Template\n\nLet's open up the template and explore.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}