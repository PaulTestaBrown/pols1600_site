{
  "hash": "2fb6d1a03f26435c39f996b5e58d03d7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"POLS 1600\"\nsubtitle: \"Quantifying uncertainty:<br> Confidence Intervals &<br>Hypothesis Tests\"\ndate: last-modified\ndate-format: \"[Updated ]MMM D, YYYY\"\nformat: \n  revealjs:\n    theme: brownslides.scss\n    logo: images/pols1600_hex.png\n    footer: \"POLS 1600\"\n    multiplex: false\n    transition: fade\n    slide-number: c\n    incremental: true\n    center: false\n    menu: true\n    scrollable: true\n    highlight-style: github\n    progress: true\n    code-overflow: wrap\n    chalkboard: true\n    html-math-method: mathjax\n    # include-after-body: title-slide.html\n    title-slide-attributes:\n      align: left\n      data-background-image: images/pols1600_hex.png\n      data-background-position: 90% 50%\n      data-background-size: 40%\nfilters:\n  - openlinksinnewpage\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  message: false\n  cache: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n# {{< fa map-location>}} Overview {.inverse}\n\n## Class Plan\n\n- Announcements\n- Feedback\n- Topics:\n  - Sampling distributions and standard errors (15 minutes)\n  - Confidence intervals (15 minutes )\n  - Hypothesis testing (15 minutes)\n  - Quantifying uncertainty for regression (15 minutes)\n\n## Announcements\n\n- Final lab this week.\n\n- Next week's lecture:\n  - Workshop/Review/special topics\n  - Ask questions in the survey\n\n- Feedback on A2 by tomorrow.\n\n## Setup: Packages for today\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Pacakges for today\nthe_packages <- c(\n  ## R Markdown\n  \"kableExtra\",\"DT\",\"texreg\",\"htmltools\",\n  ## Tidyverse\n  \"tidyverse\", \"lubridate\", \"forcats\", \"haven\", \"labelled\",\n  ## Extensions for ggplot\n  \"ggmap\",\"ggrepel\", \"ggridges\", \"ggthemes\", \"ggpubr\", \n  \"patchwork\",\n  \"GGally\", \"scales\", \"dagitty\", \"ggdag\", \"ggforce\",\n  # Data \n  \"COVID19\",\"maps\",\"mapdata\",\"qss\",\"tidycensus\", \"dataverse\", \n  # Analysis\n  \"DeclareDesign\", \"easystats\", \"zoo\", \"boot\", \"modelr\" ,\"purrr\"\n)\n\n## Define a function to load (and if needed install) packages\n\nipak <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n\n## Install (if needed) and load libraries in the_packages\nipak(the_packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   kableExtra            DT        texreg     htmltools     tidyverse \n         TRUE          TRUE          TRUE          TRUE          TRUE \n    lubridate       forcats         haven      labelled         ggmap \n         TRUE          TRUE          TRUE          TRUE          TRUE \n      ggrepel      ggridges      ggthemes        ggpubr     patchwork \n         TRUE          TRUE          TRUE          TRUE          TRUE \n       GGally        scales       dagitty         ggdag       ggforce \n         TRUE          TRUE          TRUE          TRUE          TRUE \n      COVID19          maps       mapdata           qss    tidycensus \n         TRUE          TRUE          TRUE          TRUE          TRUE \n    dataverse DeclareDesign     easystats           zoo          boot \n         TRUE          TRUE          TRUE          TRUE          TRUE \n       modelr         purrr \n         TRUE          TRUE \n```\n\n\n:::\n:::\n\n\n\n\n## Feedback\n\n![](https://media1.tenor.com/m/wDzDbUBVbW4AAAAC/the-critic-it-stinks.gif)\n\n\n::: {.cell}\n\n:::\n\n\n\n## What did we like {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-4b41ed1e6c04f9540c23\" style=\"width:100%;height:90%;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-4b41ed1e6c04f9540c23\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"Great question!\",\"- conditional probability\",\"I liked how we were able to chose our own predictors/outcomes to look into from the provided data\",\"The background information on probability was very interesting and helpful!\",\"I loved the embedded code in this week's lecture that allowed us to play around with graphs. It helped me understand the concepts and get some coding practice\",\"Tuesday's class had good timing and I liked using data from the ANES during lab.\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Likes<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":6,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Likes\",\"targets\":1}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[6,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n## What did we dislike {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-9fff1b267981bddf18d8\" style=\"width:100%;height:90%;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9fff1b267981bddf18d8\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"Also a great question!\",\"i did not have fun with this lab lol - i couldn't keep up and had a lot of trouble downloading the data\",\"I think we should make loading data before class mandatory because my group struggled to get things moving in the beginning of the class because some of us were not ready.\",\"Nothing!\",\"a cipher\",\"Visualizing data is still hard\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Dislikes<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":6,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Dislikes\",\"targets\":1}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[6,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n## What are we streaming {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-63c727e71790b0a5de6d\" style=\"width:100%;height:90%;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-63c727e71790b0a5de6d\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"Nimona\",\"gossip girl\",\"YouTube?\",\"40hz 6hz gamma waves for focus, concentration, memory\",\"Nikita\",\"Bel-Air on peacock\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Streaming<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":6,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Streaming\",\"targets\":1}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[6,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n## Goals:{.smaller}\n\n- A [sampling distribution]{.blue} is a theoretical distribution of estimates obtained in repeated sampling\n\n  - What could have happened?\n\n- A [standard error]{.blue} (SE) is the standard deviation of the sampling distribution\n\n- We can calculate SEs via [simulation]{.blue} and [analytically]{.blue}\n\n- We can use SEs to construct [confidence intervals]{.blue} and conduct [hypothesis tests]{.blue} allowing us to [quantify uncertainty]{.blue}\n\n\n\n# {{< fa concepts >}} Sampling distributions and standard errors {.inverse}\n\n## Populations and samples{.smaller}\n\n\n- [Population]{.blue}: All the cases from which you could have sampled\n\n- [Parameter:]{.blue} A quantity or quantities of interest often generically called $\\theta$ (\"theta\"). What we want to learn about our population\n\n- [Sample:]{.blue} A (random) draw of observations from that population\n\n- [Sample Size:]{.blue} The number of observations in your draw (without replacement)\n\n## Estimators, estimates, and statistics{.smaller}\n\n- [Estimator:]{.blue} A rule for calculating an *estimate* of our parameter of interest. \n\n- [Estimate:]{.blue} The value produced by some estimator for some parameter from some data. Often called $\\hat{\\theta}$ \n\n- [Unbiased estimators:]{.blue} $E(\\hat{\\theta})=E(\\theta)$ On average, the estimates produced by some estimator will be centered around the truth\n\n- [Consistent estimates:]{.blue} $\\lim_{n\\to \\infty} \\hat{\\theta_N} = \\theta$ As the sample size increases, the estimates from an estimator converge in probability to the parameter value\n\n- [Statistic:]{.blue} A summary of the data (mean, regression coefficient, $R^2$). An estimator without a specified target of inference \n\n## Distrubtions and standard errors{.smaller}\n\n- [Sampling Distribution:]{.blue} How some estimate would vary if you took [repeated samples]{.blue} from the population\n\n- [Standard Error:]{.blue} The standard deviation of the sampling distribution\n\n- [Resampling Distribution:]{.blue} How some estimate would vary if you took repeated samples [from your sample WITH REPLACEMENT]{.blue} \n    - \"Sampling from our sample, as the sample was sampled from the population.\"\n\n## Sampling distributions{.smaller}\n\n:::: panel-tabset\n\n## Overview\n\n:::{.nonincremental}\n\n- Treat the 2024 NES pilot as the population\n\n- Take repeated samples of size N = 10, 30, 300\n\n- For each sample of size N, calculate the sample mean of `age`\n\n- Plot the distribution of sample means (i.e. the sampling distribution)\n\n:::\n\n## {{<fa code>}} Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Data\nload(url(\"https://pols1600.paultesta.org/files/data/nes24.rda\"))\n\n# ---- Population ----\n\n# Population average\nmu_age <- mean(df$age, na.rm=T)\n# Population standard deviation\nsd_age <- sd(df$age, na.rm = T)\n\n# ---- Function to Take Repeated Samples From Data ----\n\nsample_data_fn <- function(\n    dat=df, var=age, samps=1000, sample_size=10,\n    resample = F){\n  if(resample == F){\n  df <- tibble(\n  sim = 1:samps,\n  distribution = \"Sampling\",\n  size = sample_size,\n  sample_from = \"Population\",\n  pop_mean = dat %>% pull(!!enquo(var)) %>% mean(., na.rm=T),\n  pop_sd = dat %>% pull(!!enquo(var)) %>% sd(., na.rm=T),\n  se_asymp = pop_sd / sqrt(size),\n  ll_asymp = pop_mean - 1.96*se_asymp,\n  ul_asymp = pop_mean + 1.96*se_asymp,\n) %>% \n  mutate(\n    sample = purrr::map(sim, ~ slice_sample(dat %>% select(!!enquo(var)), n = sample_size, replace = F)),\n    sample_mean = purrr::map_dbl(sample, \\(x) x %>% pull(!!enquo(var)) %>% mean(.,na.rm=T)),\n    ll = sample_mean - 1.96*sd(sample_mean),\n    ul = sample_mean + 1.96*sd(sample_mean)\n  )\n  }\n  if(resample == T){\n    df <- tibble(\n  sim = 1:samps,\n  distribution = \"Resampling\",\n  size = sample_size,\n  sample_from = \"Sample\",\n  pop_mean = dat %>% pull(!!enquo(var)) %>% mean(., na.rm=T),\n  pop_sd = dat %>% pull(!!enquo(var)) %>% sd(., na.rm=T),\n  se_asymp = pop_sd / sqrt(size),\n  ll_asymp = pop_mean - 1.96*se_asymp,\n  ul_asymp = pop_mean + 1.96*se_asymp,\n) %>% \n  mutate(\n    sample = purrr::map(sim, ~ slice_sample(dat %>% select(!!enquo(var)), n = sample_size, replace = T)),\n    sample_mean = purrr::map_dbl(sample, \\(x) x %>% pull(!!enquo(var)) %>% mean(.,na.rm=T))\n  )\n  }\n  return(df)\n}\n\n# ---- Plot Single Distribution -----\n\nplot_distribution <- function(the_pop,the_samp, the_var, ...){\n  mu_pop <- the_pop %>% pull(!!enquo(the_var)) %>% mean(., na.rm=T)\n  mu_samp <- the_samp %>% pull(!!enquo(the_var)) %>% mean(., na.rm=T)\n  ll <- the_pop %>% pull(!!enquo(the_var)) %>% as.numeric() %>%  min(., na.rm=T)\n  ul <- the_pop %>% pull(!!enquo(the_var)) %>% as.numeric() %>% max(., na.rm=T)\n  p<- the_samp %>% \n    ggplot(aes(!!enquo(the_var)))+\n    geom_density()+\n    geom_rug()+\n    theme_void()+\n    geom_vline(xintercept = mu_samp, col = \"red\")+\n    geom_vline(xintercept = mu_pop, col = \"grey40\",linetype = \"dashed\")+\n    xlim(ll,ul)\n  return(p)\n}\n\n# ---- Plot multiple distributions ----\n\nplot_samples <- function(pop, x, variable,n_rows = 4, ...){\n  sample_plots <- x$sample[1:(4*n_rows)] %>% \n  purrr::map( \\(x) plot_distribution(the_pop=pop, the_samp = x, \n                                     the_var = !!enquo(variable)))\n  p <- wrap_elements(wrap_plots(sample_plots[1:(4*n_rows)], ncol=4))\n  return(p)\n  \n}\n\n# ---- Plot Combined Figure ----\n\nplot_figure_fn <- function(\n    d=df, \n    v=age, \n    sim=1000, \n    size=10,\n    rows = 4){\n  # Population average\n  mu <- d %>% pull(!!enquo(v)) %>% mean(., na.rm=T)\n  sd <- d %>% pull(!!enquo(v)) %>% sd(., na.rm=T)\n  se <- sd/sqrt(size)\n  # Range\n  ll <- d %>% pull(!!enquo(v)) %>% as.numeric() %>%  min(., na.rm=T)\n  ul <- d %>% pull(!!enquo(v)) %>% as.numeric() %>% max(., na.rm=T)\n  # Population standard deviation\n  # Sample data\n  samp_df <- sample_data_fn(dat=d, var = !!enquo(v), samps = sim, sample_size = size)\n  # Plot Population\n  p_pop <- d %>%\n    ggplot(aes(!!enquo(v)))+\n      geom_density(col =\"grey60\")+\n      geom_rug(col = \"grey60\", )+\n      geom_vline(xintercept = mu, col=\"grey40\", linetype=\"dashed\")+\n      theme_void()+\n      labs(title =\"Population\")+\n      xlim(ll,ul)+\n      theme(plot.title = element_text(hjust = 0))\n\n  \n  p_samps <- plot_samples(pop=d, x= samp_df,variable = !!enquo(v),\n                          n_rows = rows)\n  p_samps <- p_samps + \n    ggtitle(paste(\"Repeated samples of size N =\",size,\"from the population\"))+\n    theme(plot.title = element_text(hjust = 0.5), \n          plot.background = element_rect(\n            fill = NA, colour = 'black', linewidth = 2)\n          )\n  \n  \n  p_dist <- samp_df %>% \n  ggplot(aes(sample_mean))+\n  geom_density(col=\"red\",aes(y= after_stat(ndensity)))+\n  geom_rug(col=\"red\")+\n  geom_density(data = df, aes(!!enquo(v), y= after_stat(ndensity)),\n               col=\"grey60\")+\n  geom_vline(xintercept = mu, col=\"grey40\", linetype=\"dashed\")+\n  xlim(ll,ul)+\n  theme_void()+\n    labs(\n      title = \"Sampling Distribution\"\n    )+  theme(plot.title = element_text(hjust = 0))\n  \n  range_upper_df <- tibble(\n  x = seq( ((ll+ul)/2 -5), ((ll+ul)/2 +5), length.out = 20),\n  xend = seq(ll-5, ul+5, length.out = 20),\n  y = rep(9, 20),\n  yend = rep(1, 20)\n)\np_upper <- range_upper_df %>% \n  ggplot(aes(x=x, xend = xend, y=y,yend=yend))+\n  geom_segment(\n    arrow = arrow(length = unit(0.05, \"npc\"))\n  )+\n  theme_void()+\n  coord_fixed(ylim=c(0,10),\n              xlim =c(ll-5,ul+5),clip=\"off\")\n  # Lower\n  range_df <- samp_df %>% \n  summarise(\n    min = min(sample_mean),\n    max = max(sample_mean),\n    mean = mean(sample_mean)\n  )\n  \n  plot_df <- tibble(\n  id = 1:50,\n  # x = sort(rnorm(50, mu, sd)),\n  x = sort(runif(50, ll, ul)),\n  xend = sort(rnorm(50, mu, se)),\n  y = 9,\n  yend = 1\n)\n\np_lower <- plot_df %>%\n  ggplot(aes(x,y, group =id))+\n  geom_segment(aes(xend=xend, yend=yend),\n               col = \"red\",arrow = arrow(length = unit(0.05, \"npc\"))\n               )+\n  theme_void()+\n  coord_fixed(ylim=c(0,10),xlim = c(ll,ul),clip=\"off\")\n\n  \n  design <-\"##AAAA##\n            ##AAAA##\n            ##AAAA##\n            BBBBBBBB\n            BBBBBBBB\n            #CCCCCC#\n            #CCCCCC#\n            #CCCCCC#\n            #CCCCCC#\n            DDDDDDDD\n            DDDDDDDD\n            ##EEEE##\n            ##EEEE##\n            ##EEEE##\"\n  \n  fig <- p_pop / p_upper / p_samps / p_lower / p_dist +\n    plot_layout(design = design)\n  return(fig)\n\n\n  \n  \n  \n}\n\n# ---- Samples and Figures Varying Sample Size ----\n## N = 10\nset.seed(1234)\nsamp_n10 <- sample_data_fn(sample_size  = 10, samps = 1000)\nset.seed(1234)\nfig_n10 <- plot_figure_fn(v=age,size = 10)\n\n## N = 30\nset.seed(1234)\nsamp_n30 <- sample_data_fn(sample_size  = 30, samps = 1000)\nset.seed(1234)\nfig_n30 <- plot_figure_fn(size = 30,rows=4)\n\n## N = 300\nset.seed(1234)\nsamp_n300 <- sample_data_fn(sample_size  = 300, samps = 1000)\nset.seed(1234)\nfig_n300 <- plot_figure_fn(size = 300)\n```\n:::\n\n\n## N = 10\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign10-1.png){width=960}\n:::\n:::\n\n\n\n## N = 30\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign30-1.png){width=960}\n:::\n:::\n\n\n\n## N = 300\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign300-1.png){width=960}\n:::\n:::\n\n\n\n## Comments\n\n:::{.nonincremental}\n\nAs the sample sample size increases:\n\n- The width of the sampling distribution decreases (LLN)\n  \n- The shape of the sampling distribution approximates a Normal distribution (CLT)\n:::\n\n::::\n\n## Standard errors {.smaller}\n\n:::: panel-tabset\n\n## Overview\n\n:::{.nonincremental}\n\n- The standard error (SE) is simply the [standard deviation]{.blue} of the sampling distribution.\n\n- The SE decreases as the sample size increases (by the LLN):\n\n- Approximately 95% of the sample means will be within 2 SEs of the population mean (CLT)\n:::\n\n## {{<fa code>}} Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse_df <- tibble(\n  `Sample Size` = factor(paste(\"N =\",c(10,30, 300))),\n  se = c(sd(samp_n10$sample_mean),\n         sd(samp_n30$sample_mean),\n         sd(samp_n300$sample_mean)),\n  SE = paste(\"SE =\", round(se,2)),\n  ll = mu_age,\n  ul = mu_age + se,\n  y = c(.3,.3,.45),\n  yend = y\n)\n\nci_df <- tibble(\n  `Sample Size` = factor(paste(\"N =\",c(10,30, 300))),\n  se = c(sd(samp_n10$sample_mean),\n         sd(samp_n30$sample_mean),\n         sd(samp_n300$sample_mean)),\n  mu = mu_age,\n  ll = round(mu_age - 1.96 *se,2),\n  ul = round(mu_age + 1.96 *se,2),\n  ci = paste(\"95 % Coverage Interval [\",ll,\";\",ul,\"]\",sep=\"\"),\n  y = c(.3,.3,.45),\n  yend = y\n)\nsim_df <- samp_n10 %>% \n  bind_rows(samp_n30) %>% \n  bind_rows(samp_n300) %>% \n  mutate(\n    `Sample Size` = factor(paste(\"N =\",size))\n    ) %>% \n  left_join(ci_df) %>% \n  mutate(\n    Coverage = case_when(\n      sample_mean > ll_asymp & sample_mean < ul_asymp  & size == 10~ \"#F8766D\",\n      sample_mean > ll_asymp & sample_mean < ul_asymp  & size == 30~ \"#00BA38\",\n      sample_mean > ll_asymp & sample_mean < ul_asymp  & size == 300~ \"#619CFF\",\n      T ~ \"grey\"\n    )\n  )\n\n\n\nfig_se <- sim_df %>% \n  ggplot(aes(sample_mean, col = `Sample Size`))+\n  geom_density()+\n  geom_rug()+\n  geom_vline(xintercept = mu_age, linetype = \"dashed\")+\n  theme_minimal()+\n  facet_wrap(~`Sample Size`, ncol=1)+\n  ylim(0,.5)+\n  guides(col=\"none\")+\n  geom_segment(\n    data = se_df,\n    aes(x= ll, xend =ul, y = y, yend = yend)\n  )+\n  geom_text(\n    data = se_df,\n    aes(x = ul, y =y, label = SE),\n    hjust = -.25\n  ) +\n  labs(\n    y = \"\",\n    x = \"Sampling Distributions of Sample Means\",\n    title = \"Standard Errors decrease with Sample Size\"\n  )\n\nfig_coverage <- sim_df %>% \n  ggplot(aes(sample_mean,col=`Sample Size`))+\n  geom_density()+\n  geom_rug(col=sim_df$Coverage)+\n  geom_vline(xintercept = mu_age, linetype = \"dashed\")+\n  theme_minimal()+\n  facet_wrap(~`Sample Size`, ncol=1)+\n  ylim(0,.55)+\n  guides(col=\"none\")+\n  geom_segment(\n    data = ci_df,\n    aes(x= ll, xend =ul, y = y, yend = yend)\n  )+\n  geom_text(\n    data = ci_df,\n    aes(x = mu, y =y, label = ci),\n    hjust = .5,\n    nudge_y =.1\n  ) +\n  labs(\n    y = \"\",\n    x = \"Sampling Distributions of Sample Means\",\n    title = \"Approximately 95% of sample means are within 2 SE of the population mean\"\n  )\n```\n:::\n\n\n## {{<fa chart-line>}} SEs\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figse-1.png){width=960}\n:::\n:::\n\n\n## {{<fa chart-line>}} Coverage\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figcoverage-1.png){width=960}\n:::\n:::\n\n\n\n\n::::\n\n## How do we calculate a standard error from a single sample? {.center .smaller}\n\n## Calculating standard errors {.smaller}\n\n:::: panel-tabset\n\n\n## Two Approaches\n\n:::{.nonincremental}\n\n- [Simulation]{.blue}:\n  - Treat sample as population\n  - Sample with replacement (\"bootstrapping\")\n  - Estimate SE from standard deviation of resampling distribution (\"plug-in principle\")\n\n- [Analytic]{.blue}\n  - Characterize sampling distribution from sample mean and variance via asymptotic theory (the LLT and CLT)\n  - For a sample mean, $\\bar{x}$\n  \n$$\nSE_{\\bar{x}} = \\frac{\\sigma_x}{\\sqrt(n)}\n$$\n:::\n\n\n## {{< fa code >}}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_resampling_fn <- function(d=df, v=age, sim=1000, size=10,rows=3){\n  # Population average\n  mu <- d %>% pull(!!enquo(v)) %>% mean(., na.rm=T)\n  # Population standard deviation and SE\n  sd <- d %>% pull(!!enquo(v)) %>% sd(., na.rm=T)\n  se <- sd/sqrt(size)\n  # Range\n  ll <- d %>% pull(!!enquo(v)) %>% as.numeric() %>%  min(., na.rm=T)\n  ul <- d %>% pull(!!enquo(v)) %>% as.numeric() %>% max(., na.rm=T)\n  # Resampling with replace\n  # Draw 1 Sample\n  sample <- sample_data_fn(dat=d, var = !!enquo(v), samps = 1, sample_size = size, resample = F)\n  samp_df <- as.data.frame(sample$sample)\n  # Resample from sample with replacement\n  resamp_df <- sample_data_fn(dat=samp_df, var = !!enquo(v), samps = sim, sample_size = size, resample = T)\n  # Plot Population\n  p_pop <- d %>%\n    ggplot(aes(!!enquo(v)))+\n      geom_density(col =\"grey60\")+\n      geom_rug(col = \"grey60\", )+\n      geom_vline(xintercept = mu, col=\"grey40\", linetype=\"dashed\")+\n      theme_void()+\n      labs(title =\"Population\")+\n      xlim(ll,ul)+\n      theme(plot.title = element_text(hjust = 0))\n\n  p_samp <- plot_distribution(the_pop = d,\n                              the_samp = samp_df,\n                              the_var = age)+\n    labs(title =\"Sample\")+\n      xlim(ll,ul)+\n      theme(plot.title = element_text(hjust = 0))\n  \n  p_samps <- plot_samples(pop=d, x= resamp_df,variable = !!enquo(v), n_rows =rows)\n  p_samps <- p_samps + \n    ggtitle(paste(\"Repeated samples with replacement\\nof size N =\",size,\"from sample\"))+\n    theme(plot.title = element_text(hjust = 0.5), \n          plot.background = element_rect(\n            fill = NA, colour = 'black', linewidth = 2)\n          )\n  \n  # Resampling Distribution\n  \n  \n  p_dist <- resamp_df %>% \n  ggplot(aes(sample_mean))+\n  geom_density(col=\"red\",aes(y= after_stat(ndensity)))+\n  geom_rug(col=\"red\")+\n  geom_density(data = df, aes(!!enquo(v), y= after_stat(ndensity)),\n               col=\"grey60\")+\n  geom_vline(xintercept = unique(resamp_df$pop_mean), col=\"red\", linetype=\"solid\")+\n  geom_vline(xintercept = mu, col=\"grey40\", linetype=\"dashed\")+\n  xlim(ll,ul)+\n  theme_void()+\n    labs(\n      title = \"Reampling Distribution\"\n    )+  theme(plot.title = element_text(hjust = 0))\n  \n   range_upper_df <- tibble(\n  x = seq( ((ll+ul)/2 -5), ((ll+ul)/2 +5), length.out = 20),\n  xend = seq(ll-5, ul+5, length.out = 20),\n  y = rep(9, 20),\n  yend = rep(1, 20)\n)\np_upper <- range_upper_df %>% \n  ggplot(aes(x=x, xend = xend, y=y,yend=yend))+\n  geom_segment(\n    arrow = arrow(length = unit(0.05, \"npc\"))\n  )+\n  theme_void()+\n  coord_fixed(ylim=c(0,10),\n              xlim =c(ll-5,ul+5),clip=\"off\")\n  # Lower\n  range_df <- resamp_df %>% \n  summarise(\n    min = min(sample_mean),\n    max = max(sample_mean),\n    mean = mean(sample_mean)\n  )\n  \n  plot_df <- tibble(\n  id = 1:50,\n  # x = sort(rnorm(50, mu, sd)),\n  x = sort(runif(50, ll, ul)),\n  xend = sort(rnorm(50, unique(resamp_df$pop_mean), se)),\n  y = 9,\n  yend = 1\n)\n\np_lower <- plot_df %>%\n  ggplot(aes(x,y, group =id))+\n  geom_segment(aes(xend=xend, yend=yend),\n               col = \"red\",arrow = arrow(length = unit(0.05, \"npc\"))\n               )+\n  theme_void()+\n  coord_fixed(ylim=c(0,10),xlim = c(ll,ul),clip=\"off\")\n\n  \n  design <-\"##AAAA##\n            ##AAAA##\n            ##AAAA##\n            ##BBBB##\n            ##BBBB##\n            ##BBBB##            \n            CCCCCCCC\n            CCCCCCCC\n            #DDDDDD#\n            #DDDDDD#\n            #DDDDDD#\n            #DDDDDD#\n            EEEEEEEE\n            EEEEEEEE\n            ##FFFF##\n            ##FFFF##\n            ##FFFF##\"\n  \n  fig <- p_pop / p_samp /p_upper / p_samps / p_lower / p_dist +\n    plot_layout(design = design)\n  return(fig)\n\n\n  \n  \n  \n}\nset.seed(123)\nresamp_n10 <- sample_data_fn(\n  dat = sample_data_fn(samps = 1, sample_size = 10, resample = T)$sample %>%  as.data.frame(),\n  sample_size = 10, \n  resample = T)\nset.seed(123)\nfig_n10_bs <- plot_resampling_fn(size=10)\n\nset.seed(12345)\nresamp_n30 <- sample_data_fn(\n  dat = sample_data_fn(samps = 1, sample_size = 30, resample = T)$sample %>%  as.data.frame(),\n  samps = 1000, sample_size = 30, resample = T)\n\nset.seed(12345)\nfig_n30_bs <- plot_resampling_fn(size=30)\n\nset.seed(1234)\nresamp_n300 <- sample_data_fn(\n  dat = sample_data_fn(samps = 1, sample_size = 300, resample = T)$sample %>%  as.data.frame(),\n  samps = 1000, sample_size = 300, resample = T)\nset.seed(1234)\nfig_n300_bs <- plot_resampling_fn(size=300)\n```\n:::\n\n\n## N = 10\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign10bs-1.png){width=960}\n:::\n:::\n\n\n\n## N = 30\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign30bs-1.png){width=960}\n:::\n:::\n\n\n\n## N = 300\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fign300bs-1.png){width=960}\n:::\n:::\n\n\n## Simulation vs Analytic\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| Bootstrap SE| Analytic SE|\n|------------:|-----------:|\n|         5.74|        5.61|\n|         2.75|        3.24|\n|         1.07|        1.02|\n\n\n:::\n:::\n\n\n\n::::\n\n# {{< fa lightbulb >}} Confidence intervals {.inverse}\n\n## Confidence intervals\n\nConfidence intervals:\n\n- provide a way of [quantifying uncertainty]{.blue} about [estimates]{.blue}\n\n- describe a [range of plausible values]{.blue} for an estimate\n\n- are a function of the [standard error]{.blue} of the estimate, and the a [critical value]{.blue} determined by $\\alpha$, which describes the degree of confidence we want \n\n\n## {.smaller}\n#### Calculating a confidence interval {.smaller}\n\n:::: panel-tabset\n\n## Steps\n\n:::{.nonincremental}\n\n- Choose [level of confidence]{.blue} $(1-\\alpha)\\times 100%$ \n  - $\\alpha = 0.05$, corresponds to a 95% confidence level.\n\n- Derive the [sampling distribution]{.blue} of the estimator\n  - [Simulation:]{.blue} bootstrap re-sampling\n  - [Analytically:]{.blue} computing its mean and variance.\n\n- Compute the [standard error]{.blue}\n\n- Compute the [critical value]{.blue} $z_{\\alpha/2}$ \n  - as the $1.96 = \\Phi(z_{0.5/2})$ for a 95% CI\n\n- Compute the [lower and upper]{.blue} confidence limits \n  - lower limit = $\\hat{\\theta} - z_{\\alpha/2}\\times SE$ \n  - upper limit = $\\hat{\\theta} + z_{\\alpha/2}\\times SE$ \n\n:::\n\n## {{<fa code>}} Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresamp_df <- \n  resamp_n10 %>% \n  bind_rows(resamp_n30) %>% \n  bind_rows(resamp_n300) %>% \n  mutate(\n    `Sample Size` = factor(paste(\"N =\",size))\n    )\n\nresamp_ci_df <- tibble(\n  `Sample Size` = factor(paste(\"N =\",c(10,30,300))),\n  mu = unique(resamp_df$pop_mean),\n  ll = unique(resamp_df$ll_asymp),\n  ul = unique(resamp_df$ul_asymp),\n  y = c(.3, .3,.5)\n)\n\nfig_ci1 <- resamp_df %>% \n  ggplot(aes(sample_mean,\n             col = `Sample Size`))+\n  geom_density()+\n  geom_rug()+\n  geom_vline(xintercept = mu_age, linetype = \"dashed\")+\n  geom_vline(data = resamp_ci_df,\n             aes(xintercept = mu,\n                 col = `Sample Size`))+\n  geom_segment(data = resamp_ci_df,\n               aes(x = ll, xend =ul, y = y, yend =y,\n                   col = `Sample Size`))+\n  facet_wrap(~`Sample Size`, ncol=1)+\n  theme_minimal()+\n  labs(\n    y = \"\",\n    x = \"Resampling Distribution\",\n    title = \"95% Confidence Intervals\"\n  )\n  \n\nsamp_ci_df <- samp_n10 %>% \n  bind_rows(samp_n30) %>% \n  bind_rows(samp_n300) %>% \n  mutate(\n    `Sample Size` = factor(paste(\"N =\",size))\n    ) %>% \n  mutate(\n    Coverage = case_when(\n      pop_mean > ll & pop_mean < ul ~ \"red\",\n      T ~ \"black\"\n    )\n  )\n\nfig_ci2 <- samp_ci_df %>% \n  filter(sim %in% 1:100) %>% \n  filter(size == 10) %>% \n  ggplot(aes(y = sample_mean, x= sim))+\n  geom_pointrange(aes(ymin = ll, ymax =ul, col=Coverage))+\n  geom_hline(yintercept = mu_age, linetype = \"dashed\")+\n  coord_flip()+\n  theme_minimal()+\n  guides(col = \"none\")+\n  facet_wrap(~`Sample Size`)\n\nfig_ci3 <- samp_ci_df %>% \n  filter(sim %in% 1:100) %>% \n  ggplot(aes(y = sample_mean, x= sim))+\n  geom_pointrange(aes(ymin = ll, ymax =ul, col=Coverage))+\n  geom_hline(yintercept = mu_age, linetype = \"dashed\")+\n  coord_flip()+\n  theme_minimal()+\n  guides(col = \"none\")+\n  facet_wrap(~`Sample Size`)\n```\n:::\n\n\n## {{<fa chart-line>}} Fig 1\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figci1-1.png){width=960}\n:::\n:::\n\n\n\n## {{<fa chart-line>}} Fig 2\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figci2-1.png){width=960}\n:::\n:::\n\n\n## {{<fa chart-line>}} Fig 3\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figci3-1.png){width=960}\n:::\n:::\n\n\n## Comments\n\n:::{.nonincremental}\n\n- Figure 1 shows 3 confidences intervals for 3 samples of different sizes (N = 10, 30, 300). The CIs for  N = 10 and N = 300, intervals contain the truth (include the population mean).  By chance, the CI for N=30 falls outside of the truth.\n\n- Figure 2 shows that our confidence is about the property of the interval. Over repeated sampling, 95% of the intervals would contain the truth, 5% percent would not.\n\n  - In any one sample, the population parameter either is or is not within the interval.\n  \n- Figure 3, shows that while the width of the interval declines with the sample size, the coverage properties remains the same. \n:::\n\n::::\n\n## Interpreting confidence intervals {.smaller}\n\n- Confidence intervals give a range of values that are likely to include the true value of the parameter $\\theta$ with probability $(1-\\alpha) \\times 100\\%$\n\n  - $\\alpha = 0.05$ corresponds to a \"95-percent confidence interval\"\n\n- Our \"confidence\" is about the interval\n  \n- In repeated sampling, we expect that $(1-\\alpha) \\times 100\\%$ of the intervals we construct would contain the truth.\n\n- For any one interval, the truth, $\\theta$, either falls within in the lower and upper bounds of the interval or it does not.\n\n# {{< fa lightbulb >}} Hypothesis testing {.inverse}\n\n## What is a hypothesis test\n\n- A formal way of assessing statistical evidence. Combines\n   \n  - [**Deductive reasoning**]{.blue} distribution of a test statistic, if the a null hypothesis were true \n   \n  - [**Inductive reasoning**]{.blue} based on the test statistic we observed, how likely is it that we would observe it if the null were true?\n\n\n## What is a test statistic? {.smaller}\n\n- A way of summarizing data\n  - difference of means\n  - coefficients from a linear model\n  - **coefficients from a linear model divided by their standard errors** \n  - R^2\n  - [Sums of ranks](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)\n\n::::{.fragment}\n\n:::{.callout-note}\nDifferent test statistics may be more or less appropriate depending on your data and questions. \n:::\n\n::::\n\n## What is a null hypothesis?\n\n- A statement about the world\n    \n  - Only interesting [if we reject]{.blue} it\n  \n  - Would yield a distribution of test statistics [under the null]{.blue} \n  \n  - Typically something like \"X has no effect on Y\" (Null = no effect)\n  \n  - [Never accept the null]{.blue} can only reject\n\n## What is a p-value?{.smaller}\n\nA p-value is a [conditional probability]{.blue} summarizing the likelihood of [observing a test statistic]{.blue} as far from our hypothesis or farther, [if our hypothesis were true]{.blue}.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/pval-1.png){width=960}\n:::\n:::\n\n\n\n## How do we do hypothesis testing?{.smaller}\n\n1. Posit a [hypothesis]{.blue} (e.g. $\\beta = 0$)\n\n\n2. Calculate the [test statistic]{.blue} (e.g. $(\\hat{\\beta}-\\beta)/se_\\beta$)\n\n3. Derive the [distribution]{.blue} of the test statistic [under the null]{.blue} via simulation or asymptotic theory\n  \n4. Compare the test statistic to the distribution under the null\n  \n5. Calculate [p-value]{.blue} (Two Sided vs One sided tests)\n    \n6. Reject or fail to reject/retain our hypothesis based on some [threshold of statistical significance]{.blue} (e.g. p < 0.05)\n\n## Outcomes of hypothesis tests {.smaller}\n\n:::{.nonincremental}\n\n- Two conclusions from of a hypothesis test: we can reject or fail to reject a hypothesis test.\n\n- **We never \"accept\" a hypothesis**, since there are, in theory, an infinite number of other hypotheses we could have tested.\n\nOur decision can produce four outcomes and two types of error:\n\n|                | Reject $H_0$ | Fail to Reject $H_0$ |\n|----------------|--------------|----------------------|\n| $H_0$ is true  | False Positive | Correct!           |\n| $H_0$ is false | Correct!     | False Negative       |\n\n- **Type 1 Errors:** False Positive Rate (p < 0.05)\n- **Type 2 Errors:** False negative rate (1 - Power of test)\n\n:::\n\n# {{< fa code >}} Quantifying uncertainty in regression {.inverse}\n\n## Quantifying uncertainty in regression{.smaller}\n\n:::: panel-tabset\n\n## Overview\n\nHow do income and education shape political participation?\n\nLet's fit the following model\n\n$$\ny = \\beta_0 + \\beta_1\\text{income} + \\beta_2 \\text{education} + \\epsilon\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm_robust(dv_participation ~   education + income, df)\n```\n:::\n\n\nAnd unpack the output\n\n## {{<fa table>}} Raw\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m1) %>% \n  mutate_if(is.numeric, \\(x) round(x, 3)) -> m1_sum\nm1_sum\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         term estimate std.error statistic p.value conf.low conf.high   df\n1 (Intercept)    0.312     0.080     3.910   0.000    0.155     0.468 1684\n2   education    0.167     0.024     6.891   0.000    0.119     0.214 1684\n3      income    0.007     0.010     0.671   0.502   -0.014     0.028 1684\n           outcome\n1 dv_participation\n2 dv_participation\n3 dv_participation\n```\n\n\n:::\n:::\n\n\n## {{<fa table>}} SEs\n\n\n```{.r .cell-code}\nhtmlreg(m1,include.ci=F) \n```\n\n<table class=\"texreg\" style=\"margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;\">\n<caption>Statistical models</caption>\n<thead>\n<tr>\n<th style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 1</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">(Intercept)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.31<sup>&#42;&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.08)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">education</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.17<sup>&#42;&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.02)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">income</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.01</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.01)</td>\n</tr>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.04</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Adj. R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.04</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Num. obs.</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1687</td>\n</tr>\n<tr style=\"border-bottom: 2px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">RMSE</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1.29</td>\n</tr>\n</tbody>\n<tfoot>\n<tr>\n<td style=\"font-size: 0.8em;\" colspan=\"2\"><sup>&#42;&#42;&#42;</sup>p &lt; 0.001; <sup>&#42;&#42;</sup>p &lt; 0.01; <sup>&#42;</sup>p &lt; 0.05</td>\n</tr>\n</tfoot>\n</table>\n\n\n## {{<fa table>}} CIs\n\n\n```{.r .cell-code}\nhtmlreg(m1,include.ci=T) \n```\n\n<table class=\"texreg\" style=\"margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;\">\n<caption>Statistical models</caption>\n<thead>\n<tr>\n<th style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 1</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">(Intercept)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.31<sup>&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">[ 0.16; 0.47]</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">education</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.17<sup>&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">[ 0.12; 0.21]</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">income</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.01</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">[-0.01; 0.03]</td>\n</tr>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.04</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Adj. R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.04</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Num. obs.</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1687</td>\n</tr>\n<tr style=\"border-bottom: 2px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">RMSE</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1.29</td>\n</tr>\n</tbody>\n<tfoot>\n<tr>\n<td style=\"font-size: 0.8em;\" colspan=\"2\"><sup>&#42;</sup> 0 outside the confidence interval.</td>\n</tr>\n</tfoot>\n</table>\n\n\n## {{<fa code>}} \n\n::: {.cell}\n\n```{.r .cell-code}\nm1_coefplot <- m1_sum %>% \n  ggplot(aes(term, estimate))+\n  geom_pointrange(aes(ymin = conf.low, ymax =conf.high))+\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  coord_flip()+\n  labs(\n    y = \"Estimate\",\n    x = \"\",\n    title = \"Coefficient plot\"\n  )+\n  theme_minimal()\n```\n:::\n\n\n\n## {{<fa chart-line>}} Coefficient plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/m1_coefplot_fig-1.png){width=960}\n:::\n:::\n\n\n\n::::\n\n## Estimates {.smaller}\n\n:::: panel-tabset\n\n## Estimate\n\nThe estimate column are the regression coefficients, $\\beta$\n\nRecall, lm_robust() calculates these:\n\n$$\n\\hat{\\beta} = (X'X)^{-1}X'y\n$$\n\n:::{.callout-tip}\n$\\beta$s describe substantive relationships between predictors (income, education) and the outcome (political participation) \n:::\n\n\n## {{<fa code>}}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)   education      income \n0.311609712 0.166755964 0.007034253 \n```\n\n\n:::\n\n```{.r .cell-code}\nX <- model.matrix(m1,data=df)\ny <- model.frame(m1)$dv_participation\nbetas <- solve(t(X)%*%X)%*%t(X)%*%y\nbetas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   [,1]\n(Intercept) 0.311609712\neducation   0.166755964\nincome      0.007034253\n```\n\n\n:::\n:::\n\n\n## Comments\n\nA unit increases in education is associated with about 0.16 more acts of political participation, while a unit increase in income is associated with 0.007 more acts of participation.\n\nNote that both `income` and `education` are measured with ordinal scales\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_value_labels(df$educ)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    No HS credential High school graduate         Some college \n                   1                    2                    3 \n       2-year degree        4-year degree            Post-grad \n                   4                    5                    6 \n```\n\n\n:::\n:::\n\n\nSuch that it might be unreasonable to assume [cardinality]{.blue} (going from a 1 to 2 is the same as going from a 3 to 4)\n\n- Consider treating as factor / recoding variable\n\n\n::::\n\n## {.smaller}\n#### Standard errors & confidence intervals \n\n:::: panel-tabset\n\n## SEs and CI\n\nThe default standard errors from `lm_robust()` are [calculated](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html) as follows\n\n$$\nSE_{\\beta} = (X'X)^{-1}X'\\text{diag}\\left[\\frac{e_i^2}{1-h_{ii}}\\right]X(X'X)^{-1}\n$$\n\nWhich we could also obtain via bootstrapping. \n\nThe confidence intervals are calculated as follows:\n\n$$\nCI = \\beta \\pm 1.96\\times SE_\\beta\n$$\n\n\n## {{<fa code>}} Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 0 Set seed\nset.seed(123)\n\n# 1,000 bootstrap samples\nboot <- modelr::bootstrap(df %>% select(dv_participation, income, education), 1000)\n# Estimate Boostrapped Models\nm1_bs <- purrr::map(boot$strap, ~ lm_robust(dv_participation ~  income + education, data = .))\n\n# Tidy coefficients\nm1_bs_df <- map_df(m1_bs, tidy, .id = \"id\")\nm1_asymp_df <- tidy(m1) %>% \n  mutate(\n    term = factor(term)\n  ) %>% \n  select(term,estimate, std.error,conf.low, conf.high) %>% \n  mutate(\n    ll = conf.low,\n    ul = conf.high,\n    y = 1.1,\n    type = \"Analytic\"\n  )\n\nm1_bs_ci_df <- m1_bs_df %>%\n  mutate(\n    term = factor(term)\n  ) %>% \n  group_by(term) %>% \n  summarise(\n  beta = mean(estimate,na.rm=T),\n  se = sd(estimate,na.rm=T)\n  ) %>% \n  mutate(\n  ll = beta - 1.96*se,\n  ul = beta + 1.96*se,\n  y = 1.05,\n  type = \"Bootstrap\"\n) \n\n# Compare SEs\n\ncompare_m1_se_tab <-\n  tibble(\n    `Predictor` = m1_bs_ci_df$term,\n    Estimate = m1_asymp_df$estimate,\n    `SE` = m1_asymp_df$std.error,\n     `CI` = paste(\"[\", round(m1_asymp_df$ll,2),\n                  \"; \", round(m1_asymp_df$ul,2),\"]\",\n                  sep =\"\"),\n    `SE ` = m1_bs_ci_df$se,\n    `CI ` = paste(\"[\", round(m1_bs_ci_df$ll,2),\n                  \"; \", round(m1_bs_ci_df$ul,2),\"]\",\n                  sep =\"\"),\n  )\n\n\n# Figure\nfig_m1_bs <- m1_bs_df %>% \n  ggplot(aes(estimate))+\n  geom_density(aes(y=after_stat(ndensity)))+\n  geom_rug()+\n  geom_vline(xintercept = 0, linetype = \"dashed\")+\n  facet_wrap(~term,scales = \"free\")+\n  theme_minimal()+\n  ylim(0, 1.2)+\n  geom_vline(\n    data = m1_asymp_df,\n    aes(xintercept = estimate)\n  ) +\n  geom_segment(\n    data = m1_bs_ci_df,\n    aes(x = ll, xend = ul,\n        y = y, yend = y,\n        col = \"Bootstrap\")\n    \n  ) +\n  geom_segment(\n    data = m1_asymp_df,\n    aes(x = ll, xend = ul,\n        y = y, yend = y,\n        col = \"Analytic\")\n    \n  ) +\n  labs(\n    col = \"Confidence Interval\",\n    x = \"Bootstrapped Sampling Distribution\\n of Coefficients\"\n  )\n```\n:::\n\n\n## {{<fa table>}} SEs\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"2\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Analytic</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Bootstrap</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Predictor </th>\n   <th style=\"text-align:center;\"> Estimate </th>\n   <th style=\"text-align:center;\"> SE </th>\n   <th style=\"text-align:center;\"> CI </th>\n   <th style=\"text-align:center;\"> SE </th>\n   <th style=\"text-align:left;\"> CI </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 0.3116 </td>\n   <td style=\"text-align:center;\"> 0.0797 </td>\n   <td style=\"text-align:center;\"> [0.16; 0.47] </td>\n   <td style=\"text-align:center;\"> 0.0805 </td>\n   <td style=\"text-align:left;\"> [0.15; 0.47] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> education </td>\n   <td style=\"text-align:center;\"> 0.1668 </td>\n   <td style=\"text-align:center;\"> 0.0242 </td>\n   <td style=\"text-align:center;\"> [0.12; 0.21] </td>\n   <td style=\"text-align:center;\"> 0.0248 </td>\n   <td style=\"text-align:left;\"> [0.12; 0.22] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> income </td>\n   <td style=\"text-align:center;\"> 0.0070 </td>\n   <td style=\"text-align:center;\"> 0.0105 </td>\n   <td style=\"text-align:center;\"> [-0.01; 0.03] </td>\n   <td style=\"text-align:center;\"> 0.0107 </td>\n   <td style=\"text-align:left;\"> [-0.01; 0.03] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## {{<fa chart-line>}} SEs\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/figm1bs-1.png){width=960}\n:::\n:::\n\n\n## Comments\n\n- The main takeaway here is that for linear models, bootstrapped SEs and CIs are quite similar to those obtained via analytically (via math and asymptotic theory)\n\n- For common estimators and large samples, we'll generally use analytic SEs (quicker)\n\n- For less common estimators (ratios of estimates), analytic estimates of the SEs may not exist. Bootstrapping will still provide valid SEs, provided we \"sample from the sample, as the sample was drawn from the population\"\n\n::::\n\n## Test statistics and p-values {.smaller}\n\n:::: panel-tabset\n\n## Overview\n\nThe test statistic (\"t-stat\") reported by `lm()` and `lm_robust()` is our observed coefficient, $\\hat{\\beta}$ minus our hypothesized value $\\beta$ (e.g. 0), divided by the standard error of  $\\hat{\\beta}$.\n\n$$t= \\frac{\\hat\\beta-\\beta}{\\widehat{SE}_{\\hat{\\beta}}} \\sim \\text{Students's } t \\text{ with } n-k \\text{ degrees of freedom}$$\nWhich follows a [$t$ distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) -- like a Normal with \"heavier tails\" (e.g. more probability assigned to extreme values)\n\n## {{<fa code>}} Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate t-stats\n\nt_stat_df <- tibble(\n  x= seq(-3,3,length.out = 20),\n  p = dt(x,df=m1$df[1] )\n)\n\n\nm1_tstat_educ <- t_stat_df %>% \n  ggplot(aes(x=x,y=p))+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"line\",\n    xlim = c(\n      min(c(-3, abs(m1$statistic[2])*-1 -1)),\n      max(c(3, abs(m1$statistic[2])+1))\n      )\n  )+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"area\",\n    fill = \"blue\",\n    alpha = .5,\n    xlim = c(m1$statistic[2],4)\n  )+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"area\",\n    fill = \"blue\",\n    alpha = .5,\n    xlim = c(-4, abs(m1$statistic[2])*-1)\n  )+\n  geom_vline(xintercept = m1$statistic[2],\n             col = \"blue\",\n             linetype = \"dashed\")+\n   geom_vline(xintercept = m1$statistic[2]*-1,\n             col = \"blue\",\n             linetype = \"dashed\")+\n  theme_minimal()+\n  labs(\n    title = \"Education\",\n    subtitle = paste(\"t-stat = \",round(m1$statistic[2],3),\n    \"\\nPr(>|t|) = \",\n    format(round(m1$p.value[2],3),nsmall = 3),\n    sep = \"\"\n    ),\n    x = \"Distribution of t-stat under the Null\"\n  )\n\nm1_tstat_income <- t_stat_df %>% \n  ggplot(aes(x=x,y=p))+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"line\",\n    xlim = c(\n      min(c(-3, abs(m1$statistic[3])*-1 -1)),\n      max(c(3, abs(m1$statistic[3])+1))\n      )\n  )+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"area\",\n    fill = \"blue\",\n    alpha = .5,\n    xlim = c(m1$statistic[3],4)\n  )+\n  stat_function(\n    fun= dt, \n    args = list(df = m1$df[1]),\n    geom = \"area\",\n    fill = \"blue\",\n    alpha = .5,\n    xlim = c(-4, abs(m1$statistic[3])*-1)\n  )+\n  geom_vline(xintercept = m1$statistic[3],\n             col = \"blue\",\n             linetype = \"dashed\")+\n   geom_vline(xintercept = m1$statistic[3]*-1,\n             col = \"blue\",\n             linetype = \"dashed\")+\n  theme_minimal()+\n  labs(\n    title = \"Income\",\n    subtitle = paste(\"t-stat = \",round(m1$statistic[3],3),\n    \"\\nPr(>|t|) = \",\n    format(round(m1$p.value[3],3),nsmall = 3),\n    sep = \"\"\n    ),\n    x = \"Distribution of t-stat under the Null\"\n  )\n\nfig_pvalue <- m1_tstat_educ + m1_tstat_income\n\n# Compare Pvalues\n\ncompare_m1_pvalue <-\n  tibble(\n    `Predictor` = m1_bs_ci_df$term,\n    Estimate = m1_asymp_df$estimate,\n    SE = m1_sum$std.error,\n    `t-stat` = m1_sum$statistic,\n     `Pr(>abs(t))` = format(round(m1_sum$p.value,3), nsmall=3)\n  )\n```\n:::\n\n\n## {{<fa table>}}\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Predictor </th>\n   <th style=\"text-align:right;\"> Estimate </th>\n   <th style=\"text-align:right;\"> SE </th>\n   <th style=\"text-align:right;\"> t-stat </th>\n   <th style=\"text-align:left;\"> Pr(&gt;abs(t)) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 0.312 </td>\n   <td style=\"text-align:right;\"> 0.080 </td>\n   <td style=\"text-align:right;\"> 3.910 </td>\n   <td style=\"text-align:left;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> education </td>\n   <td style=\"text-align:right;\"> 0.167 </td>\n   <td style=\"text-align:right;\"> 0.024 </td>\n   <td style=\"text-align:right;\"> 6.891 </td>\n   <td style=\"text-align:left;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> income </td>\n   <td style=\"text-align:right;\"> 0.007 </td>\n   <td style=\"text-align:right;\"> 0.010 </td>\n   <td style=\"text-align:right;\"> 0.671 </td>\n   <td style=\"text-align:left;\"> 0.502 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## {{<fa chart-line>}}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fig_pvalue-1.png){width=960}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n:::\n\n\n## Comments\n\n:::{.nonincremental}\n\n- The p-value for the coefficient on education is less than 0.05, while the p-value for income is 0.50.\n\n- If there was no relationship between education and participation ($H_0:\\beta_2=0$), it would be quite unlikely that we would observed a test statistic of 6.89 or larger.\n\n- Similarly, test statistics  as larger or larger than 0.671 occurs quite frequently in a world where there is no relationship ($H_0:\\beta_3=0$) between income and participation.\n\n- Thus we reject the null hypothesis for education, but fail to reject the null hypothesis for income in this model.\n:::\n\n::::\n\n\n## Predicted values{.smaller}\n\n:::: panel-tabset\n\n## Overview\n\nLet's explore whether income and education condition each other's relationship with participation using the following [interaction model]{.blue} \n\n$$\ny = \\beta_0 +\\beta_1 \\text{educ} + \\beta_2 \\text{inc} + \\beta_3\\text{educ}\\times\\text{inc} + \\epsilon\n$$\n\nTo help our interpretations we'll produce plots of [predicted values]{.blue} of participation, at varying levels of income and education.\n\n## {{< fa code>}} Code\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model\nm2 <- lm_robust(dv_participation ~ education*income, df)\n\n\n# Regression Table\nm2_tab <- htmlreg(\n  m2, \n  include.ci = F,\n  digits = 3,\n  stars = c(0.05, 0.10)\n                    )\n\n# Predicted values\n\n# Data frame of values we want to make predictions at\npred_df <-expand_grid(\n  income = sort(unique(df$income)),\n  education = quantile(df$education, na.rm = T)[c(2,4)]\n)\n\n# Combine model predictions\npred_df <- cbind(pred_df, predict(m2, pred_df,\n                                  interval = \"confidence\")$fit)\n\n# Plot predicted values\nfig_m2_pred <- pred_df %>% \n  mutate(\n    Education = ifelse(education == 2, \"High school\",\"College\")\n  ) %>% \n  ggplot(aes(income, fit, group=Education))+\n  geom_ribbon(aes(ymin = lwr, ymax = upr,\n                  fill = Education),\n              alpha=.5)+\n  geom_line()+\n  theme_minimal()+\n  labs(y = \"Predicted Participation\",\n       x = \"Income\",\n       title = \"\")\n```\n:::\n\n\n## {{<fa table >}} Table\n\n\n<table class=\"texreg\" style=\"margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;\">\n<caption>Statistical models</caption>\n<thead>\n<tr>\n<th style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</th>\n<th style=\"padding-left: 5px;padding-right: 5px;\">Model 1</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">(Intercept)</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.060</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.151)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">education</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.242<sup>&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.050)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">income</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.048<sup>&#42;&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.024)</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">education:income</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">-0.011<sup>&#42;</sup></td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">&nbsp;</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">(0.006)</td>\n</tr>\n<tr style=\"border-top: 1px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.042</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Adj. R<sup>2</sup></td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">0.040</td>\n</tr>\n<tr>\n<td style=\"padding-left: 5px;padding-right: 5px;\">Num. obs.</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1687</td>\n</tr>\n<tr style=\"border-bottom: 2px solid #000000;\">\n<td style=\"padding-left: 5px;padding-right: 5px;\">RMSE</td>\n<td style=\"padding-left: 5px;padding-right: 5px;\">1.286</td>\n</tr>\n</tbody>\n<tfoot>\n<tr>\n<td style=\"font-size: 0.8em;\" colspan=\"2\"><sup>&#42;&#42;</sup>p &lt; 0.05; <sup>&#42;</sup>p &lt; 0.1</td>\n</tr>\n</tfoot>\n</table>\n\n\n## {{<fa chart-line >}} Fig\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-slides_files/figure-revealjs/fig_m2_pred-1.png){width=960}\n:::\n:::\n\n\n\n## Comments\n\nLow income individuals with a college degree participate at significantly higher rates than individuals with a similar levels of income with only a high school diploma.\n\nAlternatively, we might say that the college educated tend to participate at similar levels, regardless of their level of income, while income has a marginally positive relationship with participation for those without college degrees.\n\n:::{.callout-note}\nIs this a causal relationship? What assumptions would we need to make a causal claim about the effects of education on participation?\n\n:::\n\n::::\n\n\n\n## References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.32/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}