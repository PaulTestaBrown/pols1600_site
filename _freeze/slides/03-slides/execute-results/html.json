{
  "hash": "4da0ec3ad1135efbdc7592a976e9e7ca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 03:\"\nsubtitle: \"Casual Inference in Experimental Designs\"\nauthor: \"Paul Testa\"\nformat: \n  revealjs:\n    theme: [default, brownslides.scss]\n    logo: images/pols1600_hex.png\n    footer: \"POLS 1600\"\n    multiplex: false\n    transition: fade\n    slide-number: c\n    incremental: true\n    center: false\n    menu: true\n    scrollable: true\n    highlight-style: github\n    progress: true\n    code-overflow: wrap\n    # include-after-body: title-slide.html\n    title-slide-attributes:\n      align: left\n      data-background-image: images/pols1600_hex.png\n      data-background-position: 90% 50%\n      data-background-size: 40%\nexecute: \n  echo: true\nfilters:\n  - openlinksinnewpage\n---\n\n\n\n\nclass: inverse, center, middle \\# Overview\n\n## General Plan\n\n-   Groups, Labs & Tutorials\n-   Feedback\n-   Review\n-   Lecture:\n    -   Causal inference\n    -   Notations to describe causal claims\n    -   Causal Identification\n    -   Causal Identification in experimental designs\n\n## Group Assignments\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-d0366b73c41ec88a390e\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-d0366b73c41ec88a390e\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"Anna Lister\",\"Kate Kuli\",\"Andreas Young\",\"Claudia Spelman\"],[\"Elizabeth Steeves\",\"Fabian Lopez\",\"Lorenzo Mahoney\",\"Ariana Palomo\"],[\"Will Lake\",\"Taha Siddiqui\",\"Amanda Page\",\"Noah Soutier\"],[\"Georgia Kennedy-Bailey\",\"Samuel Levine\",\"Elie Lubin\",\"Bianca Rosen\"],[\"Theo Simmons\",\"Fengyu Seah\",\"Hunter Keneley\",\"Schuyler Dubitsky\"],[\"Logan Torres\",\"Jonathan Zhang\",\"Osiris Russell-Delano\",\"Aicha Sama\"],[\"Natalia Ibarra\",\"Khaled Abdo\",\"Starrchild Jackson\",\"Selene Luna\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Group 1<\\/th>\\n      <th>Group 2<\\/th>\\n      <th>Group 3<\\/th>\\n      <th>Group 4<\\/th>\\n      <th>Group 5<\\/th>\\n      <th>Group 6<\\/th>\\n      <th>Group 7<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Group 1\",\"targets\":1},{\"name\":\"Group 2\",\"targets\":2},{\"name\":\"Group 3\",\"targets\":3},{\"name\":\"Group 4\",\"targets\":4},{\"name\":\"Group 5\",\"targets\":5},{\"name\":\"Group 6\",\"targets\":6},{\"name\":\"Group 7\",\"targets\":7}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n## Labs & Tutorials\n\n-   Upload Lab 2 if you haven't done so already\n-   Same for Tutorials 0, 1, 2.\n    -   Some confusion on what to upload, so let's do a quick demo.\n\nclass: inverse, center, middle background-image:url(\"https://m.media-amazon.com/images/I/51vs7dtZnZL.\\_AC\\_.jpg\") background-size:contain\n\n# Feedback\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## What do we like\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-53c3fa9e6eec5ef62d1c\" style=\"width:100%;height:90%;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-53c3fa9e6eec5ef62d1c\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\"],[\"Good intro! Feels like I have a good basic grasp of R\",\"Liked the hands-on aspect of the lab.\",\"I like that we go through the meaning behind each code chunk.\",\"I really enjoyed the hands-on work through the more complicated parts of understanding R, such as the pipe function and creating objects.\",\"I fixed my errors eventually.\",\"I really like when we work all together, and when there's lots of repetition for hotkeys, etc. I definitely need to hear things more than once to understand them.\",\"I found the textbook very useful.\",\"i like that, with the lab this week, there were opportunities to work through codings individually and as a group. it made me more confident about recoding data on my own.\",\"I liked working through visualizing data in R. I feel like I have a better sense of how to approach creating useful graphs from datasets and breaking up the process into tangible steps.\",\"I liked being engaged in class through lab.\",\"I liked plotting (simple) graphs. It feels nice to see a tangible product of coding\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Likes<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":4,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Likes\",\"targets\":1}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[4,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n## What do we dislike\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-f167680b22fad09d1b58\" style=\"width:100%;height:90%;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f167680b22fad09d1b58\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\"],[\"Honestly mostly the temperature of the room. Also there was a little too much content and too little time\",\"Wished the lab moved a little faster.\",\"N/A\",\"For a class full of beginner coders, there may be more details than they can handle. At the beginning of the course, I feel like labs can be a bit shorter so the students can understand the coding a bit better.\",\"I had trouble thinking of every step and finding the correct slide\",\"I'm worried that in the future I won't be able to finish the labs in time.\",\"I think the pace of the class and the lack of explanations on the functions even though the repeated use of them made me confused.\",\"I'm still confused about how the tutorials work. for this week, mine isn't loading the data in and I don't know where to get the data set.\",\"Sometimes copying and pasting code is helpful, but I feel slightly unprepared to tackle processing and visualizing data from scratch.\",\"What to do next in the lab wasn't always clear, I wish that the info would have been presented in a more straight forward way.\",\"We're starting to enter functions/syntax is isn't as intuitive as simple arithmetic. But I'm not too concerned -- I'll get there with practice\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Dislikes<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":4,\"columnDefs\":[{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Dislikes\",\"targets\":1}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[4,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n## Learning to code:\n\n-   Thinking programattically\n    -   Chunk big problems into concrete tasks\n-   Use R Markdown to organize your code\n-   Learn to troubleshoot errors\n-   Don't be afraid to FAAFO\n\n## Who's got the right of way?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Data\ndf %>%\n  mutate(\n    Turn = str_wrap(as_factor(Turn), width = 15)\n  )%>%\n  # Aesthetics\n  ggplot(aes(Turn,fill=Turn))+\n  # Geometries\n  geom_bar(stat=\"count\")+\n  # Other layers\n  coord_flip()+\n  guides(fill =F)+\n  theme_minimal()+\n  labs(y=\"\",\n       x=\"\",\n       title = \"Another car is turning left, who goes first at a red light?\")\n```\n:::\n\n\n## Who's got the right of way?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Review\n\n-   Set up\n-   Data wrangling\n-   Data visualization\n\n## Setup\n\nEvery time you work in R\n\n-   Save your file to your course or project folder\n\n-   Set your working directory\n\n-   Load, and if needed, install packages\n\n-   Maybe change some global options in your .Rmd file\n\n## Setting your working directory:\n\n-   My default code for setting a working directory is:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set working directory\nwd <- \".\" # Change to file path on your computer\nsetwd(wd)\n```\n:::\n\n\n-   This is really just a reminder to someone else using my code that they need to have their working directories set up correctly\n\n-   R Studio sets the working directory automatically, when you knit the file\n\n-   When I work on a file, I set the working directory manually\n\n## Setting your working directory when working \"Live\"\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://statisticsglobe.com/wp-content/uploads/2020/03/figure-2-set-working-directory-to-source-file-location-manually.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Packages for today\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nthe_packages <- c(\n  ## R Markdown\n  \"kableExtra\",\"DT\",\n  \n  ## Tidyverse\n  \"tidyverse\", \"lubridate\", \"forcats\", \n  \"haven\", \"labelled\",\n  \n  ## Extensions for ggplot\n  \"ggmap\",\"ggrepel\", \"ggridges\", \n  \"ggthemes\", \"ggpubr\", \"GGally\",\n  \"scales\", \"dagitty\", \"ggdag\", #<<\n  \n  # Data \n  \"COVID19\",\"maps\",\"mapdata\",\n  \"qss\" #<<\n)\n```\n:::\n\n\n## Define a function to load (and if needed install) packages\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nipak <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n```\n:::\n\n\n## Load packages for today\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nipak(the_packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nkableExtra         DT  tidyverse  lubridate    forcats      haven   labelled \n      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE       TRUE \n     ggmap    ggrepel   ggridges   ggthemes     ggpubr     GGally     scales \n      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE       TRUE \n   dagitty      ggdag    COVID19       maps    mapdata        qss \n      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE \n```\n\n\n:::\n:::\n\n\nclass:inverse, center, middle \\# üí™ \\## Load the Covid-19 Data\n\n## Load the Covid-19 Data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# covid <- COVID19::covid19(\n#   country = \"US\",\n#   level = 2,\n#   verbose = F\n# )\nload(url(\"https://pols1600.paultesta.org/files/data/covid.rda\"))\n```\n:::\n\n\n## Filter the Covid-19 Data to include Just US States\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Vector containing of US territories\nterritories <- c(\n  \"American Samoa\",\n  \"Guam\",\n  \"Northern Mariana Islands\",\n  \"Puerto Rico\",\n  \"Virgin Islands\"\n  )\n\n# Filter out Territories and create state variable\ncovid_us <- covid %>%\n  filter(!administrative_area_level_2 %in% territories)%>%\n  mutate(\n    state = administrative_area_level_2\n  )\n```\n:::\n\n\n## Setting global options\n\n-   Lets you control the default behavior of R and R Markdown\n    -   Do you want to print warnings when you knit?\n    -   How big should your figures be\n-   I'll typically set these for you\n\n## The global options for these slides\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noptions(htmltools.dir.version = FALSE)\n\nknitr::opts_chunk$set(\n  warning = FALSE, \n  message = FALSE, \n  comment = NA, \n  dpi = 300, fig.align = \"center\", out.width = \"80%\", \n  cache = FALSE) #<<\n```\n:::\n\n\n## Cacheing\n\n-   Sometimes I will turn [cacheing](https://bookdown.org/yihui/rmarkdown-cookbook/cache.html) on (`cache=TRUE`)\n\n-   When you knit with cache-ing, R saves the output of each codechunk\n\n-   The next time you knit, if the code in a code chunk hasn't changed, R just loads the saved output from the previous session, rather than re-running the code.\n\n-   This is useful when [a chunk of code takes a long time to run](https://bookdown.org/yihui/rmarkdown-cookbook/cache.html)\n\n-   This can potentially create errors, if you change something in one code chunk, but subsequent code are unchanged and load older versions of your code, that don't have the thing you changed.\n\n-   If this happens, try turning off the cacheing (`cache=F`) and rerunning your code. If your code works, can turn cache-ing back on.\n\n## Data transformations\n\nYou want to:\n\n-   Load some data\n\n-   Combine multiple functions\n\n-   Look at your data\n\n-   Recode your data\n\n-   Transform your data\n\n## Data transformations\n\n.pull-left\\[ You want to:\n\n-   Load some data\n\n-   Combine multiple functions\n\n-   Look at your data\n\n-   Recode your data\n\n-   Transform your data \\]\n\n.pull-right\\[ You could use\n\n-   `read_*` functions\n\n-   `%>%` the \"pipe\" operator\n\n-   `glimpse()` `head()`, `filter()`, `select()`, `arrange()`\n\n-   `mutate()`, `case_when()`, `ifelse()`\n\n-   `summarize()`, `group_by()`\n\n\\]\n\n# üîç\n\n# Recoding categorical data in R\n\nLet's clarify what's going on when we create the `face_masks` variable from the `facial_coverings` variable\n\n-   Why are we doing this\n-   What does `mutate()` do\n-   What does `case_when()` do\n-   What does `factor()` do\n\n## Why are we doing this?\n\nWhen we looked at the raw data, `facial_coverings` was a numeric variable with both positive and negative values\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(covid_us$facial_coverings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   -4    -3    -2    -1     0     1     2     3     4 \n  410  5897  7362   275  3893  8604 17424  9191   622 \n```\n\n\n:::\n:::\n\n\n## Why are we doing this?\n\nSubstantively, the absolute value of these numeric values correspond to increasingly restrictive face mask policies:\n\n-   0 - No policy\n-   1 - Recommended\n-   2 - Required in some specified shared/public spaces outside the home with other people present, or some situations when social distancing not possible\n-   3 - Required in all shared/public spaces outside the home with other people present or all situations when social distancing not possible\n-   4 - Required outside the home at all times regardless of location or presence of other people\n\nWith negative values denoting \"best guesses\" of the policy in effect for most people in a state - Example: Illinois is coded as a negative 4 when Chicago adopts a stringent face mask policy\n\n## Why are we doing this?\n\n-   The numbers for these policies reflect an *ordinal* ranking:\n    -   No policy is less restrictive than Recommendations is less restrictive than requirements ...\n-   Beyond this ordering, the numbers themselves don't convey any additional meaning:\n    -   A partial requirement (2) is not \"twice as restrictive\" as a recommendation (1).\n-   How to treat statewide policies (positive numbers) vs mixed regimes (negative) is tricky\n    -   Ideally, we'd use more granular data (e.g. counties)\n    -   In practice, we'll collapse this distinction in our code\n    -   As social scientists, we'd then want explore how our results change using alternative coding rules\n-   By converting the numeric `facial_coverings` variable into the categorical, ordered factor `face_masks` we get a variable that:\n    -   Has meaningful labels\n    -   Retains the substantive ordering of policies\n\n## Creating the `face_masks` variable\n\nHere's the snippet of code I've given you in the past:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncovid_us %>%\nmutate(\n    face_masks = case_when(\n      facial_coverings == 0 ~ \"No policy\",\n      abs(facial_coverings) == 1 ~ \"Recommended\",\n      abs(facial_coverings) == 2 ~ \"Some requirements\",\n      abs(facial_coverings) == 3 ~ \"Required shared places\",\n      abs(facial_coverings) == 4 ~ \"Required all times\",\n    ) %>% factor(.,\n      levels = c(\"No policy\",\"Recommended\",\n                 \"Some requirements\",\n                 \"Required shared places\",\n                 \"Required all times\")\n    ) \n    ) -> covid_us\n```\n:::\n\n\n## Creating the `face_masks` variable\n\nHere's a slightly clearer way of doing the same thing\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncovid_us %>%\nmutate(\n  # Recode facial_coverings to create face_masks\n    face_masks = case_when(\n      facial_coverings == 0 ~ \"No policy\",\n      abs(facial_coverings) == 1 ~ \"Recommended\",\n      abs(facial_coverings) == 2 ~ \"Some requirements\",\n      abs(facial_coverings) == 3 ~ \"Required shared places\",\n      abs(facial_coverings) == 4 ~ \"Required all times\",\n    ),\n    # Turn face_masks into a factor with ordered policy levels\n    face_masks = factor(face_masks,\n      levels = c(\"No policy\",\"Recommended\",\n                 \"Some requirements\",\n                 \"Required shared places\",\n                 \"Required all times\")\n    ) \n    ) -> covid_us\n```\n:::\n\n\n## Understanding what `case_when()` does\n\nLet's take a (pseudo) random slice of our data:\n\n\n::: {.cell layout-align=\"center\" highlight.output='[4,8,9]'}\n\n```{.r .cell-code}\nset.seed(123)\ncovid_us %>%\n  select(date, state, facial_coverings, face_masks)%>%\n  slice(sample(1:dim(covid_us)[1], size=10, replace = F))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         date         state facial_coverings             face_masks\n1  2020-04-26      Maryland                2      Some requirements\n2  2022-04-25       Florida                1            Recommended\n3  2020-12-16     Tennessee               -3 Required shared places\n4  2020-05-15     Tennessee                1            Recommended\n5  2021-09-18      Arkansas               -2      Some requirements\n6  2021-09-08       Florida               -2      Some requirements\n7  2020-07-11        Alaska               -3 Required shared places\n8  2020-07-07 New Hampshire               -2      Some requirements\n9  2022-09-11      Nebraska                2      Some requirements\n10 2020-04-06        Oregon                1            Recommended\n```\n\n\n:::\n:::\n\n\n## Understanding all that other stuff did\n\n.pull-left\\[ - `set.seed(123)` sets the \"seed\" that your computer uses to generate pseudo random numbers - `select()` selects just the `date`, `state`, `facial_coverings`, and `face_masks` columns from the data - `slice()` selects a slice of rows from the data - `sample()` takes random sample from the sequence of numbers 1 to 40,889 (`dim(covid_us)`) of size 10, without replacement (no duplicates), which `slice()` interprets as the rows you want to select\n\n\\]\n\n.pull-right\\[\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\ncovid_us %>%\n  select(date, state, facial_coverings, face_masks)%>%\n  slice(sample(1:dim(covid_us)[1], size=10, replace = F))\n```\n:::\n\n\n\\]\n\n## Data visualization\n\nA basic graphic requires at minimum:\n\n-   `data:` the dataset containing the variables of interest.\n-   `aes`: aesthetic attributes of the geometric object. For example, x/y position, color, shape, and size. Aesthetic attributes are mapped to variables in the dataset.\n-   `geom:` the geometric object in question. This refers to the type of object we can observe in a plot For example: points, lines, and bars.\n\n## Data visualization\n\nBasic graphics are made even better with:\n\n-   `facets`\n-   `statistics`\n-   `coordinates`\n-   `themes`\n\n## Topics\n\n-   Causal inference\n\n-   Notations to describe causal claims\n\n    -   Potential Outcomes\n    -   Directed Acyclic Graphs\n\n-   Causal Identification\n\n    -   Experimental designs (this week)\n    -   Observational designs (next week)\n\n-   Causal Identification in Experimental Designs\n\n    -   How random assignment creates credible counter factual comparisons\n\n## Exercises\n\n1.  What kinds questions have causal interpretations?\n\n2.  Estimating an average treatment effect with the `resume` data\n\n3.  Exploring the data for Broockman and Kalla 2016\n\nclass: inverse, center, middle \\# üí° \\# Causal Inference \\## *Causal claims imply counterfactual comparisons*\n\n## Causal claims imply counterfactual comparisons\n\n-   Causal claims imply claims about counterfactuals\n    -   What would have happened if we were to change some aspect of the world?\n\n--\n\nWhat's the counter factual for these claims:\n\n--\n\n-   Foreign aid increases develop\n\n--\n\n-   Wikileaks cost Hillary Clinton the 2016 election\n\n--\n\n-   Democracies don't fight wars with other democracies\n\n--\n\n-   Universal Pre-K improves child development\n\n## Casual claims are are all around us\n\n.pull-left\\[\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://images-na.ssl-images-amazon.com/images/I/A1qhBebbu6L.jpg){fig-align='center' width=80%}\n:::\n:::\n\n\n\\]\n\n--\n\n.pull-right\\[\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://press.uchicago.edu/.imaging/mte/ucp/medium/dam/ucp/books/jacket/978/02/26/11/9780226112374.jpg/jcr:content/9780226112374.jpg){fig-align='center' width=80%}\n:::\n:::\n\n\n\\]\n\n## Casual claims are are all around us\n\nWhat are some questions that interest you?\n\nWhat are the counterfactual comparisons they imply?\n\nclass: inverse, center, middle \\# üí° \\# Notations to describe causal claims\n\nIn this course, we will use two forms of notation to describe our causal claims.\n\n-   Directed Acyclic Graphs\n\n-   Potential Outcomes Notation\n\n## Directed Acyclic Graphs\n\n-   Directed Acyclic Graphs provide a way of encoding assumptions about casual relationships\n\n    -   **Directed** Arrows $\\to$ describe a direct causal effect\n\n    -   Arrow from $D\\to Y$ means $Y_i(d) \\neq Y_i(d^\\prime)$ \"The outcome ( $Y$) for person $i$ when D happens ( $Y_i(d)$ ) is different than the the outcome when $D$ doesn't happen ( $Y_i(d^\\prime)$ )\n\n    -   No arrow = no effect ( $Y_i(d) = Y_i(d^\\prime)$ )\n\n    -   **Acyclic:** No cycles. A variable can't cause itself\n\n-   Used by Pearl ([2009](http://bayes.cs.ucla.edu/jp_home.html), [2017](http://bayes.cs.ucla.edu/jp_home.html)) to describe and assess causal structural models\n\n> Basically, they're math's fancy pants version of a flow chart\n\n## Why we use Directed Acyclic Graphs\n\n-   Directed Acyclic Graphs are flexible ways of representing complex relationships\n\n-   They're great for illustrating sources of potential bias in our models:\n\n-   Two types of bias we'll talk about today:\n\n    -   **Confounder bias:** Bias that exists because two variables have a *common cause*\n\n    -   **Collider bias:** Bias we create when we condition on a *common consequence*\n\n## What do we mean by bias\n\nWe'll talk about lots of types of bias throughout this course.\n\nFormally, we'll say an estimate, $\\hat{\\theta}$ (\"theta hat\") is an unbiased estimator of a parameter, $\\theta$ (\"theta\") if:\n\n$$\nE[\\hat{\\theta}] = \\theta\n$$\n\nBias or error, $\\epsilon$, is the difference between our estimate and the truth\n\n$$\n\\epsilon = \\hat{\\theta} -\\theta\n$$\n\nAn estimator is unbiased if, on average, the errors equal 0\n\n$$\nE[\\epsilon] = E[\\hat{\\theta} -\\theta] = 0\n$$\n\n## Bias vs. variance\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/images/bias_variance/bullseye.png){fig-align='center' width=80% height=80%}\n:::\n:::\n\n\n## The Bias-Variance Tradeoff\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Drawing DAGs in R\n\n-   Let's draw some dags to consider some simple examples:\n\n    -   Does drinking coffee cause lung cancer? (Confounding bias)\n\n    -   Does chicken pox cause influenza? (Collider bias)\n\n-   Nice examples of DAGs from [ggdag](https://ggdag.malco.io/index.html)\n\n### Confounding = Common Causes\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-25-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Controlling for a confounding variable\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-26-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Colliders = Common Consequence\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Don't Condition on a Collider\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-28-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Don't Condition on a Collider\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Potential Outcomes\n\n-   DAGs are great for representing a wide array of relationships\n\n-   Doing [causal inference with DAGs](https://mixtape.scunning.com/dag.html) is a bit beyond the scope of this class\n\n-   Instead, we'll typically talk about causal claims using the logic of potential outcomes to describe the counterfactual comparisons we want to make.\n\n-   To do this, we'll need to get comfortable with some basic notation.\n\n## Some general notes on notation\n\n-   Notation can seem scary, overwhelming, confusing.\n\n-   Notation can be incredibly helpful for communicating precisely and clearly\n\n-   Our goal is to demystify notation\n\n## General Notation: Populations and Samples\n\n-   $U$: Population of units:\n    -   Finite population $U = {1,2,3,\\dots,N}$\n    -   Infinite super population $U = {1,2,3,\\dots,\\infty}$\n-   $S$: sample of size $n$ from population $U$\n\n## General Notation: Outcome Variables\n\n-   $Y_i$: Observed outcome from unit $i$\n    -   $Y_i$ might be whether persion $i$, call them Paul has Covid while $Y_j$ would be whether person $j$, call them Aleks has Covid\n\n## General Notation: Treatment Variables\n\n-   $D_i$: An indicator for the receipt of treatment. $D_i$ = 1 if treated, $D_i$ = 0 if untreated,\n    -   $D_i = 0$ means Paul got the placebo in a vaccine trial\n    -   $D_i = 1$ means Paul got the vaccine\n    -   Generalizes to multiple treatments $D \\in \\{0,1,2,3, \\dots\\}$\n-   $Z_i$: An indicator for the assignment of treatment. $Z_i$ = 1 if assigned to treatment, $Z_i$ = 0 if assigned to control,\n    -   $Z_i = 1$ means Paul was assigned to receive the vaccine. Whether Paul got the vaccine depends on $D_i$\n\n## General Notation: Observed and Unobserved Covariates\n\n-   $X_i$ pre-treatment covariates.\n    -   $X_i$ might be Paul's age, or gender, or partisan affiliation\n    -   Pre-treatment refers to things that are determined before the treatment is assigned and therefore cannot be influenced by the treatment\n-   $U_i$ unobserved potential confounds\n    -   $_i$ might be something we didn't or can't measure like Paul's genome or general crankiness\n\n## General Notation: Expected Values\n\n-   The $E[Y]$ reads as \"the expected value of Y\"\n\n-   $E[Y]$ is defined as a probability weighted average based on the uncoditional probability of Y ( $f(y)$ )\n\n$$\\operatorname{E}[Y] = \\int_{-\\infty}^\\infty y f(y)\\, dy$$\n\n## General Notation: Conditional Expectations\n\n-   The $E[Y|X=x]$ reads as \"the expected value of Y conditional on the value of X\"\n\n-   $E[Y|X=x]$ is defined as a probability weighted average of Y based on the conditional probability of Y given X ( $y f_{Y|X}(y|x)$ )\n\n$$\\operatorname{E}[Y \\vert X=x] = \\int_{-\\infty}^\\infty y f (y\\vert x) \\, dy$$\n\n## General Notation: Expected Values\n\n-   Don't worry about the math in this course.\n\n-   We'll talk more expected values during our discussion of probability\n\n-   For now, just think of $E[Y]$ and $E[Y|X=x]$ as a theoretical averages which we can estimate from the empirical means in our data (`mean(data$y)`, `mean(data$y[data$x == 1]`))\n\n## Potential Outcomes Notation:\n\n-   Potential outcomes notation is a way of describing counterfactuals\n\n--\n\n-   $Y_i(d)$ is the value of the outcome if $D_i$ was $d$\n\n    -   $Y_i(1)$ is the vote share of Rep. Smith when they support #MeToo\n\n    -   $Y_i(0)$ is the vote share of Rep. Smith when they do not support #MeToo.\n\n--\n\n-   Potential outcomes are fixed, but we only observe one (of many) potential outcomes $\\to$ *Fundamental Problem of Causal Inferenece*\n\n## Fundamental Problem of Causal Infernece\n\nThe individual causal effect (ICE), $\\tau_i$, of some treatment $d_i$ on some observation $i$ is\n\n$$\n\\tau_i \\equiv Y_i(1) - Y_i(0)\n$$\n\n-   The **fundamental problem of causal inference** is that we only ever see one potential outcome for an individual, and so it's **impossible to know** the causal effect of some intervention for that individual\n\n-   The ICE is unidentified\n\n-   Example:\n\n    -   Paul got the vaccine. The individual effect of the vaccine on Paul is the difference in his health status when he got the vaccine compared to his health status when he got the placebo. But we only observe one of these two potential outcomes.\n\nclass: inverse, center, middle \\# üí° \\# Causal Identification \\## *What assumptions do we need to make for a causal claim to be credible*\n\n## Identification\n\n-   Identification refers to what we can learn from the data available\n\n-   A quantity of interest is *identified* if, with infinite data it can only take one value\n\n-   Mathematically, we'll sometimes say a coefficient in an equation is unidentified if\n\n    -   We have more predictors than observations, or\n    -   Some of predictors are linear combinations of other predictors.\n\n## Causal Identification\n\n-   **Casual Identification** refers to \"the assumptions needed for statistical estimates to be given a causal interpretation\" [Keele (2015)](http://lukekeele.com/wp-content/uploads/2016/03/causal.pdf)\n\n-   **What's Your Casual Identification Strategy:** What are the assumptions that make your research design credible?\n\n-   Identification \\> Estimation\n\n## Observational vs Experimental Designs\n\n-   **Experimental designs** are studies in which a causal variable of interest, the *treatement*, is manipulated by the researcher to examine its causal effects on some *outcome* of interest\n\n-   **Observational designs** are studies in which a causal variable of interest is assigned by someone other than the researcher (nature, governments, people)\n\nclass: inverse, center, middle \\# üí° \\# Causal Identification in Experimental Designs\n\n## The FPoCI is a problem of missing data\n\nThat an individual causal effect $\\tau_i$, is defined as:\n\n$$\n\\tau_i \\equiv Y_i(1) - Y_i(0)\n$$\n\nThe problem is that for any one individual, we only observe $Y_i(1)$ or $Y_i(0)$, but never both.\n\n-   If Paul got the vaccine $(Y_{Paul}(Vaxxed)=\\text{Covid Free})$, then we don't know what Paul's health status would have been, had he not got the vaccine $(Y_{Paul}(Unvaxxed) =???)$\n\n## A statistical solution to the FPoCI\n\nRather than individual causal effects:\n\n$$\n\\tau_i \\equiv Y_i(1) - Y_i(0)\n$$\n\nFocus on average causal effects\n\n$$\nE[\\tau_i] = \\overbrace{E[Y_i(1) - Y_i(0)]}^{\\text{Average of a difference}} = \\overbrace{E[Y_i(1)] - E[Y_i(0)]}^{\\text{Difference of Averages}}\n$$\n\nWhen does the difference of averages provide us with a good estimate of the average difference?\n\n## The hospital example\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://i.pinimg.com/originals/1d/1e/dd/1d1eddaa79918e9cca7e7dc857d95ffe.jpg){fig-align='center' width=80%}\n:::\n:::\n\n\n## The hospital example\n\nWant to know the effect of going to the hospital on people need to go to the hospital\n\n$$\n\\text{What we want} = E[Y(1|D=1) - Y(0|D=1)]\n$$\n\n$$\n\\text{What we want} = E[\\text{Mortality}(\\text{Hospital}|\\text{Sick}) - \\text{Mortality}(\\text{No Hospital}|\\text{Sick})]\n$$\n\n## The hospital example\n\nInstead we might end up comparing outcomes among the sick and non-sick\n\n$$\\text{What we estimate} = E[Y(1|D=1)] - E[Y(0|D=0)]$$\n\n$$\\text{What we estimate} = E[\\text{Mortality}(\\text{Hospital})] - E[\\text{Mortality}(\\text{No Hospital})]$$\n\n## Selection bias\n\nThe hospital example illustrates the general problem of selection bias\n\n$$\\widehat{SATE}=\\overbrace{\\textbf{E[Y(1)|D=1]} - E[Y(0)|D=1]}^{\\text{Average Effect of Treatment on Treated}}\\\\\n\\underbrace{+ E[Y(0)|D=1]- \\textbf{E[Y(0)|D=0]}}_{\\text{Selection Bias}}$$\n\n-   The bold quantities are things we can **observe** (estimate)\n-   $E[Y(0)|D=1]$ is a an unobservable counterfactual.\n-   It's the average health outcomes of people who went to the hospital $(D=1)$ if they hadn't $(Y(0)|D=1)$\n\n## Selection bias\n\n-   Adding and subtracting $E[Y(0)|D=1]$ thing doesn't change the equation but it allows us to write what we can estimate in terms of two quantities:\n\n-   The **Average Treatment Effect on the Treated:** $\\mathbf{E[Y(1)|D=1]} - E[Y(0)|D=1]$\n\n    -   This is what we **want to know** if we want to make causal claims about the effect of health care\n\n-   **Selection Bias:** $E[Y(0)|D=1] - \\mathbf{E[Y(0)|D=0]}$,\n\n    -   This is the difference in health outcomes between healthy folks who didn't go to the hospital $(Y(0)|D=0)$ and sick folks who went to the hopsital had they not gone $(Y(0)|D=1)$\n    -   This what **confounds our causal claims** if we just compare outcomes among people who went to the hospital and people who didn't\n    -   Selection bias equals 0 if $E[Y(0)|D=1] = \\mathbf{E[Y(0)|D=0]}$\n    -   $E[Y(0)|D=1] = \\mathbf{E[Y(0)|D=0]}$ if **D has been randomly assigned**\n\n## Random Assignment \"Solves\" the Problem of Selection Bias\n\nRandomly assigning treatments creates *statistical independence* $(\\unicode{x2AEB})$ between treatment ( $D$ ) and potential outcomes ( $Y(1),Y(0)$ ) as well as any observed ( $X$ ) or unobserved confounders ( $U$ ):\n\n$$Y_i(1),Y_i(0),\\mathbf{X_i},\\mathbf{U_i} \\unicode{x2AEB} D_i$$\n\n## Random Assignment \"Solves\" the Problem of Selection Bias\n\nWhen treatment has been randomly assigned, what we can observe ( $E[Y_i|D=0], E[Y_i|D=1]$ ), provides good (unbiased) estimates of theoretical quantities we want observe\n\n$$E[Y_i|D=0] = E[Y_i(0)|D=0] = E[Y_i(0)] = E[Y_i(0)|D=1]$$\n\n$$E[Y_i|D=1] = E[Y_i(1)|D=1] = E[Y_i(1)] = E[Y_i(1)|D=0]$$\n\n## Estimating an Average Treatment Effect\n\nIf we treatment as been randomly assigned, we can estimate the ATE by taking the difference of means between treatment and control:\n\n$$\n\\begin{align*}\nE \\left[ \\frac{\\sum_1^m Y_i}{m}-\\frac{\\sum_{m+1}^N Y_i}{N-m}\\right]&=\\overbrace{E \\left[ \\frac{\\sum_1^m Y_i}{m}\\right]}^{\\substack{\\text{Average outcome}\\\\\n\\text{among treated}\\\\ \\text{units}}}\n-\\overbrace{E \\left[\\frac{\\sum_{m+1}^N Y_i}{N-m}\\right]}^{\\substack{\\text{Average outcome}\\\\\n\\text{among control}\\\\ \\text{units}}}\\\\\n&= E [Y_i(1)|D_i=1] -E[Y_i(0)|D_i=0]\n\\end{align*}\n$$\n\nThat is, the ATE is causally identified by the **difference of means** estimator in an experimental design\n\n## Causal Identification with Experimental Designs\n\nCausal identification for an experiment, requires very few assumptions:\n\n--\n\n-   **Independence** (Satisfied by Randomization)\n    -   $Y(1), Y(0),X,U, \\perp D$\n-   **SUTVA** Stable Unit Treatment Value Assumption (Depends on features of the design)\n    -   No interference between units $Y_i(d_1, d_2, \\dots, d_N) = Y_i(d_i)$\n    -   No hidden values of the treatment/Variation in the treatment\n\n## Random Assignment creates testable implications\n\n-   If treatment has been randomly assigned, we would expect that there should be few differences between **pre-treatment covariates** in our treatment and control groups.\n\n--\n\n-   That is, on average, the only the thing that should differ between these groups is that one group got the treatment and one group did not.\n\n--\n\n-   If the treatment had an effect, than we can credibly claim that that effect was due to the presence or absence of the treatment, and not some alternative explanation.\n\n--\n\n-   This type of clean counterfactual comparison is what people mean when they talk about an *experimental ideal*\n\n## No Causation without Manipulation?\n\n-   \"No causation without manipulation\" - [Holland (1986)](https://www.jstor.org/stable/2289064)\n-   Causal effects are well defined when we can imagine manipulating (changing) the value of $D_i$ and only $D_i$\n-   But what about the \"effects\" of things like:\n    -   Race\n    -   Sex\n    -   Democracy\n-   Studying the effects of these factors requires strong theory and clever design [Sen and Wasow (2016)](https://scholar.harvard.edu/files/msen/files/race_causality.pdf)\n\nclass:inverse, center, middle\n\n# üîç\n\n# Summary\n\n# Causal Inference\n\n--\n\n-   Causal Claims involve counterfactual comparisons\n\n--\n\n-   The fundamental problem of causal inference is that for an individual only observe one of many potential outcomes\n\n--\n\n-   Causal identification refers to the assumptions necessary to generate credible causal estimates\n\n--\n\n-   Experimental designs are identified by the random assignment of treatment which allows us to produce unbiased estimates of the **Average Treatment Effect**\n\n--\n\n-   Estimates are unbiased if, on average, they're equal to the trut $(E[\\hat{\\theta} - \\theta] = 0 )$\n\n--\n\n-   Two kinds of bias:\n    -   Confounding occurs when we **fail to control** for factors that influence both our outcome and explanatory variables\n    -   Colliding bias occurs when we **control** for factors influenced by both our outcome and explanatory variables\n\nclass: inverse, center, middle \\# üí™\\\n\\# Estimating an average treatment effect with the `resume` data\n\n## The Resume Experiment (p. 33)\n\nLet's take a look at the resume experiment from your text book and compare some of Imai's code to its `tidyverse` equivalent\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# make sure qss package is loaded\nlibrary(qss)\ndata(\"resume\")\n```\n:::\n\n\n## High level Overview (p. 34)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(resume)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4870    4\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(resume)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  firstname    sex  race call\n1   Allison female white    0\n2   Kristen female white    0\n3   Lakisha female black    0\n4   Latonya female black    0\n5    Carrie female white    0\n6       Jay   male white    0\n```\n\n\n:::\n:::\n\n\n## High level Overview (p. 34)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(resume)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  firstname             sex                race                call        \n Length:4870        Length:4870        Length:4870        Min.   :0.00000  \n Class :character   Class :character   Class :character   1st Qu.:0.00000  \n Mode  :character   Mode  :character   Mode  :character   Median :0.00000  \n                                                          Mean   :0.08049  \n                                                          3rd Qu.:0.00000  \n                                                          Max.   :1.00000  \n```\n\n\n:::\n:::\n\n\n## Cross Tabs\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrace.call.tab <- table(race = resume$race,\n                       call = resume$call)\nrace.call.tab\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       call\nrace       0    1\n  black 2278  157\n  white 2200  235\n```\n\n\n:::\n\n```{.r .cell-code}\naddmargins(race.call.tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       call\nrace       0    1  Sum\n  black 2278  157 2435\n  white 2200  235 2435\n  Sum   4478  392 4870\n```\n\n\n:::\n:::\n\n\n## Tidy cross tab\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresume %>%\n  group_by(race, call)%>%\n  summarise(\n    n = n()\n  )%>%\n  pivot_wider(names_from = call, values_from = n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 3\n# Groups:   race [2]\n  race    `0`   `1`\n  <chr> <int> <int>\n1 black  2278   157\n2 white  2200   235\n```\n\n\n:::\n:::\n\n\n## Calculating Call Back Rates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Overall\nsum(race.call.tab[,2])/nrow(resume)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.08049281\n```\n\n\n:::\n\n```{.r .cell-code}\n# Black names\ncb_bl <- sum(race.call.tab[1,2])/sum(race.call.tab[1,])\n# White Names\ncb_wh <- sum(race.call.tab[2,2])/sum(race.call.tab[2,])\n\n# ATE\ncb_wh - cb_bl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03203285\n```\n\n\n:::\n:::\n\n\n## Calculating Call Back Rates with group_by()\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresume %>%\n  group_by(race)%>%\n  summarise(\n    call_back = mean(call)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 2\n  race  call_back\n  <chr>     <dbl>\n1 black    0.0645\n2 white    0.0965\n```\n\n\n:::\n:::\n\n\n## Factor variables in Base R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresume$type <- NA\nresume$type[resume$race == \"black\" & resume$sex == \"female\"] <- \"BlackFemale\"\nresume$type[resume$race == \"black\" & resume$sex == \"male\"] <- \"BlackMale\"\nresume$type[resume$race == \"white\" & resume$sex == \"female\"] <- \"WhiteFemale\"\nresume$type[resume$race == \"white\" & resume$sex == \"male\"] <- \"WhiteMale\"\n```\n:::\n\n\n## Factor variables in Tidy R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresume %>%\n  mutate(\n    type_tidy = case_when(\n      race == \"black\" & sex == \"female\" ~ \"BlackFemale\",\n      race == \"black\" & sex == \"male\" ~ \"BlackMale\",\n      race == \"white\" & sex == \"female\" ~ \"WhiteFemale\",\n      race == \"white\" & sex == \"male\" ~ \"WhiteMale\"\n    )\n  ) -> resume\n```\n:::\n\n\n## Comparing approaches\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(base= resume$type, tidy= resume$type_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             tidy\nbase          BlackFemale BlackMale WhiteFemale WhiteMale\n  BlackFemale        1886         0           0         0\n  BlackMale             0       549           0         0\n  WhiteFemale           0         0        1860         0\n  WhiteMale             0         0           0       575\n```\n\n\n:::\n:::\n\n\n## Visualizing Call Back Rates by Name\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresume %>%\n  group_by(race, sex,firstname)%>%\n  summarize(\n    Y = mean(call),\n    n = n()\n  )%>%\n  arrange(desc(Y)) %>%\n  mutate(\n    firstname = forcats::fct_reorder(firstname,Y)\n  )%>%\n  ggplot(aes(Y, firstname,col=race, size=n))+\n  geom_point() + \n  facet_grid(sex~.,scales = \"free_y\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slides_files/figure-revealjs/unnamed-chunk-42-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nclass:inverse, center, middle \\# üí™\\\n\\# Exploring the data for Broockman and Kalla 2016\n\n# Reading Academic Papers\n\n-   Reading academic papers is a skill and takes practice.\n-   You should aim to answer the following:\n    -   What's the research question?\n    -   What's the theoretical framework?\n    -   What's the empirical design?\n    -   What's are the main results?\n\n## Broockman and Kalla (2016)\n\n-   What's the research question?\n-   What's the theoretical framework?\n-   What's the empirical design?\n-   What's are the main results?\n\n## Study Design :A placebo-controlled field experiment\n\n1.  Recruited from voter files to complete a baseline survey\n2.  Among those who complete the survey, half are assigned to receive an intervention and half are assigned to receive a placebo\n3.  Only some are actually home or open the door when the canvassers knock.\n4.  These people are then recruited to participate in a series of surveys 3 days, 3 weeks, 6 weeks, and 3 months after the initial intervention.\n\n## Data for Thursday\n\nLet's load the data from the orginal study\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(url(\"https://pols1600.paultesta.org/files/data/03_lab.rda\"))\n```\n:::\n\n\n## Codebook\n\n-   `completed_baseline` whether someone completed the baseline survey (\"Survey\") or not (\"No Survey\")\n-   `treatment_assigned` what intervention someone who completed the baseline survey was assigned two (treatment= \"Trans-Equality\", placebo = \"Recycling\")\n-   `answered_door` whether someone answered the door (\"Yes\") or not (\"No\") when a canvasser came to their door\n-   `treatment_group` the treatment assignments of those who answered the door (treatment= \"Trans-Equality\", placebo = \"Recycling\")\n-   `vf_age` the age of the person in years\n-   `vf_female` the respondent's sex (female = 1, male = 0)\n-   `vf_democrat` whether the person was a registered Democract (Democrat=1, 0 otherwise)\n-   `vf_white` whether the person was white (White=1, 0 otherwise)\n-   `vf_vg_12` whether the person voted in the 2012 general election (voted = 1, 0 otherwise)\n\n## HLO\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 68,378\nColumns: 14\n$ completed_baseline <chr> \"No Survey\", \"No Survey\", \"No Survey\", \"No Survey\",‚Ä¶\n$ treatment_assigned <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ answered_door      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ treatment_group    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ vf_age             <dbl> 23.00000, 38.00000, 48.00000, 49.20192, 49.20192, 4‚Ä¶\n$ vf_female          <dbl> 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, ‚Ä¶\n$ vf_democrat        <dbl> 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, ‚Ä¶\n$ vf_white           <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ‚Ä¶\n$ vf_vg_12           <dbl> 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, ‚Ä¶\n$ therm_trans_t0     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ therm_trans_t1     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ therm_trans_t2     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ therm_trans_t3     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ therm_trans_t4     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n```\n\n\n:::\n:::\n\n\n## Study Design\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(df$completed_baseline)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNo Survey    Survey \n    66553      1825 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(df$treatment_assigned)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Recycling Trans-Equality \n           913            912 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(df$answered_door)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  No  Yes \n1324  501 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(df$treatment_group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Recycling Trans-Equality \n           255            246 \n```\n\n\n:::\n:::\n\n\n## Assessing balance in covariates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf %>%\n  filter(completed_baseline == \"Survey\") %>%\n  select(treatment_assigned,starts_with(\"vf_\"))%>%\n  group_by(treatment_assigned)%>%\n  summarise(across(starts_with(\"vf_\"), mean))->pretreatment_balance\n```\n:::\n\n\n## Assessing balance in covariates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npretreatment_balance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 6\n  treatment_assigned vf_age vf_female vf_democrat vf_white vf_vg_12\n  <chr>               <dbl>     <dbl>       <dbl>    <dbl>    <dbl>\n1 Recycling            46.3     0.593       0.463    0.209    0.757\n2 Trans-Equality       47.7     0.582       0.488    0.217    0.719\n```\n\n\n:::\n:::\n\n\n## Assessing balance in covariates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npretreatment_balance %>%\n  gather(.,key = covariate, value = value, -treatment_assigned) %>%\n  spread(treatment_assigned, value) %>%\n  mutate(\n    Difference = `Trans-Equality` - Recycling\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 4\n  covariate   Recycling `Trans-Equality` Difference\n  <chr>           <dbl>            <dbl>      <dbl>\n1 vf_age         46.3             47.7      1.40   \n2 vf_democrat     0.463            0.488    0.0246 \n3 vf_female       0.593            0.582   -0.0103 \n4 vf_vg_12        0.757            0.719   -0.0375 \n5 vf_white        0.209            0.217    0.00790\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding/datatables.js\"></script>\n<script src=\"../site_libs/jquery/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk/js/crosstalk.min.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}